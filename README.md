# Algorithm_Datastructure

# 2023.08.02

# Map_Reduce using STL (STL을 이용)

맵은 컨테이너 C를 입력으로 받아, 컨테이너의 모든 원소에 함수 f(x)를 적용하는 것이다. 예를 들어 f(x)=x^2함수를 사용할 경우에 대한 맵 연산을 다음에 나타낸다.
1 2 3 4 5 6 7
->1 4 9 16 25 36 49

리듀스는 컨테이너 C의 모든 원소 x에 함수 f(acc,x)를 적용하여 하나의 값으로 축약하는 연산이다. 예를 들어 f(acc,x)=acc+x 함수를 사용할 경우에 대한 리듀스 연산의 예를 다음에 나타낸다. 
1 2 3 4 5 6 7
->28

c++ 표준 라이브러리는 맵과 리듀스 연산을 std::transform()과
std::accumulate함수로 제공한다. c++17에서는 std::reduce()도 제공한다.
accumulate()는 기본적으로 누적 연산을 수행하기 때문에 리듀스 연산의 제한된 형태라고 볼 수 있다. c++17을 지원하는 최신 컴파일러에서는 더 일반적이며 병렬 처리도 지원하는 reduce()를 사용할 수 있다.

# Map_Reduce_PrimeNumber

맵 리듀스 모델을 사용하여 프로그램을 작성하려면 원하는 연산을 맵과 리듀스 두 단계로 표현할 수 있어야 한다. 맵(또는 파티션) 단계에서는 입력을 중간 단계의 <키,값>쌍으로 표현하고, 리듀스 단계에서는 중간 단계의 <키,값>쌍을 원하는 방식으로 결합하여 최종 결과를 생성한다.
하둡은 맵과 리듀스 연산을 확장성 있고 분산 처리가 가능하게 만듦으로써 컴퓨터 클러스터에서 동작할 수 있고 연산 시간을 크게 단축시킬 수 있다.

해당 코드는 양의 정수 N이 있을 때 1에서 N사이의 소수를 찾으려고 한다. 맵 리듀스 프로그래밍 모델과 멀티 스레드를 사용하여 이 문제를 해결한다.

# PPL (병렬 처리 라이브러리)

병렬 처리 라이브러리에서 제공하는 함수들과 STL 함수의 맵 작업의 속도를 비교하는 MS 레퍼런스의 코드이다. 
여러 프로세스를 처리하는 병렬 처리 방식을 사용하는 parallel_for_each함수가 더 빠른 것을 확인할 수 있다.

병렬 처리는 대규모의 데이터를 처리할 때 유용하게 사용되는 개념이다.

# Student_grade 

학생들의 정보를 저장하고 평균과 총점, 정보를 출력할 수 있는 클래스를 구현했다.

# 2023.08.03

# Greedy Algorithm (shortest -job-first-scheduling)

은행 창구에 줄을 서서 순서를 기다리는 사람들이 있다. 하필이면 은행이 바쁜 날이라서 하나의 창구에서만 업무를 보고 있고, 대기열에 N명의 사람들이 기다리고 있다. 이들은 서로 다른 용무로 방문했기 때문에 일 처리에 필요한 시간은 사람들마다 다르다. 대기열에 기다리고 있던 모든 사람이 매우 합리적이어서 평균 대기 시간이 최소화될 수 있도록 대기 순서를 다시 정하는 것에 동의했다. 그래서 이제 대기 순서를 어ᄄᅠᇂ게 바꿔야 하는지를 결정해야 한다.

일 처리 시간 		8 1 2 4 9 2 3 5
기다려야 하는 시간  0 8 9 11 15 24 26 29
평균 대기 시간 15.25

평균 대기 시간을 최소화하는 것이 목표이기 때문에 가능한 많은 사람의 대기 시간을 줄일 수 있는 방법을 찾아야 한다. 모든 사람의 대기 시간을 줄이려면 일 처리가 가장 빨리 끝나는 사람을 맨 앞에 세워야 한다. 이러한 방식을 반복하면 다음과 같이 재정렬할 수 있다.

일 처리 시간1 2 2 3 4 5 8 9 기다려야 하는 시간
0 1 3 5 8 12 17 25
평균 대기 시간 8.875

# Fractional_kanpsack_problem (분할 가능 배낭 문제)

0-1 배낭 문제라고도 부르는 일반 배낭 문제는 NP-완전 문제로 알려져 있어서 다항 시간 솔루션을 사용할 수 없다. 그러나 0-1배낭 문제를 조금 변경한 분할 가능 배낭 문제는 그리디 방식으로 해결할 수 있다. 이 두 가지 문제를 살펴보면서 문제 정의의 작은 차이가 문제 해결 방법에 큰 변화를 가져올 수 있다는 것을 알 수 있다.

# 
<0-1배낭 문제>

물건들의 집합 O={O1,O2,O3...,On)이 있고, 여기서 I번째 물건 Oi의 무게는 Wi이고 가격은 Vi이다. 그리고 최대 무게를 T까지 견딜 수 있는 가방이 하나 주어진다. 이제 물건들을 가방에 담아야 하는데, 가방에 넣은 물건들의 가격 합이 최대가 되도록 물건을 선택하려 한다. 단, 물건들의 무게 합이 T를 넘지 않아야 한다.

배낭 문제는 NP-완전 문제로 알려져 있고, 이 문제에 대한 다항 시간 솔루션은 알려져 있지 않다. 결과적으로 모든 가능한 조합을 조사하여 무게가 T를 넘지 않는 가장 높은 가격을 찾아내야 한다. 
#
<분할 가능 배낭 문제>

이번에는 앞서 설명한 일반 배낭 문제를 조금 바꿔본다. 즉, 주어진 물건을 원하는 형태로 얼마든지 분할할 수 있고, 각 물건의 일부분만을 배낭에 담을 수 있다고 가정한다. 실생활의 예를 들면, 상인이 기름,곡물,밀가루와 같은 품목을 다룬다고 생각하면 된다. 이 경우 각 품목을 원하는 양만큼 덜어내서 배낭에 담을 수 있다.

# interval_scheduling_solution(작업 스케줄링 문제)

각각의 작업은 ID로 구분되고, 특정 시간 시작 시간과 종료 시간 사이에만 수행할 수 있다. 정해진 시간 안에 최대한 많은 수의 작업을 완료하는 것이 목표이다. 이 경우 어떤 작업을, 어떤 순서로 수행해야 할까? 특정 시점에 오직 하나의 작업만 수행할 수 있다.

1.각각의 작업은 고유한 ID, 시작 시간, 종료 시간을 가진다. 이러한 작업을 표현할 구조체를 생성한다.

2.N개의 작업을 포함하는 std::list를 생성한다. 각 작업은 1부터 N까지의 고유한 ID를 가진다. 시작 시간과 종료 시간은 임의의 정수로 설정한다.

3.다음과 같은 방식으로 스케줄링 함수를 작성한다.


  a.종료 시간을 기준으로 전체 작업 리스트를 정렬한다.

  b.그리디 방식으로 가장 빠른 종료 시간을 갖는 작업을 선택한다.

  c.현재 선택된 작업과 시간이 겹치는 작업은 모두 제거한다. 즉, 현재 작업 종료 시간보다 먼저 시작하는 작업은 제거한다.

  d.리스트에 작업이 남아 있다면 b로 이동한다. 그렇지 않으면 선택된 작업들로 구성된 벡터를 반환한다.

# MST (Minimum Spanning Tree)

모든 문제에 그리디 방식을 적용할 수 있는 것은 아니다. 최적 부분 구조와 그리디 선택이라는 두 가지 속성을 모두 갖는 문제만 그리디 접근 방식으로 최적의 솔루션을 구할 수 있다.

*최적 부분 구조: 주어진 문제 p에 대한 최적의 솔루션이 p의 부분 문제들의 최적의 솔루션으로 구성될 경우, 문제 p가 최적의 부분 구조를 갖는다고 말한다.

*그리디 선택: 주어진 문제 P에 대한 지역적 최적 솔루션을 반복적으로 선택하여 전체 최적 솔루션을 구할 수 있는 경우, 문제 p가 그리디 선택 속성을 갖는다고 말한다.

최적 부분 구조와 그리디 선택 속성에 대해 이해하기 위해, 크루스칼 최소 신장 트리 알고리즘에 대해 알아본다.

최소 신장 트리는 다음과 같이 정의할 수 있다. “정점(vertex)의 집합 V와 가중치를 갖는 에지(Edge)의 집합E로 구성된 그래프 G=<V,E>가 주어질 때, 모든 정점을 연결하고 연결된 에지의 가중치 합이 최소인 트리 T를 구하시오.”

실생활에서 찾아볼 수 있는 MST 문제의 예로 상수도관 네트워크 또는 도로 네트워크 설계가 있다. 상수도관 네트워크 설계의 경우, 모든 사람에게 수돗물이 전달되어야 하고 전체 상수도관의 길이는 최소가 되는 것이 좋다. 도로 네트워크를 설계할 때는 모든 필요한 지점에 도로가 연결되어야 하고 도로의 전체 길이는 최소가 되는 것을 목표로 한다. 

최소 신장 트리T를 구하는 방법은 다음과 같다.

1.그래프 G의 모든 에지를 최소 힙 H에 추가한다.

2.H로부터 에지 e를 하나 꺼낸다. 당연히 e는 모든 에지 중에서 가장 가중치가 작은 에지이다.

3.e의 양 끝 정점이 이미 T에 있을 경우, e로 인해 T에서 사이클이 발생할 수 있다. 그러므로 이런 경우에는 e를 버리고 2단계로 이동한다.

4.최소 신장 트리 T에 e를 추가하고, 2단계로 이동한다.

이 알고리즘은 2단계부터 4단계까지를 반복하면서 가장 작은 가중치의 에지를 찾고, 이 에지에 의해 사이클이 발생하지 않으면 해당 에지와 양 끝 정점을 최종 솔루션에 추가한다. 이렇게 선택된 에지와 정점은 최소 신장 트리를 구성한다. 이 알고리즘은 매 반복마다 최소 에지 가중치를 선택하기 때문에 그리디 방식이라고 할 수 있다. 이 알고리즘을 크루스칼 최소 신장 트리 알고리즘이라고 한다.

최적 부분 구조: 귀류법을 사용하여 최적 부분 구조 속성을 증명해본다. 이를 위해 MST 문제가 최적 부분 구조 속성을 가지지 않는다고 가정한다. 즉, 최소 신장 트리가 더 작은 최소 신장 트리의 집합으로 구성되지 않는다고 가정한다.

1. 그래프 G의 정점으로 구성된 최소 신장 트리 T가 있다고 가정한다. T에서 에지 e를 하나 선택하여 제거한다. e를 제거하면 T가 더 작은 트리인 T1과 T2로 나눠진다.

2.MST 문제가 최적 부분 구조 속성을 갖지 않는다고 가정했으므로 T1보다 작은 가중치를 갖는 신장 트리 T1'이 존재해야 한다. 이 신장 트리 T1'과 T2를 에지 e로 연결한 새로운 신장 트리를 T'이라고 한다.

3. T'의 가중치가 T의 가중치보다 작으므로 처음에 T가 최소 신장 트리라고 가정했던 사실이 틀리게 된다.

정리하면 최소 신장 트리 T의 부분 구조인 T'의 가중치가 더 작으므로 T'도 신장트리라고 할 수 있다. 따라서 T는 더 작은 신장트리로 구성된다고 할 수 있다. 따라서 처음 가설이 틀린 것이다.

그리디 선택: MST 문제가 그리디 선택 속성을 갖는다면 정점 v와 연결된 에지 중에서 최소 가중치 에지는 반드시 최소 신장 트리 T에 속해야 한다. 귀류법을 사용하여 이 가설을 증명할 수 있다.

1.정점 v에 연결되어 있는 에지 중에서 최소 가중치를 갖는 에지를 (u,v)라고 가정한다. 

2.만약 (u,v)가 T에 속하지 않는다면 T는 v와 연결되어 있는 다른 에지를 포함해야 한다. 이 에지를 (x,v)라고 한다. (u,v)가 최소 가중치 에지이기 때문에, (x,v)는 (u,v)의 가중치보다 커야 한다. 

3.T에서 (x,v)를 제거하고 (u,v)를 추가할 경우 전체 가중치가 더 작은 트리를 얻을 수 있다. 이는 T가 최소 신장 트리라는 가정에 위배된다. 따라서 그리디 선택 속성을 만족한다.

이 알고리즘을 구현하려면 그래프 에지 정보를 저장할 자료 구조가 필요하고, 새로운 에지를 추가할 때 사이클이 발생하는지를 판단하는 기능이 필요하다. 이 문제는 디스조인트-셋 자료 구조를 사용하여 해결할 수 있다.

# 2023.08.08

# copy_jpg (using c style file input-output)

C 언어의 함수인 fopen_s를 사용하여 jpg파일을 복사하는 코드이다.

# 2023.08.09

# Linux File-System upgrade version
이전에 공부했던 N-항 트리를 이용한 리눅스 파일 시스템에서 부모 노드의 주소를 저장하여 이전 노드로 디렉토리를 움직일 수 있다. 
또한 현재 노드가 소유한 모든 디렉토리를 보여주는 all기능도 추가했다.

# Graph Coloring

그래프 컬러링은 실생활의 다양한 문제에 적용할 수 있다. 택시 예약 스케줄 작성, 스도쿠 퍼즐 풀기, 시험 시간표 작성 등 그래프로 모델링한 후 컬러링 문제 형태로 해결할 수 있다. 그러나 그래프 컬러링에 필요한 최소 개수의 색상 수를 찾는 것은 NP-완전 문제로 알려져 있다. 다만 문제를 조금 변경함으로써 시간 복잡도를 크게 변경할 수 있다.

스도쿠 문제는 다음과 같이 해결할 수 있다. 

1.각각의 셀을 그래프 정점으로 표현한다.

2.같은 행, 같은 열, 3*3 블록 안에 있는 모든 정점끼리 에지를 연결한다.

3.생성된 그래프 G에 대해 그래프 컬러링을 수행하면 입력 스도쿠 퍼즐의 해답을 구할 수 있다.

그래프 컬러링의 평가는 얼마나 적은 수의 색상을 사용했는가에 의해 결정된다. 가능한 적은 수의 색상을 사용하는 최적의 그래프 컬러링 방법 찾기는 
NP-완전 문제이지만, 그리디 방식이 유용한 근사치를 제공하곤 한다. 예를 들어 컴파일러를 설계할 경우, 컴파일하는 프로그램의 변수에 CPU 레지스터를 할당하기 위해 그래프 컬러링이 사용된다. 몇몇 휴리스틱 방법과 함께 그리디 방식의 컬러링 알고리즘을 사용하면 “충분히 괜찮은” 솔루션을 얻을 수 있으며, 이러한 방식은 컴파일러의 빠른 동작이 필요한 상황에서 바람직하다.

휴리스틱(heuristic) 방식은 문제를 해결하는데 있어서 직관적인 접근법을 의미한다. 이 방식은 완전하거나 최적의 해답을 찾는 것이 어렵거나 시간이 너무 많이 걸리는 복잡한 문제에 대해, '충분히 좋은' 해결책을 빠르게 찾아내는 데 사용된다.

휴리스틱 방식의 핵심 아이디어는 모든 가능한 해결책을 탐색하는 대신, 경험적인 규칙, 지식, 추정 등을 활용하여 탐색 과정을 단축하고 결과를 빠르게 도출하는 것이다. 예를 들어, 경로 탐색 알고리즘에서 A* 알고리즘이 휴리스틱 함수를 사용하여 목적지에 도달할 가장 유망한 경로를 우선적으로 탐색한다.

그러나 휴리스틱 방식은 '최선'의 해답이 아니라 '충분히 좋은' 해답을 제공한다는 점에서 한계가 있다. 즉, 효율성과 정확성 사이에 일종의 트레이드오프(trade-off)가 존재한다. 때문에 언제 휴리스틱 방법론을 사용할지 결정하기 위해서는 해당 문제의 세부 사항과 요구사항 등 다양한 요소들을 고려해야 한다.

# Normal_Tree (색다른 버전의 트리)

이전에 공부했던 Tree와 살짝 다른 구조를 가지고 있다.

# 2023.08.21

# BehaviorTree

언리얼 엔진의 BehaviorTree를 간단하게 구현한 예제이다. Selector, Sequence, Decorator, ActionNode 등이 있고 간단한 처리가 가능하다. 

N항 트리 구조를 사용했다.

# DungeonGenerator

N항 트리를 사용한 리눅스 파일 시스템 코드를 변형하여 TXT_RPG에 사용할 DungeonGenerator를 구성했다. 

# Welsh-Powell algorithm (웰시 포웰 알고리즘 - 그래프 컬러링)

앞서 살펴본 그래프 컬러링의 성능을 조금 향상시키는 방법이 있다. 차수가 높은 정점부터 차례대로 그래프 컬러링을 수행하는 것이다. 이를 웰시 포웰 알고리즘이라고 한다. 

1.모든 정점을 차수에 대한 내림차순으로 정렬하고 배열에 저장한다. 

2.정렬된 배열에서 색상이 지정되지 않은 첫 번째 정점을 선택하고, 이 정점과 연결된 모든 정점을 조사하여 아직 사용되지 않은 색상을 해당 정점에 지정한다. 이 색상을 C라고 지정한다. 

3.정렬된 배열에서 색상이 지정되지 않은 정점을 모두 찾고, 만약 이 정점의 이웃이 C 색상을 가지고 있지 않다면 해당 정점에 C를 부여한다.

4.배열에 색상이 지정되지 않은 정점이 남아 있다면 2단계로 이동한다. 남아 있는 정점이 없다면 종료한다. 이때까지 정점에 지정된 색상이 최종 결과다.

차수는 정점에서 연결된 선의 개수이다.

<구현 솔루션>

1.먼저 에지를 표현하는 Edge 구조체와 에지 리스트를 사용하여 그래프 구조를 표현하는 Graph클래스를 작성해야 한다. 

2.웰시 포웰 그래프 컬러링 알고리즘을 구현한 함수를 작성한다. 이 함수는 각 정점의 색상을 벡터로 반환하도록 한다. 이 벡터의 I번째 원소는 I번째에 해당하는 정점의 색상을 나타낸다. 

일반적인 그래프 컬러링 알고리즘보다 성능이 좋다. 이유는 정점의 차수를 고려하지 않고 차례대로 색깔을 검사하는 것 보다 차수가 큰 정점부터 색깔을 조사하는 것이 더 효율적이기
때문이다.

# BFS(Breadth_First_Search) 너비 우선 탐색

그래프에서 너비 우선 탐색은 시작 정점을 경계에 추가하는 것으로 시작한다. 경계는 이전에 방문했던 정점들에 의해 구성된다. 그리고 현재 경계에 인접한 정점을 반복적으로 탐색한다.

BFS는 모든 정점에 대해 자식 정점을 손자 정점보다 먼저 방문한다는 점이 중요한 특징이다. BFS를 구현할 경우, 보통 경계를 별도의 자료 구조를 만들어서 명시적으로 사용하지는 않는다. 대신 정점 ID를 큐에 저장하여 시작 정점과 가까운 정점을 멀리 있는 정점보다 먼저 방문할 수 있도록 구현한다.

BFS의 시간 복잡도는 O(V+E)이다. V는 정점의 개수이고, E는 에지의 개수이다.

# DFS(Depth_First_Search) 깊이 우선 탐색

너비 우선 탐색이 시작 정점에서 시작하여 점차 탐색 범위를 넓혀 나가는 방식이라면, 깊이 우선 탐색은 시작 정점에서 시작하여 특별 경로를 따라 가능한 멀리 있는 정점을 재귀적으로 먼저 방문하는 방식이다. 그리고 더 방문할 정점이 없어지면 다른 경로를 찾아 다시 멀어지는 방향으로 탐색을 반복한다. 이러한 그래프 탐색 방법을 백트래킹이라고 한다. DFS는 큐 대신 스택을 사용한다. 스택은 후입선출 속성을 가지고 있기 때문에 현재 정점과 인접한 정점들을 재귀적으로 이동하면서 방문할 때 사용하기에 적합한 자료 구조이다.

BFS와 DFS의 시간 복잡도는 모두 O(V+E)이다. 그러나 두 알고리즘에는 몇 가지 큰 차이가 있다. 다음은 BFS와 DFS의 두드러진 차이점과 적합한 사용 시나리오를 정리한 것이다. 

*BFS는 시작 정점에서 가까운 정점을 찾는 데 적합하고, DFS는 대체로 시작 정점에서 멀리 있는 정점을 찾을 때 적합하다.

*BFS에서 특정 정점을 방문할 경우, 시작 정점에서 해당 정점까지의 최단 거리 경로가 보장된다. 그러나 DFS는 최단 경로를 보장하지 않는다. 이러한 속성 때문에 단일-시작 또는 다중-시작 최단 경로 알고리즘이 BFS 알고리즘을 조금 변경하여 사용하고 있다.

*BFS는 현재 경계에 인접한 모든 정점을 방문하므로 BFS에 의해 생성된 검색 트리는 짧고 넓은 편이며, 많은 메모리를 필요로 한다. 반면에 DFS에 의해 생성된 검색 트리는 길고 좁은 편이며 상대적으로 적은 메모리를 필요로 한다.

# 2023.08.22

# Bipartite_Graph discrimination (이분 그래프 판별 코드)

이분 그래프는 정점을 두 개의 집합으로 나눌 수 있는 그래프이다. 이때 그래프의 모든 에지는 서로 다른 집합에 속한 정점끼리 연결되어야 한다. 이분 그래프는 실생활의 여러 문제를 모델링할 수 있다. 예를 들어 학생 목록과 수업 목록이 있을 때, 학생들이 어떤 수업을 수강하고 있는지를 이분 그래프로 표현할 수 있다. 즉, 학생 정점에서 수업 과목 정점으로 에지가 연결되어 있으면 해당 학생이 이 수업을 수강하고 있다는 의미이다. 학생에서 학생으로, 또는 수업에서 다른 수업으로 연결되는 에지는 있을 수 없다. 따라서 이분 그래프로 표현하기 적합하다.

특정 학생이 신청한 두 개의 수업이 같은 시간대에 중복되지 않도록 수강 계획을 만드는 데 사용할 수 있다. 예를 들어 유미가 수학과 영어 과목을 수강했다면 두 수업이 같은 시간대에 진행되면 안된다. 수업 시간표 작성 시 이러한 충돌을 최소화하는 작업은 그래프에서 최대 유량 문제를 풀어서 달성할 수 있다. 최대 유량 문제에 대해서는 몇 가지 표준 알고리즘이 알려져 있다. 포드-풀커슨 알고리즘, 디닉 알고리즘, 푸시-리레이블 알고리즘이 그 예이다. 그러나 이들 알고리즘은 꽤 복잡하여 지금은 다루지 않는다.

넷플릭스나 유튜브같은 대형 비디오 스트리밍 플랫폼에서 제공되는 영화 목록과 시청자 사이의 관계도 이분 그래프를 사용하여 모델링할 수 있다. 즉, 사용자가 특정 영화를 시청했다면 에지를 연결하는 방식으로 사용자의 시청 기록을 관리할 수 있다.

이분 그래프에 대해 흥미로운 사실은 최대 매칭 또는 최소 정점 커버 문제처럼 일반 그래프에서는 NP-완전인 문제들이 이분 그래프에서는 다항시간으로 풀 수 있다는 사실이다. 따라서 주어진 그래프가 이분인지 아닌지를 알아내는 것은 매우 중요하다. 

다음은 주어진 그래프가 이분 그래프인지 확인하는 c++프로그램의 아이디어이다. 이분 그래프를 판별하는 알고리즘은 DFS를 조금 변형하여 만들 수 있다.

1. 1번 정점부터 DFS를 시작한다고 가정한다. 그러므로 1번 정점을 스택에 추가한다.

2.만약 스택에 방문하지 않은 정점이 남아 있으면 스택에서 정점을 하나 꺼내고 이를 현재 정점으로 설정한다.

3.이전 정점에 할당된 색상이 ‘검은색’이면, 현재 정점에 ‘빨간색’을 할당한다. 반대로 이전 정점에 할당된 색상이 ‘빨간색’이면 현재 정점에 ‘검은색’을 할당한다.

4.현재 정점과 인접한 정점들 중에서 아직 방문하지 않은 정점들을 스택에 넣고, 현재 정점을 방문한 것으로 설정한다.

5.모든 정점에 색상이 지정될 때까지 2~4단계를 반복한다. 알고리즘 종료 시 모든 정점에 색상이 칠해져 있다면 이 그래프는 이분 그래프이다.

6.만약 탐색을 진행하다가 만나게 된 정점이 이미 방문한 정점이고, 이 정점의 색상이 현재 할당할 색상과 다른 색상이면, 알고리즘을 종료하고, 해당 그래프가 이분 그래프가 아니라고 판별한다.

즉 이분 그래프가 주어졌다면 두 집합을 번갈아가며 다른 색으로 모두 칠할 수 있기에 이분 그래프로 판별하고, 만약 같은 색상으로 할당된 인접한 정점을 만나면 이분 그래프가 아니라고 판별한다.

# Prim MST Algorithm (프림 최소 신장 트리)

MST 문제를 다시 정의해보면 “정점 집합 V와 가중치를 갖는 에지 집합 E로 구성된 그래프 G=<V,E>가 주어질 때 모든 정점을 연결하고 연결된 에지의 가중치 합이 최소인 트리 T를 구한다.”

크루스칼 알고리즘은 그래프의 모든 에지를 최소 힙에 추가하고, 사이클을 만들지 않는 최소 가중치의 에지를 이용하여 MST를 구성한다.

프림 알고리즘은 BFS의 동작 방식과 유사하다. 프림 알고리즘은 먼저 시작 정점을 이용하여 경계를 구성한다. 경계는 이전에 방문했던 정점들에 의해 구성되며, 현재 경계에 인접한 정점을 반복적으로 탐색한다. 이때 프림 알고리즘은 경계를 관통하는 에지 중에서 가장 가중치가 작은 에지를 선택하고, 이 에지에 연결된 정점을 방문한다. 

프림 알고리즘을 구현하려면 그래프의 각 정점에 경계로부터의 거리(distance) 정보를 기록해야 한다.

1.모든 정점의 거리 값을 무한대로 초기화한다. 시작 정점에서 자기 자신까지의 거리는 0이므로 시작 정점의 거리 값은 0으로 설정한다. 그리고 모든 거리 값을 최소 힙 H에 추가한다.

2.최소 힙 H로부터 정점을 하나 꺼낸다. 이 정점을 U라고 하면, 정점 U는 경계에서 가장 가까이 있는 정점이다. 이 정점을 포함하도록 경계를 새로 설정한다. 

3.U와 인접한 모든 정점 V에 대해 만약 V의 거리 값이(U,V)의 에지 가중치보다 크면 V의 거리 값을 (U,V)의 에지 가중치로 설정한다. 처음에는 거리 값이 모두 무한대이기 때문에 시작 정점의 인접 정점들의 거리 값이 가중치로 초기화된다. 이 과정을 정점 U에 안착(settle)했다고 한다. 

4.방문하지 않은 정점이 남아 있다면 2단계로 이동한다.

5.모든 정점에 대해 안착한 후 최종 MST가 생성된다.

프림 알고리즘(Prim's Algorithm)은 최소 비용 신장 트리(Minimum Spanning Tree)를 찾는 그리디 알고리즘 중 하나이다. 최소 비용 신장 트리란 그래프 내의 모든 정점을 포함하면서 간선의 가중치 합이 최소인 트리를 말한다. 이 알고리즘에서 거리 값이 사용되는 이유는 다음과 같다.

프림 알고리즘의 목적은 주어진 연결 그래프에서 최소 비용 신장 트리를 구성하는 것이다. 알고리즘이 진행되면서 트리가 점진적으로 확장되며, 트리 내의 정점들과 트리 밖의 정점들 사이에 새로운 간선을 연결하는 방식으로 진행된다. 이때, 선택되지 않은 정점들 중에서 최소 비용의 간선을 선택하여 트리에 추가하는 것이 핵심적인 아이디어이다.

거리 값이 사용되는 이유는 다음과 같다:

정점의 선택: 알고리즘은 현재 트리에 속한 정점과 트리에 속하지 않은 정점 간의 간선 중 가장 작은 가중치를 가진 간선을 선택하여 트리에 연결한다. 이때, 간선의 가중치를 거리 값으로 볼 수 있다. 가중치가 작을수록 두 정점 간의 거리가 짧다고 볼 수 있다.

트리 내 간선의 갱신: 이미 트리에 속한 정점과 트리에 속하지 않은 정점을 연결하는 간선 중에서 더 작은 가중치를 가진 간선이 나타날 수 있다. 이 경우, 새로운 간선으로 갱신하여 더 작은 거리 값을 사용하게 된다.

그래프 내에서의 최소 거리: 프림 알고리즘은 선택되지 않은 정점들 중에서 최소 비용의 간선을 찾아 트리에 추가한다. 이를 통해 최소 비용 신장 트리가 생성되는데, 이는 그래프 내의 정점들 간의 최소 거리를 고려한 결과라고 볼 수 있다.

종합적으로, 프림 알고리즘에서 거리 값은 정점 간의 연결을 결정하고 최소 비용 신장 트리를 형성하는 데 사용되는 중요한 개념이다.

# 2023.08.23

# Dijkstra Algorithm (최소 비용 경로)

“주어진 그래프 G=<V,E>가 있다. 여기서 V는 정점의 집합이고, E는 에지의 집합이다. 각각의 에지는 가중치를 가지고 있다. 시작 정점과 목적 정점이 주어질 때, 시작 정점에서 목적 정점까지 이어지는 최소 비용 경로를 구하시오.”

다익스트라 알고리즘은 음수 가중치가 없는 그래프에서 동작하는 최단 경로 탐색 알고리즘으로 프림의 MST 알고리즘을 약간 변형한 형태이다. 다익스트라 알고리즘이 프림 알고리즘과 다른 두 가지 차이점은 다음과 같다.

*프림 알고리즘은 경계로부터 최소 거리를 정점의 거리 값으로 설정하지만, 다익스트라 알고리즘은 시작 정점으로부터 각 정점까지의 전체 거리를 사용한다. 

*다익스트라 알고리즘은 목적 정점이 나타나면 종료하지만 프림 알고리즘은 모든 정점을 방문해야 종료한다.

다익스트라 알고리즘의 동작은 다음과 같다.

1.모든 정점의 거리 값을 무한대로 초기화한다. 시작 정점에서 자기 자신까지의 거리는 0이므로 시작 정점의 거리 값은 0으로 설정한다. 그리고 모든 거리 값을 최소 힙 H에 추가한다.

2.최소 힙 H로부터 정점을 하나 꺼낸다. 이 정점을 U라고 하면, 정점 U는 시작 정점에서 가장 가까운 정점이다. 만약 U가 목적 정점이면 최단 경로를 찾은 것이므로 알고리즘을 종료한다.

3.U와 인접한 모든 정점 V에 대해 만약 V의 거리 값이 (U의 거리값+ (U,V)의 가중치)보다 크면 V까지 다다르는 더 짧은 경로를 찾은 것으로 볼 수 있다. 그러므로 V의 거리 값을 (U의 거리 값+(U,V)에지 가중치)값으로 설정한다. 이러한 과정을 정점 U에 안착했다고 한다.

4.방문하지 않은 정점이 남아 있다면 2단계로 이동한다. 

5.최소 힙 H로부터 꺼낸 정점이 목적 정점이면 알고리즘을 종료한다.

다익스트라 알고리즘을 피보나치 최소 힙을 사용하여 구현한 시간 복잡도는 
O(E+VlogV)이다.

# USA_NY_shortest_path (다익스트라 알고리즘을 이용한 뉴욕 도로망 최소 비용 거리)

다익스트라 알고리즘을 사용하여 뉴욕시 도로망에서 최단 거리 경로를 찾는 프로그램을 만들어 본다. 이번 실습 문제에서 사용할 도로망 그래프는 264,326개의 정점과 733,846개의 방향 에지로 구성되고, 에지 가중치는 두 정점 사이의 유클리디언 거리로 정의된다. 

# Bellman_Ford_Algorithm(벨만 포드 알고리즘)

음수 가중치가 있는 그래프를 다룰 때에는 벨만-포드 알고리즘을 사용할 수 있다. 이 방법은 그래프의 모든 에지에 대해 다익스트라의 그리디 선택 방법을 
(V-1)번 반복하여 점진적으로 최단 거리를 찾는다. 여기서 V는 정점의 개수를 나타낸다. 벨만-포드 알고리즘은 다익스트라 알고리즘보다 높은 점근적 시간 복잡도를 가지지만, 다익스트라 알고리즘이 잘못 해석할 수 있는 그래프에 대해서도 정확한 결과를 제공한다.

# Greedy_Robot using Bellman-Ford Algorithm

장애물 코스에서 효율적인 경로를 찾는 길 찾기 로봇을 개발하려고 한다. 테스트를 위해 체스판 같은 정사각형 격자 형태의 코스를 몇 개 만들었다. 로봇은 어떤 장애물이든 통과할 수 있지만, 이 경우 많은 전력을 소모하게 된다. 로봇은 격자의 좌측 상단에서 출발하고, 동서남북 네 방향으로 이동할 수 있다. 로봇이 목적지에 도착할 때 남아있는 에너지가 최대가 되도록 경로를 선택하는 알고리즘을 구현해야 한다.

이러한 탐색을 하려면 많은 에너지를 필요로 하기 때문에 코스 곳곳에 충전소를 설치하였고, 로봇은 여기서 스스로 충전할 수 있다. 그러나 이 로봇은 꽤나 욕심이 많아서 충전소를 재방문할 수 있는 경로가 있다면 몇 번이고 다시 방문하여 충전을 반복하게 되고, 결국에는 과충전되어 폭발할 수 있다. 이 때문에 로봇이 충전소에 재방문할 것인지를 예측하여 과충전 같은 문제를 미연에 방지해야 한다.

*입력

첫 번째 줄은 정수 하나가 있으며, 이를 N이라고 한다. N은 코스의 가로 및 세로 크기를 나타낸다. 

그 다음에 나타나는 (N^2-1)줄은 방향을 가리키는 directions 문자열과 전력 소모량을 나타내는 power 정수 값으로 구성된다. 각각의 줄은 격자 모양 코스의 맨 처음 해의 왼쪽부터 오른쪽 방향으로 나타나는 셀(격자)의 정보를 나타낸다. 예를 들어 3x3 크기의 격자 코스인 경우, [0,0]->[0,1]->[0,2]->[1,0]->
[1,1]->[1,2]->[2,0]->[2,1] 순서로 셀 정보가 나타난다. 맨 마지막 셀은 목적지 이므로 셀 이동 정보가 없다.

direction문자열은 {'N','S','E','W'} 네 문자 중에서 0~3개를 이용하여 구성된다. 이 문자열은 로봇이 특정 지점에서 방문할 수 있는 셀 방향을 나타낸다. 즉 'N‘은 북쪽, ’S'는 남쪽, ‘E'는 동쪽, ’W'는 서쪽을 의미한다. 예를 들어 directions 문자열이 "SW"이면 로봇이 남쪽 또는 서쪽으로 이동할 수 있다. power는 셀을 이동할 때 필요한 전력 소비량을 나타낸다. p가 양수이면 현재 셀에 충전소가 있음을 나타낸다.

*출력

로봇이 코스의 우측 하단 셀에 도달할 때 가질 수 있는 최대 전력량을 출력하되, 시작시 전력량을 기준으로 상대적인 전력량을 출력한다. 예를 들어 로봇이 코스를 시작시 전력량보다 10만큼 더 많은 상태로 빠져나올 수 있다면 10을 출력한다. 만약 시작 시 전력량보다 10만큼 적은 상태로 빠져나올 수 있다면
-10을 출력한다. 

만약 탐색중에 로봇이 폭발할 경우 “탐색 중단” 문자열을 출력한다.

*문제 해결 가이드라인

벨만-포드 알고리즘에서 음수 사이클을 감지하는 알고리즘 이상의 것은 필요하지 않다.

입력을 해석하여 그래프를 구성하는 기능이 필요하다.

반드시 2차원 격자 형태의 코스를 만들 필요는 없다.

벨만-포드 알고리즘은 다익스트라 알고리즘이 제대로 작동하지 않는 그래프에 대해서도 정확한 결과를 제공하기 때문에 더 광범위하게 사용할 수 있다. 그러나 주어진 그래프가 음수 에지 가중치를 가지고 있지 않다면 그리디 방식을 사용하는 다익스트라 알고리즘이 더욱 효율적이다.

V번 이상의 반복에서 거리 값이 업데이트되는 경우에는 음의 사이클이 존재한다고 볼 수 있다. 각 반복마다 시작 정점부터 각 정점까지의 최단 경로에 최소 한 개 이상의 에지가 포함될 수
있기 때문에(최종 최단 거리가 아직 구해지지 않은 경우) 최대 V-1개의 에지가 경로에 포함될 수 있다. 따라서 V번 이상의 반복이 필요한 경우라면 V개 이상의 에지가 포함된다는 말인데
정점 개수보다 에지 개수가 많을 수는 없다. 따라서 중복 방문(사이클)이다.

# Johnson's Algorithm (벨만 포드와 다익스트라의 합성)

다익스트라 알고리즘과 벨만-포드 알고리즘의 효율성을 활용함과 동시에 음수 가중치를 갖는 그래프에 대해서도 올바른 결과를 생성할 수 있다. 존슨 알고리즘은 상당히 새로운 접근 방법을 사용한다. 이 알고리즘은 음수 가중치에 대한 다익스트라 알고리즘의 한계를 극복하기 위해 전체 에지 가중치를 음수가 아닌 형태로 변환한다. 이러한 작업은 벨만-포드 알고리즘과 적절한 수학 논리를 결합하여 이루어진다. 

존슨 알고리즘의 첫 번째 단계는 그래프에 새로운 ‘더미(dummy)' 정점을 추가하는 것이다. 그리고 이 더미 정점과 나머지 모든 정점 사이에 가중치가 0인 에지를 연결한다. 이후 벨만-포드 알고리즘을 이용하여 더미 정점과 나머지 정점들 사이의 최단 경로를 찾고, 나중에 사용하기 위해 각 정점까지의 최단 거리를 기록한다.

더미 정점 추가에 대해 좀 더 알아본다. 더미 정점과 나머지 모든 정점 사이에 가중치가 0인 에지를 연결했기 때문에 모든 최단 거리 값은 0보다 클 수 없다. 또한 그래프의 모든 정점에 대한 연결을 통해 거리 값이 모든 가능한 순회 경로에서 일정한 관계를 유지할 수 있으며 이로 인해 에지 가중치와 최단 거리의 합 연산이 간단해질 수 있다. 즉, 이동 경로상의 연속한 정점에 대해서 거리 값 연산이 서로 상쇄되어, 결국 전체 합은 첫 번째 정점과 마지막 정점의 거리 값 차와 같다.

존슨 알고리즘은 가중치를 다음 수식을 통해서 변환한다.

w(uv) = w(uv) + d[s,u] - d[s,v]

# Random_Graph_Generator (using Johnson's Algorithm)

임의의 회사에서 기술 면접에 사용하는 그래프 문제는 모든 정점 사이의 최단 경로 거리를 찾는 문제이다. 이때 사용하는 그래프는 방향성과 가중치가 있는 에지로 구성된다. 프로그램에 의해 생성된 그래프는 다음 항목을 만족해야 한다. 

*방향 그래프이어야 하며, 에지 가중치는 양수 또는 음수로 표현된다. 

*두 정점 사이에는 하나의 에지만 있으며, 특정 정점에서 나온 에지가 자기 자신으로 연결되는 셀프 에지는 없어야 한다.

*모든 정점에는 들어오거나 나가는 에지가 적어도 하나는 있어야 한다.

*에지 가중치의 절댓값은 100보다 작아야 한다.

그래프 생성 프로그램은 다음을 입력으로 받는다.

seed: 난수 발생기의 시드 값
iteration: 생성할 그래프의 개수
V:정점 개수
E:에지 개수

이 프로그램은 std::rand() 함수를 이용하여 에지를 생성하되, 두 정점 사이에 두 개 이상의 에지를 생성하면 안된다.

그래프 생성 순서는 다음과 같다.

1.입력으로 seed,iteration,V,E)값을 받는다.

2.난수 발생기의 시드 값으로 seed를 설정한다.

3. 다음 작업을 반복한다.

*i=0으로 설정

-rand 함수를 세 번 호출하여 시작 정점 source, 목표 정점 destination, 에지 가중치 w를 설정하고 이를 이용하여 에지를 생성한다.

-rand()함수로 다시 한 번 난수를 발생시키고, 이 값이 3으로 나누어 떨어지면 에지 가중치를 음수로 변환.

*만약 시작 정점과 목표 정점 사이에 이미 에지가 존재하면 다시 에지를 생성한다.

-에지 리스트에 edge(source,destination,weight)를 추가하고, I를 증가시킨다.

-만약 E개의 에지를 생성한 후 에지가 하나도 없는 정점이 남아 있다면 이 그래프는 유효하지 않은 것으로 판단.

만약 생성된 그래프가 유효하면 이제 그래프의 모든 정점 사이의 최단 경로를 찾아야 한다. 그리고 그래프의 각 정점에서 평균 최단 거리를 구하고자 한다. 정점의 평균 최단 거리는 해당 정점에서 출발하는 최단 경로의 거리 합을 도달 가능한 정점 개수로 나눈 값이다. 그래프 하나의 평균 거리는 모든 정점의 평균 최단 거리에 대한 평균으로 정의한다.

또한 가장 많은 흥미로운 그래프를 생성하는 값의 구성도 알아내려고 한다. 여기서 흥미로운 그래프란 그래프의 평균 거리가 가장 큰 에지 가중치의 절반보다 작은 경우를 의미한다. 그러므로 유효한 그래프 개수와 흥미로운 그래프 개수의 비율을 계산해서 출력해야 한다. 음수 가중치 사이클이 있는 그래프는 유효한 그래프이지만 흥미로운 그래프에는 포함되지 않는다.

입력

네 개의 정수 (seed,iteration,V,E)로 이루어진 한 줄

출력

출력은 두 줄로 구성된다. 첫 번째 줄은 “유효하지 않은 그래프 개수:” 문자열과 함께 유효하지 않은 그래프 개수를 출력한다. 두 번째 줄은 “흥미로운 그래프 생성 비율: ”문자열과 함께 (흥미로운 그래프 개수*100/유효한 그래프 개수)값을 출력한다. 이 값은 소수점 세 번째 자리에서 반올림하여 출력한다.

*문제해결 가이드라인

std::rand() 함수가 모든 환경에서 항상 동일한 값을 생성하지는 않는다. 제시된 난수 발생 코드를 참고한다.

# 2023.08.28

# Kosaraju Algorithm (strongly connected component)

<강한 연결 요소>

그래프 분류 방법중 가장 널리 사용되는 것은 방향 그래프와 무방향 그래프로 나누는 것이다. 무방향 그래프는 에지가 양방향으로 이동 가능하다고 간주한다.

다양한 채널 구독자 간의 공통점에 대한 통계를 작성해야 한다고 가정한다. 특정 채널을 구독하는 사람들과 해당 채널 소유주의 구독 정보 사이의 패턴을 발견하는데 관심이 많으며 이를 통해 타깃 광고 서비스를 어떻게 관리해야 하는지에 대해 분석하려고 한다.

구독하고 있는 채널 관계를 에지로 표현하면, 같은 채널을 구독하는 대규모 사용자 그룹이 여럿 있다 하더라도 각각의 구독 정보가 너무 다양하기 때문에 사용자 그룹 사이의 유사점을 찾기가 힘들다. 

방향 그래프의 특성으로 이러한 복잡한 문제를 해결할 수 있다. 방향 그래프에서는 한쪽 방향으로만 이동이 가능하기 때문에 특정 정점에 도달할 수 있는지 여부는 탐색을 어느 정점에서 시작했는지에 따라 다르게 결정된다. 주어진 그래프를 여러 개의 구역으로 나누되 같은 구역 안의 정점끼리는 서로 이동 가능한 경로를 갖도록 나눌 경우, 각 구역은 해당 그래프의 강한 연결 요소를 나타낸다.

<방향 그래프와 무방향 그래프에서 연결성>

무방향 그래프에서 연결 요소란 모든 정점이 서로 연결되어 있는 부분 그래프 중에서 최대 크기 부분 그래프 집합을 의미한다. 즉 하나의 구성 요소에 있는 두 정점은 상호 접근이 가능하다. 모든 정점이 연결되어 있는 그래프의 경우, 어느 정점에서 출발하든 모든 정점에 도달할 수 있으므로 이러한 그래프는 단일 연결 요소로 구성되어 있다고 할 수 있다. 상대적으로 특정 정점에서 다른 정점으로 이동할 수 없는 경우, 이러한 그래프는 연결이 끊어졋다고 할 수 있다.

이와 달리 강한 연결성은 방향 그래프에만 적용되는 특징이다.

무방향 그래프에서는 연결 요소(정점들이 연결된 부분 그래프)들이 서로 독립적이고 각 연결 요소의 정점들에서 다른 연결 요소의 정점으로 이동할 수 없다. 

반면에 강한 연결 요소는 그래프 내에서 다른 부분 그래프와 완전히 단절되어 있을 필요는 없다. 부분 그래프 사이에 경로가 존재할 수 있다. 즉 연결 요소 A,B,C가 있을 때 A는 B,C로 모두 이동할 수 있는 반면 B는 C로만 이동할 수 있고, C는 다른 연결 요소로는 이동할 수 없다. 이런 식으로 방향 그래프의 연결 요소는 이러한 형태를 지닌다. 각 강한 연결 요소끼리는 양방향으로 연결될 수 없다는 것이 특징이다. 

<코사라주 알고리즘>

그래프에서 강한 연결 요소를 찾는 가장 쉽고 널리 사용되는 방법으로 코사라주 알고리즘이 있다. 코사라주 알고리즘은 DFS를 두 번 수행하는 행태로 동작한다. 처음에는 입력 그래프 자체에 DFS를 수행하고, 두 번째에는 입력 그래프를 전치하여 DFS를 수행한다. 코사라주 알고리즘에서는 BFS로 수행할 수도 있다. 

그래프의 전치는 원본 그래프에서 시작 정점과 목표 정점이 서로 뒤바뀐 형태로, 각각의 에지 방향이 반대가 된다. 즉, 원본 그래프에 A정점에서 B정점으로 향하는 에지가 있다고 하자, 전치된 그래프에서는 B정점에서 A정점으로 향하는 에지가 있다.

코사라주 알고리즘의 첫 번째는 모든 정점 중에서 아직 방문한 적이 없는 정점에 대해 차례대로 DFS 순회를 진행하는 것이다. 각 정점에 대해 DFS를 수행할 때에는 먼저 해당 정점에 대해 방문 기록을 저장하고, 이후 이 정점과 인접한 정점 중에서 아직 방문하지 않은 정점을 재귀적으로 탐색한다. 인접한 정점을 모두 탐색한 후에는 현재 정점을 스택에 추가한 후 DFS를 종료한다.

원본 그래프에 대해 DFS 순회가 끝나면 이번에는 같은 작업을 전치 그래프에 대해 수행한다. 앞서 구축한 스택에서 정점을 하나씩 꺼내고, 이 정점을 아직 방문하지 않았다면 이 정점을 시작으로 DFS를 수행한다. 이때 각각의 DFS에서 만나는 정점들이 강한 연결 요소를 구성한다. 

코사라주 알고리즘은 그래프가 인접 리스트로 표현되어 있을 경우, O(V+E)형태의 선형 점근적 시간 복잡도를 갖기 때문에 효율적이다. 코사라주 알고리즘에서 인접 행렬을 사용하는 것은 좋지 않다. 왜냐하면 그래프 순회에서 각 정점의 이웃을 찾기 위해 상당한 양의 반복문이 필요하기 때문이다.

위 수식을 사용하면 telescope 속성을 사용할 수 있어 최종 수식이 짧아진다. 또한 모든 에지의 가중치를 0 이상의 값으로 변경할 수 있다.

벨만-포드 알고리즘은 d[s,u] + w(u,v) >= d[s,v]를 만족하기 때문에 변환된 가중치는 음수가 될 수 없다. d[s,v]가 0이기 때문이다. 

즉 원래의 최단 경로 순서는 그대로 유지한 채, 음이 아닌 가중치로 구성된 그래프가 만들어진다. 이제 새로운 가중치를 갖는 그래프의 각 정점에서 다익스트라 알고리즘을 적용하여 모든 정점 쌍 사이의 최단 거리를 구할 수 있다.

# Maze Teleportation Game

여러 개의 방으로 구성된 미로 안에 여러 명의 플레이어가 무작위로 배치되는 게임을 설계한다고 가정한다. 각 방에는 미로의 다른 방으로 이동할 수 있는 한 개 이상의 순간이동 장치가 있다. 각각의 순간이동 장치는 고유한 정수 값이 매겨져 있어서 플레이어가 순간이동장치를 사용하면 해당 값이 플레이어 점수에 더해진다. 각각의 플레이어는 모든 방을 한 번 이상 방문할 때까지 교대로 이동하고, 각 라운드가 끝났을 때 점수가 가장 낮은 플레이어가 승자가 된다. 

매 번 게임이 시작될 때마다 새로운 미로를 자동으로 생성하는 시스템을 개발했다. 그런데 자동 생성된 미로 중 일부에서 플레이어의 점수를 무한히 낮출 수 있는 이동 경로가 존재한다는 점을 알게 되었다. 또한 몇몇 플레이어는 시작 지점에 따라 점수 계산에 불이익을 받을 수 있다는 점도 발견했다. 무엇보다 플레이어가 미로의 특정 방을 방문할 수 없는 형태로 순간이동장치가 배치되기도 한다. 

생성된 미로가 유효하고 모든 플레이어에 공평한 형태인지를 확인하는 테스트 기능을 구현해야 한다. 먼저 미로에 플레이어 점수를 무한히 낮아지게 만들 수 있는 경로가 존재하는지 확인해야 한다. 만약 이러한 경로가 있다면 “유효하지 않은 미로”문자열을 출력해야 한다. 만약 방에 순간이동장치가 없는 경우에는 “고립된 방” 문자열을 출력한다.

또한 플레이어가 미로의 특정 부분에 갇히는 것을 방지하기 위해 미로의 다른 위치로 이동할 수 없는 방 그룹 정보도 출력해야 한다.

일단 실제 구현에서는 모든 방이 아니라 각각의 방에서 다른 방으로 이동할 때의 최저 점수를 구하도록 구현되어 있다.


[입력] 

*미로 안의 방 개수

*미로 안의 순간이동장치 개수

*시작 방, 목표 방, 각 순간이동장치에 지정할 점수

[출력]

프로그램은 먼저 플레이어의 점수를 무한대로 낮출 수 있는 경로가 존재하는지를 확인해야 한다. 이러한 경로가 존재하면, “유효하지 않은 미로” 문자열을 출력한다.

만약 미로가 유효하다면 각각의 방에서 다른 나머지 방으로 이동할 때 얻을 수 있는 최저 점수를 차례로 출력한다. 만약 특정 방에 순간이동장치가 없다면 “고립된 방” 문자열을 출력한다. 마지막으로 플레이어가 완전히 갇혀있게 되는 방 그룹, 즉 미로의 다른 부분으로 이동할 수 없는 방들의 번호를 출력한다.

[문제 해결 가이드라인]

관련 없는 정보로 인해 주의가 흐트러지지 않도록 한다. 실제적으로 무엇을 수행해야 하는지 자문한다.

미로에 점수를 무한히 낮출 수 있는 경로가 있는지를 판단하는 것은 다음과 같이 해석할 수 있다. 즉 미로를 가중 그래프로 표현하고, 여기에 음수 가중치사이클이 있는지를 판단하면 된다.

고립될 수 있는 경우가 어떤 경우인지를 생각해보라. 즉 강한 연결 요소에서 가장 마지막 연결 요소일 것이다. 따라서 강한 연결 요소가 있는지를 확인하면 될 것이다.

# 2023.08.29

# 적절한 방법을 선택하자. - Graph Algorithm

인접 리스트와 인접 행렬, 클래스와 단순 행렬, 벨만-포드 알고리즘과 존슨 알고리즘, BFS와 DFS등의 선택에서 어떤 것을 사용할 것인가는 데이터 특성과 우리의 선택에 달려 있다. 예를 들어 그래프의 모든 정점 사이의 최단 거리를 알아내고자 한다면 존슨 알고리즘을 사용하는 것이 가장 좋은 선택일 것이다.

그래프 이론과 구현 방법에 대한 이해를 높이는 방법은 다음과 같다.

1. 새로운 알고리즘을 구현할 때 복사&붙여넣기 사용을 지양해야 한다. 만약 내가 알고리즘 동작의 기본 원리를 이해하지 못하고 있다면 알고리즘을 잘못 사용할 가능성이 매우 높다. 만약 알고리즘이 원하는 방식으로 작동하더라도 그래프 구현은 주어진 상황에 매우 의존적이라는 점을 기억해야 한다. 알고리즘을 맹목적으로 사용하면 입력 매개변수가 조금 달라졌을 때 프로그램을 확장하기 어려울 수 있다.

2. 실전에서 새로운 기능을 추가할 때 추상적이거나 상황을 고려하지 않은 구현은 주의해야 한다. 검증 가능한 이론적인 데이터를 이용하여 알고리즘을 구현한 후, 실제 사용할 데이터에 맞게끔 소스코드를 수정해야 한다. 새로 배운 알고리즘을 어떻게 적용할 수 있을지를 자주 상상해보면 실제 업무에서 언제 어떻게 사용할 수 있는지에 대한 감을 얻을 수 있을 것이다.

*그래프를 구현하기에 앞서 다음 사항을 숙지해야 한다.

1. 기본 목적 및 해당 목적 달성을 위해 필요한 기능(즉, 그래프 표현 방법, 함수 입출력 형식,기능 확장성 등)

2. 주어진 문제와 연관된 정보를 나타내는데 필요한 가장 기본적인 구성 요소

이러한 핵심 사항들을 숙지하지 못한다면 실제 솔루션에 전혀 도움이 되지 않는 불필요한 데이터와 함수로 가득 찬, 복잡하고 지나치게 장황한 코드가 만들어질 수 있다. 실제 코드를 작성하기에 앞서 꼭 필요한 그래프 구성 요소를 계획하면 상당한 혼란과 지루한 리팩토링을 줄일 수 있다.

궁극적으로 그래프 프로그래밍에 대한 포괄적인 이해는 단순히 여러 알고리즘을 배우는 것 이상의 노력이 필요하다. 자명하지 않은 그래프 문제에 대해 웹 검색을 해보면 매우 복잡한 연구 분석, 다양한 접근 방식의 비교 평가, 합리적인 구현이 아직 발견되지 않은 추측에 의한 솔루션 등을 아주 많이 발견할 수 있을 것이다. 늘 그렇듯이 지속적인 연습은 프로그래밍 기술을 습득하는 가장 좋은 방법이다.

# 동적 계획법(Dynamic Programming)

동적 계획법(Dynamic programming)은 분할 정복 패러다임을 확장한 것으로, 특정 분류의 문제에 사용된다. 이전에 다루었던 그리디 알고리즘은 특정 상황에서는 상당히 효과적이지만, 그렇지 않은 경우에는 최적의 결과를 도출하지 못할 수 있다. 예를 들어 음수 가중치를 가진 그래프에서는 벨만-포드 알고리즘은 최적의 해를 찾을 수 있지만, 다익스트라 알고리즘은 그렇지 않다는 점을 바로 앞 장에서 설명했다. 앞서 언급한 기법으로 해결할 수 없는 문제 중에서 재귀적으로 표현할 수 있는 문제는 아마도 동적 계획법이 가장 적합할 수 있다.

다음은 동적 계획법이 자주 사용되는 경우이다.

*조합(특정 조건을 만족하는 시퀀스의 조합 또는 순열의 개수 구하기)

*문자열과 시퀀스(편집 거리, 최장 공통 부분 시퀀스, 최장 증가 부분 시퀀스 등)

*그래프(최단 경로 문제)

*머신 러닝(음성/얼굴 인식)


동적 계획법의 원리에 대해서 알아본다.

다음은 피보나치 수열이다

0 1 1 2 3 5 ...

이를 수식으로 표현하면 다음과 같다.

F(0)=0

F(1)=1

F(n)=F(n-1)+F(n-2) //이 수식은 수열의 재귀 관계를 표현한다.

이 수식으로부터 피보나치 수열이 재귀적인 관계를 가지고 있음을 알 수 있다. 이 수열의 처음 두 원소 F(0),F(1)은 기저 조건이라고 부르며, 이는 더 이상 재귀가 없어도 해를 구할 수 있는 지점을 나타낸다.


F5는 F4+F3과 같고,

	여기서 F4는 F3+F2와 같고

		여기서 F3은 F2+F1과 같고

			여기서 F2는 F1+F0과 같고,

				여기서 F1=1이고 F0=0이다.

			그리고 F1=1이다.

		그리고 F2는 F1+F0과 같고

			여기서 F1=1이고 F0=0이다.

	그리고 F3은 F2+F1과 같고

		여기서 F2는 F1+F0과 같고

			여기서 F1=1이고 F0=0이다.

		그리고 F1=1이다.

이와 같은 방식을 하향식 해법(top-down solution)이라고 부른다. 왜냐하면 전체 해결 방법을 트리 형태로 구성한 재귀 트리의 맨 꼭대기에서 시작하여 기저 조건에 닿을 때까지 아래쪽 가지로 이동하기 때문이다. 이러한 연산을 C++재귀 함수로 구현하면 다음과 같다.

int Fibonacci(int n)

{
	if(n<2)

		return n;

	return Fibonacci(n-1)+Fibonacci(n-2);

}

트리를 자세히 보면 해답을 찾기 위해 여러 개의 부분 문제 또는 중간 문제를 풀어야 한다는 점을 알 수 있고, 또한 이러한 부분 문제는 한 번 이상 나타난다는 점을 발견할 수 있다. 예를 들어 F2는 F4와 F3을 구하는 과정에서 중복해서 나타난다. 왜냐하면 F4=F3+F2이고 F3=F2+F1이기 때문이다. 그러므로 피보나치 수열은 중복되는 부분 문제라는 특성을 가지고 있다고 말할 수 있다. 이는 일반적인 분할 정복 문제와 동적 계획법 문제를 구분하는 특성 중 하나이다. 분할 정복 문제에서는 전체 문제가 독립적인 부분 문제로 나뉘는 경향이 있지만, 동적 계획법의 경우에는 같은 부분 문제가 반복적으로 나타난다.

또한 여러 부분 문제가 서로 완전히 동일하다는 것을 알 수 있다. 예를 들어 F2를 구해야 할 경우, 이것이 F4또는 F3 중에서 어느 것을 구하기 위해 필요한지에 관계없이 같은 방식의 연산을 수행하면 된다. 이를 최적 부분 구조라고 부르며, 이것이 동적 계획법 문제를 정의하는 두 번째 특성이다. 전체 문제에 대한 최적해야 부분 문제의 최적해의 조합으로 표현할 수 있을 최적 부분 구조를 갖는다고 표현한다.
어떤 문제를 동적 계획법으로 해결하려면 이 두 가지 속성을 만족해야 한다. 중복되는 부분 문제 특성으로 인해 문제의 복잡도가 입력이 증가함에 따라 기하급수적으로 증가하는 경향이 있지만 최적 부분 구조 속성을 활용하면 복잡도를 크게 줄일 수 있다. 동적 계획법에서는 본질적으로 반복 계산을 피하기 위해 이전에 해결한 부분 문제의 해답을 캐시에 저장하는 방식을 사용한다.


<메모이제이션: 하향식 접근 방법>

메모이제이션(memoization)은 메모를 한다는 의미이다. 메모이제이션을 사용하여 최적 부분 구조 특성을 갖는 피보나치 수열에 대해 하향식 해법을 재구성할 수 있다. 프로그램 로직은 이전과 같지만, 각 단계에서 부분 문제의 해답을 찾으면 이를 배열 구조의 캐시에 저장한다. 배열의 인덱스는 현재의 n값을 사용할 것이며 여기서 n은 피보나치 수열 문제 풀이 단계의 매개변수 집합 또는 상태(state)를 나타낸다. 함수 F(n)이 호출될 때마다 먼저 F(n)의 상태가 이미 캐시에 저장되어 있는지를 확인한다. 만약 캐시에 값이 저장되어 있다면 단순히 이 값을 반환한다.

const int UNKNOWN=-1;

const int MAX_SIZE = 100;

vector<int> memo(MAX_SIZE,UNKNOWN);

int Fibonacci(int n)

{

	if(n<2)

		return n;

	if(memo[n] != UNKNOWN)

		return memo[n];


	int result = Fibonacci(n-1)+Fibonacci(n-2);

	memo[n] = result;

	return result;

}

이러한 방식을 통해 상당히 많은 중복 작업을 제거할 수 있다. 이처럼 하향식 방식에서 부분 문제의 해를 캐시에 넣어 사용하는 기술을 메모이제이션이라고 하며, 이 방법은 모든 동적 계획법 문제에 적용할 수 있다. 이때 다음 조건을 만족한다고 가정한다.

1. 고유한 특성은 유지하면서 서로 다른 상태의 유사성을 활용하는 캐시 사용 방식을 고안할 수 있다.

2. 사용 가능한 스택 공간을 초과하기 전에 필요한 모든 부분 문제의 해답을 누적할 수 있다.

첫 번째 항목은 부분 문제 해법을 캐시에 인덱싱하여 저장하는 방법이 유효하고 유용해야 한다는 점을 의미한다. 캐시 사용 방법이 유효하려면 같은 의미의 부분 문제 해법을 정확하게 일치시켜 저장해야 한다. 또한 캐시 사용 방법이 유용하려면 너무 특정 상태에만 치우치게 동작하면 안된다. 예를 들어 모든 부분 문제가 같은 위치의 캐시를 참조한다면 

if(memo[KEY] != UNKNOWN)와 같은 조건에 걸리는 경우가 거의 없을 것이다.

두 번째 항목은 스택 오버플로우가 발생할 가능성에 관한 것으로, 이는 너무 많은 재귀 함수 호출을 필요로 하는 하향식 접근 방법에서 근본적으로 발생하는 문제이다. 스택 오버플로는 프로그램이 정해진 호출 스택 메모리보다 많은 메모리를 사용할 때 발생한다. 주어진 문제가 재귀 호출을너무 많이 필요로 할 경우 메모이제이션을 사용하지 못할 수도 있다. 늘 그렇듯이, 어떤 방법을 사용할 것인지를 선택하기에 앞서 주어진 문제의 잠재적인 복잡도를 평가하는 작업은 꽤 유용하다,

동적 계획법 문제에서 메모이제이션은 상당히 괜찮은 최적화 방법이다. 그러나 많은 경우 더 나은 방법을 선택할 수 있으며, 이 방법에 대해서는 다음 절에서 자세히 살펴본다.

동적 계획법의 핵심은 메모이제이션과 반대 방식의 접근 방법인 타뷸레이션
(tabulation)이라고 할 수 있다. 사실 동적 계획법이라는 용어가 메모이제이션과 타뷸레이션 두 가지 모두에 적용되긴 하지만, 일반적으로는 타불레이션을 더 많이 의식하여 사용한다.
타뷸레이션은 기저 조건 해답부터 시작하여 모든 부분 문제에 대한 해답을 표에 저장한 후 재사용하는 방식이다. 타뷸레이션 방식은 각각의 부분 문제 상태를 재귀적으로 표현할 수 있어야 하기 때문에 메모이제이션보다 개념적으로 어렵게 느껴진다.

타불레이션을 이용하여 피보나치 수열을 계산하는 함수는 다음과 같이 작성할 수 있다.

int Fibonacci(int n)

{	

	vector<int> DP(n+1,0);

	DP[1]=1;

	for(int i=2;i<=n;++i)

	{

		DP[i]=DP[i-1]+DP[i-2];

	}

	return DP[n];
}

피보나치 예제는 상태가 1차원으로 표현되고 n이 1보다 큰 경우에 항상 F(n)=
F(n-1)+F(n-2) 수식 하나를 사용하기 때문에 매우 간단하다. 그러나 많은 동적 계획법 문제가 상태를 다차원으로 표현해야 하고, 상태 전환 방식을 여러 개의 조건식으로 표현해야 할 경우도 있다. 이러한 경우 현재 상태를 제대로 표현하려면 문제에 대한 포괄적인 이해와 상당한 창의력이 필요하다.

타뷸레이션 방식의 장점은 꽤 많다. 타뷸레이션 방식은 메모리 사용량 관점에서 매우 효율적이며, 또한 가능한 모든 상태를 기록하는 룩업 레이블을 생성할 수 있다. 그러므로 주어진 문제에 대해 임의의 여러 상태를 참조해야 하는 경우에는 타뷸레이션이 최선의 방법이 될 수 있다.

보통 메모이제이션으로 해결할 수 있는 모든 문제는 타뷸레이션 방식으로도 재구성할 수 있으며, 그 반대도 가능하다. 주어진 문제를 메모이제이션 방식으로 풀이해보면 이 문제를 타뷸레이션 방식으로 해결하기 위해 어떻게 접근해야 하는지에 대한 감을 얻을 수 있다.

# SubsetSub_Problem_BruteForce (Dynamic Programming)

디지털 금전등록기 로직을 구현해야 한다고 가정한다. 계산원이 고객에게 잔돈을 거슬러주어야 할 때, 현재 금전등록기에 남아 있는 동전을 조합하여 필요한 거스름돈을 만들 수 있는지를 화면에 표시하려고 한다. 예를 들어 제품이 7500원이고 고객이 10000원을 지불했다면 현재 금전 등록기에서 정확하게 
2500원의 거스름돈을 꺼낼 수 있는지를 표시해야 한다. 현재 금전 등록기에 1000원 지폐 다섯장과 500원 동전 네 개, 100원 동전 15개가 있다고 가정할 경우, 거스름돈 2500원을 만들기 위해 다음과 같은 방식을 조합할 수 있다.

1000원 지폐 2장, 500원 한 개

1000원 지폐 2장, 100원 5개 

1000원 지폐 1장, 500원 3개

...

위의 나열된 경우의 수를 살펴보면, 다소 직관적으로 모든 화폐 조합을 시도해보는 방법으로 해결할 수 있다. 그러나 만약 필요한 잔돈이 73270원이고, 현재 금전 등록기에 50000원권, 10000원권, 1000원권, 500원, 100원, 50원, 10원 동전들이 전체 100개가 들어있다면 어떨까? 이러한 경우 모든 경우의 수를 조합하는 것은 너무 복잡해지고, 실제로 구현하는 것이 비현실적이라고 생각할 수 있다. 이것이 바로 부분집합의 합 문제이다. 부분집합의 합 문제를 한 문장으로 표현하면 다음과 같다.

“음수가 아닌 정수로 이루어진 집합 S와 임의의 정수 x가 주어질 때, S의 부분집합 중에서 그 원소의 합이 x와 같은 부분집합이 존재하는가?”

예를 하나 들어본다.

S={13,79,45,29}

x=42 -> true(13+29)

x= 25 -> false

집합 S={13,79,45,29} 형태로 주어질 경우 총 16개의 부분집합을 추출할 수 있다.

전체 부분집합의 개수는 2^n임을 알 수 있다. n이 늘어날수록 전체 부분집합을 검토하는 것은 비효율적이다.


<동적 계획법 필요 조건 분석하기>

부분집합의 합과 같은 문제에 직면하게 되면 먼저 이 문제를 동적 계획법으로 해결할 수 있는지를 확인해야 한다. 일반적으로 주어진 문제가 다음 속성을 가지고 있다면 동적 계획법으로 해결할 수 있다.

*중복되는 부분 문제: 일반적인 분할 정복 기법과 마찬가지로, 최종해(final solution)은 여러 부분 문제 조합으로 표현될 수 있어야 한다. 그러나 분할 정복과는 달리 특정 부분 문제가 여러 번 발생할 수 있다.

*최적 부분 문제 구조: 주어진 문제에 대한 최적해(optimal solution)는 부분 문제의 최적해로부터 생성될 수 있다.

크기가 n인 부분집합은 크기가 n-1인 부분집합에 새로운 원소 하나를 추가하여 만들 수 있다. 이는 새로운 부분집합을 구성하기 위한 최적의 방법이며 크기가 0보다 큰 모든 부분집합에 적용된다. 그러므로 부분집합의 합 문제는 최적 부분 구조를 갖는다고 볼 수 있다. 또한 서로 다른 부분집합이 더 작은 크기의 부분집합으로부터 생성될 수 있다. 예를 들어 {13 79 45}와 {13 79 29}는 모두 {13 79}가 중복되어 들어가므로 중복되는 부분 문제 속성도 가지고 있다.

<기저 조건과 상태 정의하기>

주어진 문제가 동적 계획법 문제임을 확인했다면 이제 이 문제에서 상태(state)를 구성하기 위해 필요한 것이 무엇인지 파악해야 한다. 즉, 각 부분 문제를 다른 부분 문제와 다르다고 판단할 수 있는 기준을 찾아야 한다. 처음부터 동적 계획법 문제의 상태를 제대로 정의하여 해를 구할 수 있다면 매우 바람집하겠지만, 주어진 문제의 최적해가 어떻게 구성되는지에 대한 명확한 이해 없이 상태를 정의하는 것은 쉽지 않다. 그러므로 문제의 해를 구하기 위한 가장 직관적인 방법부터 구현해보는 것도 좋다. 여기서는 비교적 구현하기 쉬운 두 가지 방법으로 부분집합의 합 문제를 해결해보면서 이 문제의 기저 조건과 상태에 대해 알아본다.

동적 계획법에 대해 알아보면서 전수 조사, 백트래킹, 메모이제이션, 타뷸레이션이라는 네 가지 접근 방법을 고려할 것이다. 이들 네 가지 접근 방법은 모든 동적 계획법 문제에서 정확한 결과를 제공하지만, 처음 세 방법은 입력 크기가 증가함에 따라 그 한계가 금방 드러나게 된다. 그럼에도 이들 방법을 차례대로 구현해보면 다양한 동적 계획법 문제를 해결할 때 큰 효과를 볼 수 있다.

<전수 조사>

전수 조사 방법은 분명히 비효율적이지만 현재 다루고 있는 문제를 제대로 이해하는 데 도움이 된다. 전수 조사 방법을 구현하는 것은 동적 계획법의 문제의 해를 구하는 과정에서 필수적인 단계가 될 수 있으며, 여기에는 다음과 같은 이유가 있다.

*단순성

효율성에 대한 고려 없이 단순한 방법으로 문제의 해를 구하는 작업은 주어진 문제의 근본적인 속성을 이해하는 데 도움이 된다. 주어진 문제에 대한 충분한 이해 없이 복잡한 방법으로 접근하는 것보다 최대한 단순하게 접근하는 것이 문제의 본질을 이해하기 쉽다.

*정답 비교를 위한 수단: 몇몇 복잡한 동적 계획법 문제의 경우, 주어진 문제를 충분히 이해하게 되면 상당히 많은 재설계가 필요할 수 있다. 이 때문에 우리가 동적 계획법으로 구한 해답과 비교할 수 있는 정답을 가지고 있을 필요가 있다.

*부분 문제를 시각화하는 능력

전수 조사 방법은 가능한 모든 방법을 생성한 후, 문제의 조건을 만족하는 해를 찾는 방법이다. 이러한 방법은 올바른 해답이 형성되는 방식을 시각화하는 수단을 제공할 수 있다. 이를 이용하여 다른 풀이 방법에서 사용할 수 있는 필수 패턴을 찾을 수 있다.

# SubsetSum_Backtracking (for Optimization)

전수조사 방법에서는 검사하는 부분집합의 합이 target보다 큰 경우에도 계속해서 검사를 진행했다. 유효하지 않은 모든 경우를 제거하는 백트래킹 기법을 사용할 수 있다.

백트래킹 방법을 구현하려면 주어진 문제의 기저 조건과 재귀적 표현을 결정해야 하며, 이러한작업은 이후 동적 계획법을 적용할 때 도움이 된다. 이 장의 앞부분에서 정의했듯이, 기저 조건이란 재귀 함수에서 추가적인 재귀 호출을 진행하지 않고 해를 구할 수 있는 경우를 의미한다. 이해를 돕기 위해 팩토리얼을 계산하는 경우를 예로 들어보자.

정수 n의 팩토리얼은 n*(n-1)*(n-2)*... 수식으로 계산된다. 팩토리얼을 계산하는 C++함수를 다음과 같이 작성할 수 있다.

int Factorial(int n)

{

	//기저 조건 - 재귀 호출 멈추기

	if( n == 1 )

	{

		return 1;
	}
	
	//기저 조건을 만날 때까지 재귀 호출 수행

	return n*Factorial(n-1);

}

팩토리얼 계산에서는 n==1인 경우에 재귀 호출을 하지 않고 함수가 반환되므로 n==1인 경우가 기저 조건이 된다.

부분집합 합 문제에서는 다음과 같이 기저 조건을 정의할 수 있다.

-만약 현재 부분집합의 합이 target보다 크면 : False
-만약 집합의 끝에 도달한 경우 : False

기저 조건을 만들었으니 이제 상태 변화 방법을 정의해야 한다. 


*상태 변화 방식은 다음과 같다.

-집합 set의 I번째 원소 set[i]와 부분집합 ss에 대해:

	만약 ss의 합에 set[i]를 더한 결과가 target보다 작거나 같으면:

	(1) ss에 set[i]를 추가

	(2) I를 증가
	
	다음 상태 - > ( i=i+1, ss = ss U set[i]) (U는 합집합 기호)


	모든 경우에 대해:

	(1) ss에 set[i]를 추가하지 않음

	(2) I를 증가

	다음 상태 -> ( I = I + 1 ,ss = ss )


이제 다음 물음에 대해 생각을 해본다.

	*현재 상태를 표현하기 위해 필요한 최소 데이터는 얼마인가?

	*불필요한 정보를 제거하기 위해 앞서 설명한 논리를 어떻게 재구성할 것인가?

부분집합의 합 문제를 다시 생각해본다. 이 문제는 주어진 집합의 부분집합 중에서 그 합이 정수 target과 같은 부분집합이 있는지를 판별하는 것이 목적이다. 문제 정의에 의하면 풀이 과정에서 실제 부분집합이 어떻게 구성되는지는 나타낼 필요가 없고, 단지 그 부분집합의 합만 검사하면 된다. 그러므로 상태 변화 의사 코드를 다음과 같이 간결하게 변경할 수 있다.

-집합 set의 I번째 원소 set[i]와 부분집합의 합 sum에 대해:

	만약 sum에 set[i]를 더한 결과가 target보다 작거나 같으면:

	(1) sum에 set[i]를 더함

	(2) I증가

	다음 상태 -> ( I = I+1 , sum = sum + set[i] )


	모든 경우에 대해:

	(1) sum에 set[i]를 더하지 않음

	(2) I증가

	다음 상태 ->( I = I+1 , sum = sum)

이러한 의사 코드를 사용하면 중간 단계 상태를 sum과 I 두 개의 정수로 표현할 수 있다. 최악의 경우 2^n개로 구성될 수 있는 부분집합 배열을 사용하지 않아도 된다. 또한 문제 접근 방식을 target값부터 시작해서 매 단계마다 set[i] 값을 빼는 형태로 전환하면 target값을 가지고 다니지 않게끔 만들 수도 있다. 마지막 최적화 방법으로 함수 호출 전에 집합을 정렬함으로써 target값보다 값이 커지는 경우를 만나면 나머지 집합 원소는 고려하지 않도록 만들 수도 있다.

BruteForce 방식으로 풀었던 SubsetSum 문제를 Backtracking 방법을 사용한 최적화 방식(불필요한 재귀를 줄인)으로 작성해본다. 

결과를 보면 BruteForce 방법보다 BackTracking 방법이 1000배 빠른 것을 확인할 수 있다.

# 2023.08.30

# Memoization (dynamic-programming)

백트래킹 방법이 전수 조사 방법보다는 훨씬 우수하지만 여전히 최선의 방법은 아니다. 부분집합의 합 목표치가 매우 큰 경우에 대해 생각해보겠다. 만약 목표치가 입력 집합의 모든 원소 합보다 같거나 크다면 사전에 입력 집합의 원소 합을 미리 계산하여 목표치가 유효한 범위 안에 있는지를 검사할 수 있을 것이다. 그러나 목표 합이 입력 집합의 모든 원소 합보다 미세하게 작다면 알고리즘 전체를 실행하여 모든 가능한 경우를 확인해야 한다.

이러한 차이를 확인하기 위해 barcktracking 방식의 코드에 입력을 6799로 설정하고 실행해보라, 이 값은 입력 집합 set의 모든 원소 합보다 정확히 1 작은 값이다. 아마 이전 결과보다 350배 더 느린 시간이 기록될 것이다. 다행히 메모이제이션이라는 하향식 방법을 사용하기에 필요한 모든 정보를 이미 가지고 있다. 더군다나 메모이제이션을 구현하기 위해 기존에 사용했던 방법을 수정할 필요도 없다.

*캐시 사용하기

메모이제이션을 사용하는 데 있어 가장 중요한 것은 캐시를 어떻게 사용할 것인지를 결정하는 것이다. 메모이제이션을 위한 캐시는 다양한 방식으로 정의할 수 있지만, 일반적인 방법은 다음과 같다.

*정수 인덱스를 사용하는 일반 배열

*프로그래밍 언어에서 제공하는 해시 기능을 사용하여 상태를 문자열로 표현한 해시 테이블 또는 해시 맵

*자체적으로 생성한 해시 함수를 이용하여 상태를 표현한 해시 테이블 또는 해시 맵

-어떤 것을 사용할 지에 대한 일반적인 지침은 다음과 같다.

*정수 인덱스를 사용하는 배열과 벡터는 일반적으로 맵보다 빠르다. 맵은 이미 캐시가 존재하는지를 확인하기 위해 주어진 키에 해당하는 위치를 찾는 작업이 필요하기 때문이다.

*상태를 정수로 표현할 수 있다고 하더라도 그 값이 너무 크게 나타날 경우, 실제 필요한 메모리보다 훨씬 큰 크기의 배열이 필요할 수 있다. 따라서 비합리적이다. 이러한 경우에는 맵이 나을 수 있다.

*std::unordered_map과 같은 해시 테이블은 일반적인 맵/딕셔너리 구조보다 빠르게 키를 찾고 검색할 수 있다.(그러나 여전히 배열보다는 느리다)

*std::map은 키로 사용할 수 있는 자료형 측면에서 std::unorderd_map보다 훨씬 더 자유도가 높다. std::unordered_map은 기술적으로 동일한 기능을 제공할 수 있지만, 기본적으로 키로 사용할 수 없는 자료형에 대해서는 프로그래머가 직접 해싱 함수를 만들어야 한다.

map은 키를 기준으로 정렬하기 때문에 사용자 정의 자료형에 대해서 해싱 함수를 따로 정의하지 않아도 되지만, unorderd_map은 사용자 정의 자료형을 사용하려면 해싱 함수를 따로 정의해야 하기 때문에 map이 자료형에 대해서는 자유도가 높다.


*캐시 사용 방법은 다음을 만족해야 한다.

-유효성: 캐시의 키 값은 서로 다른 상태에 대해 충돌이 발생하지 않도록 표현해야 한다. 동일한 키 값에 대해 충돌이 발생하지 않아야 한다.

-유용성: 캐시 사용 방식이 너무 독특해서 캐시에 저장된 값을 참조하는 경우가 아예 발생하지 않는다면 아무 의미가 없다.

부분집합의 합 문제에서 부분집합의 합을 상태로 사용할 경우, 특정 sum값을 갖는 상태에서 목표치를 찾지 못한다는 것이 같은 sum값을 갖는 다른 상태에서도 목표치를 찾지 못한다고 잘못 인식할 수 있다. 즉 

if( memo[sum] != UNKNOWN )
	
	return memo[sum];

형태의 코드를 사용하면 문제가 발생할 수 있다. 이는 같은 sum값에 도달할 수 있는 여러 가지 경우의 수가 있다는 사실을 고려하지 못해서 발생하는 잘못된 캐시 사용방법이다. 다음 예를 살펴본다.

{ 1 5 6 2 3 9 }

부분집합 { 1 5 }의 합 = 6

부분집합 { 6 }의 합 = 6

부분집합 { 1 2 3 }의 합 = 6

위 예에서 부분집합의 합 목표치가 8이라고 가정한다. 만약 세 번째 경우를 먼저 만나게 되면 memo[6]은 false로 반환할 것이다. 

그러나 첫 번째와 두 번째 경우에 대해서는 원소 2를 추가하여 8을 만들 수 있으므로 false를 반환하는 것이 잘못되었음을 알 수 있다.

즉 sum이 6이 되는 경우의 수가 많은데 그 중에서 2를 추가하여 8을 만들 수 있는 경우가 있음에도 불구하고 { 1 2 3 }을 먼저 만났을 때 sum이 6인 상태에서는 8을 만들 수 없다고 판단할 수 있다는 것이다.

잘못된 메모이제이션 방법의 또 다른 예는 부분집합 구성에 사용된 원소의 모든 인덱스를 키로 사용하는 것이다. 이 경우는 모든 상태가 고유한 형태의 키로 구성되고, 그 결과 같은 부분 문제에 의해 캐시가 참조되는 경우가 발생하지 않기 때문이다.

만약 구상한 캐시 사용 방식의 유효성을 알고 싶다면, 카운터 변수를 하나 만들고 캐시 참조가 발생할 때마다 카운터 변수 값을 하나씩 증가시킨다. 만약 해답이 구해진 상태에서도 값이 0이거나 또는 고려해야 할 상태 개수에 비해 매우 낮은 값이라면 우리의 캐시 사용 방법은 개선이 필요하다고 결론지을 수 있다.

연습 문제의 실행 결과를 앞선 2가지 방법과 비교하면 극적으로 최적화되어 있음을 알 수 있다.

# 2023.08.31

# SubsetSum using Tabulation (dynamic programming)

지금까지 부분집합의 합 문제를 해결하기 위한 세 가지 알고리즘을 구현해보았으며, 각각의 방법은 이전 방법에 비해 성능이 크게 개선되었다. 그러나 주어진 집합에 대해 가능한 모든 부분집합의 합 목록을 얻고 싶다고 가정한다. 공집합부터 전체 집합의 총합까지, 각각의 부분집합의 합을 구하기 위해 알고리즘을 반복적으로 실행해야 한다. 이러한 경우에는 타뷸레이션이 효과적이다.

이와 같은 문제에서 표를 사용하는 형태의 해법을 구현한다는 것을 개념화하기는 쉽지 않다. 주어진 문제를 재귀식으로 표현하는 것은 다차원 상태 표현과 분기 구조에는 잘 부합하지만, 표 형식 해법은 복잡한 계층을 for/while 문법에 의한 단순한 반복문 구조로 표현해야 한다.

메모이제이션과 마찬가지로 기저 조건과 상태를 정의한 후 해야 할 첫 번째 작업은 서로 다른 상태에 대한 해법을 어떻게 저장할 것인지를 결정하는 것이다. 일반적으로 타뷸레이션 방법에서는 간단한 배열 또는 벡터를 사용한다. 앞에서 이미 피보나치 수열 계산을 위해 정수형 벡터 DP를 선언하여 사용한 적이 있다.


vector<int> DP(n+1,0);

...

DP[i] = DP[i-1]+DP[i-2];


앞에서 팩토리얼을 재귀적으로 계산하는 방법에 대해 설명했다, 상향식 접근 방법으로 표를 채우면서 문제를 푸는 과정을 다음 수식으로 표현할 수 있다.

factorial[n] = factorial[n-1]*n;

팩토리얼 계산은 1차원으로 구성되고, 조건문도 필요 없는 매우 단순한 예이다. 각각의 상태는 처음부터 끝까지 일관된 수식으로 표현된다. 피보나치 수열 또는 팩토리얼 문제와 부분집합의 합 문제의 근본적인 차이점은 상태 표현을 위해 필요한 최소 차원 수가 다르다는 점이다. 즉, 부분집합의 합 문제는 현재까지의 부분집합의 합과 현재 처리하고 있는 집합의 인덱스가 필요하다. 부분집합 문제에 대해 좀 더 깊이 있게 생각해본다.

*크기가 k인 부분집합은 크기가 k-1인 부분집합에 새로운 원소를 추가하여 구성할 수 있다.

*인덱스 i에서 같은 부분집합의 합 x를 갖는 어떤 부분집합의 조합이든 최종적으로 같은 결과를 형성한다.


입력 집합 = {2 5 6 3 7 20}

목표치 = 28

	   i:    0    1    2      3     4        5
부분집합의 합: 2{2} 2{2} 8{2 6} 8{2 6} 8{2 6} 28{2 6 20}  - TRUE

부분집합의 함: -   5{5}  5{5}   8{5 3}  8{5 3}  28{5 3 20}  - TRUE


위에서 8을 어떤 과정으로든 도달한 후에는 무조건 TRUE로 종결된다. 부분집합의 합 문제가 최적 부분 구조 속성을 만족하기 때문이다.  8을 만족하는 집합은 마지막 20을 더하여 28을 만들 수 있기 때문에 최적 부분 구조 속성인 8만 만들면 된다. 8이 부분 문제인 것이다.


이러한 사실을 염두에 두고, 이제 하향식 접근 방식을 뒤집어 상향식 접근 방법을 개발해본다. 


<하향식 로직>

1. 부분집합의 합 목표치와 집합의 첫 번째 인덱스에서 시작

2. 입력 집합 전체에 대해 반복:

 - 만약 부분집합의 합이 0이 되면 결과는 TRUE이다.

 - 만약 입력 집합의 끝에 도달했다면 결과는 FALSE이다.

 - 그렇지 않으면 부분집합의 합에서 현재 인덱스의 집합을 빼거나 또는 그대로 유지한다.

3. 만약 부분집합의 합 x와 인덱스 i로 표현되는 상태 S에서 목표치를 찾을 수 있다면, 상태 S로 이어질 수 있는 모든 이전 상태에서도 목표치를 찾을 수 있다.


<상향식 로직>

1. 부분집합의 합과 인덱스를 0으로 설정하여 시작

2. 입력 집합 전체에 대해 반복: 

- 만약 인덱스가 0에서 i 사이일 때 x와 같은 부분집합의 합을 찾을 수 있다면, 인덱스가 0에서 I+1 사이에서도 x와 같은 부분집합의 합을 찾을 수 있다.

 - 만약 입력 인덱스가 0에서 i사이일 때 x와 같은 부분집합의 합을 찾을 수 있다면, 인덱스 0에서 i+1 사이에서 x+set[i]와 같은 부분집합의 합을 찾을 수 있다.


표를 채우는 방식과 관련해서, 하향식 접근 방법은 다음 규칙을 따른다.

상태 S1에서 부분집합의 합이 x와 같고 인덱스 i 인 경우, 다음 중 하나라도 성립하면 memo(i,x) = true이다.

- 부분집합의 합이 x-set[i]이고, 인덱스가 I+1인 상태 S2에서 목표치가 발견될 경우

- 부분집합의 합이 x이고 인덱스가 I+1인 상태 S3에서 목표치가 발견될 경우

그렇지 않으면 memo(i,x)=false이다.


이러한 로직을 상향식으로 바꾸면 다음과 같다.


만약 부분집합의 합이 x이고 인덱스가 I인 경우 다음중 하나라도 성립하면 
DP(i,x) = true이다.

-x가 set[i]보다 작고 DP(i-1,x) = true

인덱스 I에서 x<set[i]이고, 이전 인덱스에서의 결과가 true일 때

-x가 set[i]보다 크거나 같고, DP(i-1,sum) = true 또는 DP(i-1,sum-set[i]) = true)

인덱스 I에서 x>=set[i]이고 이전 인덱스에서 결과에서 둘 중 하나가 true일 때 

그렇지 않으면 DP(i,x) = false

즉, 인덱스가 0에서 I사이일 때 부분집합의 합이 x가 될 수 있다면 인덱스 0에서 I+1일 때에는 부분집합의 합이 x또는 x+set[i]가 될 수 있다. 

# Travel_Itinerary (dynamic programming)

고객의 여행 일정 작성을 도와주는 여행사 웹 프로그램을 만들려고 한다. 이 프로그램은 사용자의 여행 경로를 설계하는 데 초점을 맞추고 있다. 즉, 사용자가 방문하고 싶은 여러 여행지를 선택하면 최종 목적지로 이동하는 동안 통과해야 하는 도시 목록을 보여준다.

여행사는 주요 도시의 특정 운송 회사와 계약을 맺고 있으며, 각 운송 회사는 최대 운행 거리에 대한 제한을 가지고 있다. 비행기나 기차는 여러 도시를 운행할 수 있지만, 버스나 택시는 처음 출발 위치에서 가까운 한두 도시만 이동할 수 있다. 프로그램의 경우 가능한 여행 도시 목록을 생성하면 각 여행지에서 이동 가능한 최대 도시 개수가 함께 나타나고, 이를 활용하여 고객은 여행 경로를 구상할 수 있다.

최근 이 프로그램에 가능한 여행 경로를 필터링해서 보여주는 기능이 필요하다고 생각했다. 많은 인기 관광지는 몇몇 마을별로 구분되어 있기 때문이다. 이를 위해 출발지에서 목적지로 도달하는 모든 경로의 수를 미리 계산하여 너무 많은 경우의 수가 나타나는 것을 막으려고 한다.

이 프로그램은 이미 출발지와 목적지 사이의 주요 도시 목록을 생성하는 기능을 가지고 있다. 그리고 다음 정보를 미리 알 수 있다. 

N: 출발지부터 목적지 사이에 있는 도시의 수

distance: 각 도시에서 이동할 수 있는 최대 도시 개수를 나타내는 정수 배열


*입력

입력의 첫 번째 줄에는 출발지와 목적지 사이의 도시 개수를 나타내는 N이 적혀 있다. 두 번째 줄에는 빈칸으로 구분된 N개의 정수 d가 나열되어 있으며, 각각의 d는 i 번째 도시에서 출발하여 이동할 수 있는 최대 거리를 나타낸다.

*출력

이 프로그램은 0번 도시에서 시작하여 N번 도시에 도달하는 여행 경로 가짓수를 나타내는 정수를 하나 출력한다. N이 증가함에 따라 이 출력값이 너무 커질 수 있으므로 실제 출력은 여행 경로 가짓수를 1000000007로 나눈 나머지를 출력한다.

*추가 점수

앞서 제시한 문제를 합리적인 시간 내에 결과를 출력하는 프로그램을 만들었다면 이제 N이 10000000인 경우에 대해서도 알고리즘의 효율성 테스트를 해볼 수 있을 것이다. 여기에 모든 거리 값을 출력할 수는 없으므로 다음 소스 코드를 사용하여 거리 값 배열을 생성하여 테스트를 진행한다.

vector<int> Generate(int n)

{

	vector<int> distance(n);

	LL val = 1;

	for(int I=0;i<n;++i)

	{
		val = (val * 1103515245 + 12345) / 65536;

		val %=32768;


		distance[i] = (( val % 10000) % (n-i)) + 1;
	}

	return distance;

}

이 함수로 생성한 테스트 케이스에 대해 318948158을 출력하면 정상이다. 프로그램을 최적화된 알고리즘으로 구현했다면 1초 이내에 답을 출력해야 한다.


문제 해결 가이드라인

	*최적의 방법은 O(n) 시간 내에 실행되며 정확히 n번 반복해야 한다.

	*처음부터 동적 계획법으로 문제를 풀기 어렵다면 이 장에서 설명한 	문제를 풀어봐라. 즉, 전수 조사 방법부터 시작해서 점진적으로 풀이 	방법을 최적화해야 한다.

	*이 문제의 상태 구성 방법은 피보나치 수열에서 나왔던 재귀 관계식	을 참고해라.

# 2023.09.01

# Travel_Itinerary 분석

F(i) = Σ(j=1 to i-1) F(j) if j + distance(j) ≥ i

여기서 if문이 붙은 이유는

1번 distance[1] = 5

2번 distance[2] = 3

3번 distance[3] = 1

4번 distance[4] = 2



F(3)은 더하지 않는다. 왜냐하면 3에서 5로 바로 갈 수 없기 때문이다.

어차피 F(3)에 대한 경우의 수는 F(4)에서 더해진다.

따라서 5에 도달할 수 있는 지점들에 대해서만 더한다. 만약 5로 바로 도달할 수 없다면,

즉 1번에 도달하여 5번으로

+2번에 도달하여 5번으로

//3번은 5번에 도달할 수 없음(4번에 편입)

+4번에 도달하여 5번으로(3번에 도달하는 경우의 수 포함)

이런 뜻을 수식으로 표현한 것이다.

또한 F(3) = F(2)+F(1) 이므로 피보나치 수열과 비슷한 수식이다. 부분 문제가 중복으로 등장하고 F(3)에 대한 경로가

F(4)를 이루고 F(4)는 F(5)를 이룬다. 동적 프로그래밍의 특성에 해당하고 타뷸레이션을 이용하여 최적화할 수 있다.


sudo 코드는 다음과 같다.

F(n) -> n번째 도시에 도착하는 방법의 수

{
F(i) = 

	if i == N:
 
		return 1
  
	Otherwise:
 
		retsult = 0


		for j = 1 to distance[i]:
  
			result=result + F(i+j)
   
	return result
}

//아래 예에서 위 코드를 분석하자면, i = 2일 때 2에서 5로 가는 경우의 수는 F(3) + F(4) + F(5)가 된다. 2의 거리가 3이기 때문이다.
//F(3)을 계산해보면 1이 나오는데 결국 3->4->5의 경로를 의미한다.

*top down solution

하위 재귀의 값이 상위 재귀에 사용된다. - 하향식 재귀

1 2 3 4 5

1 2 4 5

1 2 5

1 3 4 5

1 4 5

1 5


출발점이 0인데 0은 1로만 갈 수 있으므로 1에서 출발했다고 가정하고

2에서 5를 갈 수 있는 경우는 3가지,

3에서 5를 갈 수 있는 경우는 1가지,

4도 1가지

5로 바로 가는 방법 1가지


위 내용을 0(진짜 출발지) 에서 출발했다고 한다면 , 1에서 5로 가는 방법이 0에서 1로 가는 방법의 경우의 수로 바뀐다.

즉 DP[5]+=DP[1](0은 1번 지점을 뜻한다) 인데 DP[1]=DP[0]이다.

총 6가지이다. 

F(1)= 6 (1)에서 5로 갈 수 있는 경우 6가지 -이 아래로는 1을 제외한 각 지점에서 5까지 갈 수 있는 경우의 수이다.

	result=result+F(2)
 
		      F(2) = 3 (2)에서 5로 갈 수 있는 경우 3가지
	
				result=result+F(3)
    
					      F(3) = 1
	   
						result=result+F(4)
      
							      F(4) = 1
	     
							      result=result+F(5)
	     
								            F(5)=return 1
		    
           			result(1)+=F(4)
	      
					F(4) = 1 - 중복
     
           			result(2)+=F(5)
	      
					F(5) = 1 - 중복
     
	result(3)+=result+F(3) (3)에서 가는 경우 1가지
 
		          F(3) = 1 - 중복
	    
	result(4)+=result+F(4)
 
			  F(4) = 1 - 중복
     
	result(5)+=result+F(5)
 
			  F(5) = 1 - 중복
     
	최종 result = 6	


이제 위 재귀식을 상향식으로 바꿔야 한다. 이전 결과가 다음 결과에 영향을 미치므로 상향식 재귀이다.

이제 타뷸레이션 최적화 방식의 형태가 드러나고 있다.

DP->N+1 크기의 배열

DP[0] = 1 (시작 지점에 도달 방법은 하나이다.)

for i =0 to N-1:

	for j = 1 to distance[i]:
 
		DP[i+j]+=DP[i]
  
return DP[N]


*Bottom-up solution

i = 0일 때

DP[1]+=DP[0] 1


i = 1일 떄

DP[2]+=DP[1] 1

DP[3]+=DP[1] 1

DP[4]+=DP[1] 1

DP[5]+=DP[1] 1


i = 2일 떄

DP[3]+=DP[2] 2

DP[4]+=DP[2] 2

DP[5]+=DP[2] 2


i = 3일 때

DP[4]+=DP[3] 4


i = 4일 떄

DP[5]+=DP[4] 6


즉 5에 도달하는 방법은 각 지점에 도달하는 방법을 모두 더한 값이다.

단 5로 도달할 수 없는 지점은 더하지 않아야 한다. 다른 지점의 경로에 편입되기 때문이다.

위 로직에서는 3은 5까지 갈 수 없으므로 DP[5]에는 더해지지 않고 DP[4]에 더해져서 계산된다.

다시 아래 경우에서 생각을 해본다.


1번 distance[1] = 5

2번 distance[2] = 3

3번 distance[3] = 1

4번 distance[4] = 2


일단 위 경우는 지점 6까지 있는 경우에서 5까지 도달할 수 있는 경우를 생각한 것이므로

다음과 같이 5가 마지막 지점이 되게 수정한다.


1번 distance[1] = 4

2번 distance[2] = 3

3번 distance[3] = 1

4번 distance[4] = 1


재귀는 식의 코드는 다음과 같다. reverse를 통해서 distance 배열을 뒤집으면 목적지부터 계산할 수 있다.

reverse(distance.begin(),distance.end())

DP[0] = 1; //DP[0] => 5번 지점까지 도달하는 경우의 수 (시작 지점까지 도달하는 경우의 수와 같다)

	   //뒤집었을 때는 시작점 0을 신경쓸 필요가 없다. 어차피 0에서부터 무조건 1에 도달하기 때문이다.
    
	   //또한 뒤집었을 때는 목적지부터 계산하므로 DP[0]이 목적지까지 도달하는 경우의 수로 바뀌기 때문이다.(또한 해당 정점에서 목적지까지 바로 도달하는 경우의 수로 바뀐다 두 가지 의미를 갖는다)
    
	   //뒤집지 않았을 경우에는 DP[0]=1로 설정을 해줘야 거리가 하나인 경우가 전달될 수 있다.
    
	   //0->1->2->3 일 때 각 거리가 1이라고 하면 DP[0]=0이라고 한다면 (시작점 뒤는 없으므로 시작점까지 가는 경우는 없다고 이해했을 때) DP[1]이 0으로 설정되어 버린다.
    
	   //또한 상향식 재귀 특성상 DP[0]=1이라는 기저 조건이 필요하다.
    
	
for(int i = 1; i <= n; ++i)

{

	int dist  = distance[i-1];
 
	for(int j = 1; j <= dist; ++j)
 
	{
 
		DP[i]=DP[i]+DP[i-j]
  
	}
 
}

return DP[n];

재귀를 따라가보자.

distance 배열의 원소는 1 1 3 4이다.

거꾸로 계산을 하면 더 이상 DP[4]를 제외하고는 나머지 DP값은 지점에 도달할 수 있는 경우의 수와 맞지 않는다.

즉 DP값들은 해당 지점에서 목적지까지 가는 경우의 수로 바뀐다.

아래 결과를 보면 DP[1],DP[2]는 맞지만 DP[3]은 4번 지점까지의 도달 경우의 수인데 3으로 나온다. 원래 값은 4이다.

하지만 마지막 DP[4]는 정확하게 6이 나온다. 


*i=1일 떄 (4번 지점의 거리) 4번에서 출발하여 5번까지 도달할 수 있는 경우의 수를 의미한다.

dist = distance[0]

dist->1

-j반복

DP[1]=DP[1]+DP[0]

DP[1]=1


*i=2일 때 (3번 지점의 거리) 3번에서 출발하여 5번까지 도달할 수 있는 경우의 수

dist=distance[1]

dist->1

-j반복

DP[2]=DP[2]+DP[1] 

- DP[1]은 4번에서 5번으로 갈 수 있는 경우의 수이다. 3번에서는 거리가 1이므로 4번까지 갈 수 있다. 따라서 4번의 경우의 수를 더하는 것이
- 
 3번에서 출발하여 5번까지 가는 경우의 수가 된다. 어차피 3은 4까지밖에 갈 수 없기 때문이다.
  
그럼 4에서 출발하는 경우의 수와 중복되는 거 아닌가 하는 의문이 들 수 있는데 4에서 출발하는 것과 3에서 출발하는 것은 다른 경우의 수이다.

 만약 거리가 2라면, DP[2]+=DP[0]까지가 계산되어 2가지의 경우의 수가 계산될 것이다.
 
DP[2]=1


*i=3일 때 (2번 지점의 거리) 2번 지점에서 출발하여 5번 지점까지 도달할 수 있는 경우의 수

dist=distance[2]

dist->3

-j반복

DP[3] = DP[3]+DP[0] - 바로 5번으로 가는 경우의 수

DP[3]->1

DP[3] = DP[3]+DP[1] - 3번으로 가서 5번으로 가는 경우의 수

DP[3]->2

DP[3] = DP[3]+DP[2] - 4번으로 가서 5번으로 가는 경우의 수

DP[3]->3


*i=4일 때 (1번 지점의 거리) 1번 지점에서 출발하여 5번 지점까지 도달할 수 있는 경우의 수

dist = distance[3]

dist->4

-j반복

DP[4] = DP[4]+DP[0] - 5번으로 바로 가는 경우의 수

DP[4] = DP[4]+DP[1] - 4번으로 가서 5번으로 가는 경우의 수

DP[4] = DP[4]+DP[2] - 3번으로 가서 5번으로 가는 경우의 수

DP[4] = DP[4]+DP[3] - 2번으로 가서 5번으로 가는 경우의 수

DP[4] -> DP[3]+DP[2]+DP[1]+DP[0] 1번은 각 지점에 도달할 수 있으므로 각 지점의 경우의 수를 모두 더하면 된다. DP[0]은 5로 바로 가는 것이 된다.

DP[4] -> 3 + 1 + 1 + 1이 된다.

# 2023.09.02

# Modular arithmetic 

프로그래밍 문제에서는 종종 계산 결과가 매우 큰 수가 될 수 있어서 이를 그대로 출력하는 것이 불가능하거나 비효율적인 경우가 있다. 예를 들어,
정수형 변수의 최대 범위를 초과하는 결과값이 나올 수 있는 문제 등이 이에 해당한다.

이런 경우에는 일반적으로 문제 자체에서 "모듈러 연산"을 사용하여 출력값을 제한하라고 요구한다. 모듈러 연산은 어떤 숫자를 다른 숫자로 나누었을 때의 나머지를 구하는 연산이다. 이렇게 하면 어떤 큰 수라도 특정 범위 내의 작은 수로 변환할 수 있다.

따라서 "올바른 답으로 간주된다"는 말은, 문제에서 요구한 대로 모듈러 연산을 적용한 결과값이므로, 그 값은 원래 계산해야 할 값과 다르더라도 (특히 MOD보다 클 경우) 올바른 해답으로 인정된다는 의미이다.

즉, 우리가 MOD보다 큰 값을 계산해야 하는 상황에서 % MOD 연산을 사용하여 그 결과값을 적절한 범위 내에 유지시키면, 코드는 항상 올바른 "나머지" 값을 반환할 것이다. 이 "나머지" 값은 원래의 값을 정확하게 표현하지 않더라도 (MOD보다 클 경우), 문제의 요구사항을 충족시키므로 올바른 답으로 간주된다. 하지만 의도된 값으로 다시 복원할 수는 없으므로 이 점을 유의해야 한다.

*모듈로 연산의 특성은 다음과 같다.

{

 모듈러 연산의 속성

 1. (a + b) mod n = ((a mod n) + (b mod n)) mod n

 2. (a - b) mod n = ((a mod n) - (b mod n)) mod n

 3. (a x b) mod n = ((a mod n) * (b mod n)) mod n

}

# 2023.09.04

# Longest Common Subsequence (LCS)

이번에는 동적 계획법에서 많이 사용되는 분야 중의 하나인 데이터 시퀀스의 패턴 문제에 대해 알아본다. 프로그래머가 이러한 문제에서 동적 계획법을 사용하는 것은 주로 문자열 검색, 비교, 문자열 재구성 등의 문제와 관련이 있다. 

소프트웨어 개발자는 하나의 프로젝트를 여러 개발자들과 같이 협력하여 작업하는 경우가 많다. 몇몇 프로그래머가 실수로 버그 코드를 추가할 수 있고, 또는 특정 기능을 다른 방식으로 구현하다가 다시 이전 코드로 원복할 수도 있기 때문에 버전 관리 시스템을 사용하는 것은 매우 중요하다, 최근까지 잘 동작하던 기능에 문제가 발생할 경우, 이전 버전의 소스 코드와 비교하여 변경된 부분을 쉽게 찾아볼 수 있어야 한다. 그러므로 대부분의 버전 관리 시스템은 두 가지 버전의 소스 코드를 비교하여 사용자에게 차이점을 표시해주는 비교
(diff)기능을 제공한다. 

만약 저장소에 다음 코드를 추가했다고 가정한다.

bool doSomething = true;

void DoStuff()

{
	DoSomething();

	DoSomethingElse();

	DoAnotherThing();

}

그리고 다음 날에 소스 코드를 다음과 같이 변경했다.

bool doSomething = false;

void DoStuff()

{	if( doSomething == true )

	{

		DoSomething();

	}

	else

	{

		DoSomethingElse();

	}

}

이 두 코드의 차이점을 비교하는 것이 목적이다.

파일 비교 프로그램은 두 버전에 공통적인 문자열 시퀀스가 연속적일 필요가 없다는 사실을 고려하여 두 소스 코드의 유사성을 판별해야 한다. 또한 문자열 일부가 제거되거나 새로운 문자열이 임의 위치에 추가될 수도 있다. 이러한 작업은 근사 문자열 매칭(approximate string matching) 또는 퍼지 문자열 매칭(fuzzy string matching)이 필요하며, 이를 위해 동적 계획법이 사용된다.


<최장 공통 부분 시퀀스 문제>

최장 공통 부분 시퀀스 문제는 동적 계획법의 유명한 예제 중 하나이다. 이 문제는 다음과 같이 정의된다.

두 개의 데이터가 주어질 때, 두 시퀀스에 공통으로 나타나는 가장 긴 부분 시퀀스는 무엇인가? 예를 들어 다음과 같은 두 개의 문자열 A와 B가 있다고 가정한다.

A = "ALBOCNDGZEYSXTW"
B = "12L45078N90GE9876S5432T"

이 두 문자열에서 구할 수 있는 최장 공통 부분 시퀀스는 “LONGEST"이다.

앞서 부분집합의 합 문제를 다양한 접근으로 구현해보았던 경험이 있으므로 이번에는 좀 더 똑똑하게 접근한다. 먼저 기저 조건부터 시작하여 문제 구조를 어떻게 수식으로 표현할 수 있을지 생각한다.

동적 계획법 문제를 처음부터 큰 입력에 대해 이해하기가 쉽지 않으므로 먼저 작은 크기 입력에 대한 동작을 분석해본다. 즉 짧은 문자열 입력에 대해 다양한 경우를 분석해보고, 최장 공통 부분 시퀀스의 길이를 알아내는 방법에 대해 생각해본다.

(1) A 또는 B가 빈 문자열인 경우

A = ""

B = ""

LCS = 0


A = "A"
B= ""

LCS = 0

A= ""
B="WJERNSDF“
LCS = 0

(1)번 경우는 두 문자열 모두 또는 두 문자열 중 하나가 빈 문자열인 경우이다. 이러한 경우 당연히 최장 공통 부분 시퀀스의 길이는 0이다.

(2) A와 B모두 하나의 문자로 구성된 경우

A = "A"

B = "A"

LCS = 1


A = "A"

B= "B"
LCS=0

(3)A는 한 문자이고, B는 두 문자로 구성된 경우

A="AB"
B="A"

LCS = 1


A="A"
B="BB"

LCS = 0

(2)와 (3) 경우는 두 가지 결과가 나타날 수 있다. 즉, 공통 문자가 하나 있거나, 또는 하나도 없는 경우이다.


(4)A와 B가 모두 두 문자로 구성된 경우

A=AA
B=AA

LCS=2


A=BA
B=AB

LCS=1

A=AA
B=BB

LCS = 0

(4)번 경우는 좀 더 복잡해지지만, 논리는 크게 바뀌지 않는다. 두 문자열이 완전히 같거나, 한 문자만 같거나, 또는 공통 문자가 전혀 없는 경우가 존재한다.

(5)A와 B모두 세 문자로 구성된 경우

A=ABA
B=AAB

LCS=2


A=ABC
B=BZC

LCS = 2

이제 복잡도가 크게 증가하기 시작했다. 이제는 점차 직관적인 비교가 어려워지기 시작한다.

(6)A와 B가 모두 네 문자로 구성된 경우

A=AAAB
B=AAAA

{ AAA_, AAA_ }

{ AAA_, AA_A }

{ AAA_, A_AA }

{ AAA_ , _AAA }

LCS = 3


A=AZYB
B=YZBA

{ _Z_B , _ZB_ }
{ __YB , Y_B_ }

LCS = 2

이제 최장 부분 시퀀스 문제가 중복되는 부분 문제를 포함하고 있다는 사실을 알 수 있다. 부분집합의 합 문제와 마찬가지로, 문자열 길이를 n이라고 하면
2^n개의 가능한 부분 문자열 집합이 있을 수 있다. 다만 여기서는 고려해야 할 시퀀스가 두 개다. 그리고 두 시퀀스의 부분집합을 독립적으로 처리하는 것이 아니라 두 부분집합을 서로 비교해야만 한다.

ABCX 와 ACY에 대해 가능한 모든 문자 부분 시퀀스는 다음과 같다.

( ABCX )

A___

_B__

__C_

___X


AB__

A_C_

A__X

_BC_

_B_X

__CX


ABC_

AB_X

A_CX

_BCX


ABCX


(ACY)

A__

_C_

__Y


AC_

A_Y

_CY

ACY


여기서 단순히 연속되어 나타나는 문자 집합을 찾는 것이 아니라는 사실로부터 몇 가지 고려해야할 사항이 있다. 첫째, 공통 부분 문자 시퀀스는 문자열 전체에서 다양한 형태의 배치에 의해 여러 번 나타날 수 있다. 둘째, 특정 위치에서 시작하는 공통 부분 시퀀스가 여러 개 존재할 수 있다. 

전수 조사 방법을 구현하기에 앞서 이 문제의 상태를 표현하기 위해 필요한 것들에 대해 생각해본다. 문자열 A와 B에서 특정 문자의 위치를 가리키는 두 개의 인덱스 I와 j가 필요하다. 그리고 지금까지 찾은 공통 부분 시퀀스도 저장하고 있어야 한다.


*만약 i가 A의 길이보다 커지거나 또는 j가 B의 길이보다 커지면:

 - 재귀를 종료하고 부분 시퀀스의 길이를 반환한다.

두 문자열 중 하나라도 맨 마지막에 도달하면 더 이상 비교할 대상이 없어진다.

*만약 A[i] = B[j]이면:

 - 부분 시퀀스 길이를 1만큼 증가한다.

 - i와 j를 각각 1씩 증가한다.

만약 i번째와 j번째 문자가 서로 같다면, 이 문자는 당연히 부분 시퀀스에 추가해야 한다. 그리고 각 문자는 부분 시퀀스에 최대 한 번만 추가될 수 있으므로 i와 j를 1씩 증가시킨다.

*그렇지 않으면:
	
	옵션1) (i+1)번째와 j번째 문자에 대해 검사를 진행한다.

	옵션2) i번째와 (j+1)번째 문자에 대해 검사를 진행한다.

	이 상태의 LCS는 옵션 1및 옵션 2의 최댓값과 같다.

비교한 두 문자가 같지 않다면, A 문자열의 다음 문자를 살펴보거나 B 문자열의 다음 문자를 살펴봐야 한다. 이때 두 문자열의 인덱스 i와 j를 동시에 증가시키는 경우는 따로 고려하지 않았는데, 이러한 경우는 어차피 추후에 만나게 되기 때문이다.

이 문제의 최적 부분 구조는 아직 명확하지는 않지만, 다음과 같은 기본적인 일반화를 수행할 수 있다.

*같은 길이의 부분집합만 비교하면 된다.

*특정 상태에서 다음 상태로 전이되기 위해서는 i또는 j가 증가하거나, 또는 i와 j가 같이 증가해야 한다.

*두 문자열 중 어느 하나라도 맨 마지막에 도달하면 탐색이 끝난다.

이 문제에 대해서도 전수 조사를 구현해보면 추가적으로 이해할 수 있다.

# LCS using memoization

ABCX와 ACYXB를 다시 사용하기로 하고, i=j=0인 경우에 다음 관계가 성립한다.

LCS(A,B,0,0) = 1 + LCS(A,B,1,1)

두 개의 문자열 중 하나라도 비어 있는 상태이면 LCS 값은 0이다. 또한 두 문자열 A와 B의 LCS는 A에서 마지막 문자를 제외한 문자열과 B로부터 구한 LCS, 그리고 B에서 마지막 문자를 제외한 문자열과 A로부터 구한 LCS 둘 사이의 최댓값이다.

A = "ABC"

B = "AXB"

"ABC"와 “AXB"의 LCS

 = max("AB“와 ”AXB"의 LCS, "ABC"와 “AX"의 LCS)

 = "AB"와 “AXB"의 LCS

 = "AB" (max값)

이와 같이 두 문자열의 LCS와 두 문자열의 앞쪽 부분 문자열의 LCS관계를 이용하여 다음과 같은 로직을 정의할 수 있다.

만약 두 문자열 중 하나라도 빈 문자열이면:

	LCS = 0

그렇지 않으면:

	A의 부분 문자열과 B의 부분 문자열 마지막 문자가 같으면:
		
		A와 B의 부분 문자열에서 구한 LCS 길이는 각 부분 문자열에서 마지막 한 문자를 제외한 문자열로부터 구한 LCS 길이에 1을 더한 것과 같음.

	그렇지 않으면:
		
		LCS길이는 다음 두 경우의 최댓값과 같음:

			(1) A의 부분 문자열에서 마지막 문자를 제외한 것과 B의 부분 문자열에서 구한 LCS 길이

			(2) B의 부분 문자열에서 마지막 문자를 제외한 것과 A의 부분 문자열에서 구한 LCS 길이


메모이제이션 기법을 이용하여 모든 단계의 결과를 2차원 벡터에 저장할 수 있다. 이때 첫 번째 차원의 크기는 A문자열 길이와 같고, 두 번째 차원 크기는 B문자열 길이와 같다. 기저 조건을 제외하고, memo[i-1][j-1]위치에 이미 계산된 결과가 저장되어 있는지를 확인한다. 만약 이미 저장된 값이 있다면 그 값을 그대로 반환하고, 그렇지 않으면 다시 앞에 정의한 로직을 이용하여 재귀적으로 값을 계산하여 캐시에 저장한다. 

*문제 해결 가이드라인

-상태를 2차원 벡터로 표현할 수 있다. 첫 번째 차원의 크기는 문자열 A의 길이로, 두 번째 차원의 크기는 문자열 B의 길이로 설정한다.

-전수 조사 방식을 메모이제이션 방식으로 변환하기 위해 변경해야 할 사항은 거의 없다.

-부분 문제를 다룰 때 이미 캐시에 저장되어 있는지를 구분할 수 있는 방법에 대해 잘 생각해야 한다.

# LCS using Tabulation

이전에 메모이제이션으로 해결한 코드에서 다음과 같은 패턴을 찾을 수 있다.

만약 문자가 서로 같은 경우에 대해서는 memo[i][j] = memo[i-1][j-1] + 1 이다. 만약 문자가 서로 다른 경우에 대해서는 memo[i][j]는 memo[i-1][j]와 
memo[i][j-1] 두 값의 최댓값과 같다. 주어진 문제의 최적 부분 구조를 알고 있을 경우 타뷸레이션 기법으로 해답을 구하는 작업은 매우 간단하다. 단순히 메모이제이션 해법으로 구했던 테이블을 상향식으로 구축하도록 코드를 작성하면 된다. 여기서는 기본적인 개념을 유지하되 로직을 조금 다르게 작성하려고 한다. 우선 memo 테이블 값을 UNKNOWN으로 초기화한다. 타뷸레이션 기법은 전체 테이블을 적절한 값으로 채워나가는 알고리즘이며, 알고리즘이 종료되었을 때 UNKNOWN으로 남아 있는 값이 없어야 한다.

즉, 특정 상태의 LCS길이는 이전에 발견한 LCS 길이와 같거나, 또는 문자가 서로 같을 경우에는 이전 LCS길이보다 하나 큰 값이다. 가능한 최소 LCS길이는 0이다. 그러므로 이제 다음과 같이 DP테이블을 재귀적으로 채우는 로직을 구성할 수 있다.

{

만약 i = 0 또는 j = 0 (빈 부분 문자열):

	LCS(i,j) = 0

그렇지 않으면:
	
	만약 두 부분 문자열의 마지막 문자가 같다면:

		LCS(i,j) = LCS(i-1,j-1) + 1

	그렇지 않으면:

		LCS(i,j) = LCS(i-1,j)와 LCS(i,j-1) 둘 중에 최댓값

}

이러한 로직은 앞서 설명한 메모이제이션 방법에서 나왔던 것과 본질적으로 같다. 다만 메모이제이션에서는 현재 상태 값을 알기 위해 아직 구하지 않ㅇ느 이전 상태 값을 재귀적으로 계산하는 방식이지만, 타뷸레이션 방식은 앞부분 상태부터 채워나가며 이 상태 값을 나중에 재사용한다.

*문제 해결 가이드라인

- 부분집합의 합 문제와 마찬가지로 타뷸레이션 방식은 2중 for문이 필요하다.

- 특정 상태 LCS(i,j)에 대해 세 가지 처리 방법이 필요하다. 두 부분 문자열 중 하나라도 빈 문자열인 경우, 두 부분 문자열의 마지막 문자가 같은 경우, 마지막 문자가 같지 않은 경우를 따로 처리해야 한다.

-LCS를 구성하는 문자들은 DP 테이블을 역추적하여 찾을 수 있다.

# Melodic Permutation using Tabulation

음악 집합 이론(Musical set theory)는 음(note)의 간격 관계에 따라 화성과 멜로디(Melody)를 분류하는 형태이다. 음악 용어에서 음정(interval)은 악보에 기록될 때 두 음 사이의 상대적인 거리로 정의할 수 있다.

음악에서 특정 음 집합의 순열이 몇 번 나타나는지 알고 싶다고 가정한다. 특정 멜로디와 음이름 집합이 주어지면, 주어진 멜로디에 음 집합의 순열이 나타나는 횟수를 세어야 한다. 유효한 수열에 대해 음이름은 순서에 상관없이 몇 번이든 반복되어 나타날 수 있다.

{

	  0 1 2 3 4 5 6	

멜로디 : {A,B,C,C,E,C,A}

음 이름 집합 : {A C E} //음 이름 순서는 관계 없다.

부분집합 : {0 2 4}

	{0 3 4}

	{0 4 5}

	{2 4 6}
	...

	{0,2,3,4}

	{0,2,4,5}

	...

	{0,2,3,4,5}
	...

전체 순열 개수 = 21

}

다음의 음이름 쌍은 같은 음을 나타내며 동일하게 취급해야 한다.

C - B#

C# - Db (디 플랫)

D# - Eb

E - Fb

E# - F

F# - Gb

G# - Ab

A# - Bb

B - Cb

그러므로 다음 음 이름 조합은 같다고 간주한다.

{A#,B#,C#} = {Bb,C,Db}

*문제 해결 가이드라인

 - 타뷸레이션 기법을 이용하기에 적합하도록 음을 다른 형식으로 바꿀 수 있을까?

 - n개 원소의 부분집합 개수는 몇인가? 이 정보가 이 문제를 해결하는 데 유용할까?

먼저 이 문제에서 상태를 구성하는 것이 무엇인지를 생각해야 한다.

기저 조건 -> 공집합

	1. 멜로디에 있는 각각의 음을 고려한다.

	2. 이전에 구한 각 음의 부분집합에 대해 현재 음을 추가하거나 또는 	   아무 작업도 하지 않는다.

	3. 부분집합이 목표와 일치한다면 해답에 추가한다.

이전의 부분집합에 음을 추가하거나 또는 그대로 놔두는 두 가지 방법이 존재하므로, 로직을 다음과 같이 작성할 수 있다.

“멜로디에 있는 특정 음에 대해, 해당 음을 포함하고 크기가 |N|인 부분집합의 개수는 해당 음을 포함하지 않고 크기가 |N-1|인 모든 부분집합의 개수와 같다. 
그러므로 각각의 상태는 2차원으로 표현될 수 있다.

*첫 번째 차원: 지금까지 고려한 멜로디의 길이

*두 번째 차원: 이전에 발견된 부분집합에 멜로디의 [length-1]번째 음을 추가하거나 또는 아무것도 추가하지 않은 부분집합

이러한 로직은 다음과 같은 의사 코드로 표현할 수 있다.

i = 1부터 멜로디 길이까지 반복:

	이전에 찾은 부분집합에 대해:
		
		DP(i,subset) = DP(i,subset)+DP(i-1,subset)

		DP(i,subset U melody[i-1]) = 
		DP(i,subset U melody[i-1)+DP(i-1,subset)

이제 이러한 상태를 어떻게 표현할 것인가에 대해 생각해본다.

n개의 원소가 있는 집합에 대해 전체 2^n개의 부분집합이 있을 수 있다. 예를 들어 네 개의 원소로 구성된 집합이라면 16개의 부분집합을 만들 수 있다.

S = {A B C D}

{} -> {____}

{A} -> {#___}

	{_#__}
	
	{__#_}

	{___#}

{A B} -> {# # _ _}
	
	->{#_#_}
	...

만약 0부터 15까지 숫자를 2진수로 표현하면 다음과 같다.

0 -> 0000 {____}

1 -> 0001 {#___}

2 -> 0010 {_#__}

...

0부터 2^n까지의 이진수 표현에서 숫자 1이 나타나는 위치의 원소를 선택하여 부분집합을 구성할 수 있다. 하나의 음계에 12개의 음이 있으므로 전체 
2^12=4096개의 음 부분집합이 만들어질 수 있다. 한 음계의 각각의 음을 2의 승수로 간주하고 C++ 비트 단위 연산을 이용하여 각 상태에 해당하는 부분집합을 표현할 수 있다.

# 2023.09.05

# P and NP solution

입력 데이터 크기가 증가함에 따라 문제 해결의 복잡도가 어느 정도까지 향상되는지를 파악하는 것은 매우 중요하다. 이를 통해 동적 계획법이 단순한 선호도의 문제가 아니라 필수적인 선택이라는 것을 이해할 수 있다.

“특정 값과 연산자로 구성된 부울 수식이 주어지면 그 결과가 TRUE인지
FALSE인지를 판단해라“

몇 가지 예를 들면 다음과 같다.

(0 OR 1) -> TRUE
(1 AND 0) -> FALSE

(1 NOT 1) -> FALSE

(1 NOT 0) AND (0 NOT 1) -> TRUE

이 문제는 매우 쉽게 풀 수 있다. 주어진 수식을 연산 순서에 맞게 평가하면 정확한 답을 얻을 수 있다. 그러나 문제가 다음과 같이 주어졌다고 생각해보자.

“번수와 연산자로 구성된 부울 수식이 주어질 경우, 각 변수에 TRUE 또는 
FALSE를 지정하여 그 결과가 TRUE가 될 수 있는지를 판단하라.“

다음 예제를 살펴본다.

(a1 OR a2) -> TRUE

(0 v 0) = FALSE

(0 V 1) = TRUE

(1 V 0) = TRUE

(1 v 1) = TRUE

(a1 AND a2) -> TRUE

(0 ^ 0) = FALSE

(0 ^ 1) = FALSE

(1 ^ 0) = FALSE

(1 ^ 1) = TRUE

(a1 NOT a1) -> FALSE

(0 ! 0) = FALSE

(1 ! 1) = FALSE

(a1 NOT a2) AND (a1 AND a2) -> FALSE

(0 ! 0) ^ (0 ^ 0) = FALSE

(0 ! 1) ^ (0 ^ 1) = FALSE

(1 ! 0) ^ (1 ^ 0) = FALSE

(1 ! 1) ^ (1 ^ 1) = FALSE

부울 수식을 다룬다는 점은 같지만, 두 문제의 차이는 엄청나다. 첫 번째 문제에서 복잡도를 결정하는 요소는 수식의 길이 하나 뿐이다. 그러나 두 번째 문제는 각 변수에 가능한 모든 값을 하나하나 대입해보면서 조건을 만족하는지 확인하는 방법 외에는 다른 뚜렷한 방법이 없을 것 같다.

또 다른 문제를 살펴본다.

“주어진 그래프의 모든 정점에 세 가지 색상 중 하나가 할당되어 있을 경우, 인접한 두 정점이 같은 색상으로 지정된 경우가 있는지 여부를 판단해라.”

앞서 부울 수식 예제와 마찬가지로, 이 문제 또한 매우 쉽게 구현할 수 있다. 모든 정점을 탐색하면서 인접한 정점이 같은 색상을 가지고 있다면 FALSE를 반환하면 된다. 그런데 만약 문제가 다음과 같이 바뀌면 어떨까?

“주어진 그래프의 모든 정점에 세 가지 색상 중 하나를 할당할 경우, 인접한 두 정점이 같은 색상을 갖지 않도록 지정할 수 있는지 여부를 판단하라.”

이는 앞에서 기술한 문제와는 매우 다른 문제이다.

앞서 제시한 문제들 중에서 먼저 기술한 형태의 문제를 P문제라고 부르고, 이는 다항 시간 내에 해답을 구할 수 있음을 의미한다. 주어진 문제의 시간 복잡도가 O(n),O(n^2),O(log n)등으로 표현될 수 있으면 이 문제들은 P 문제에 속한다. 그러나 나중에 기술한 형태의 문제들은 최악의 상황에서의 복잡도가 지수 시간이 아닌 솔루션이 존재하지 않는다. 그러므로 이러한 문제들은 NP 문제 또는 비결정적 다항 시간 문제라고 부른다.

주어진 문제를 P와 NP로 구분하는 것은 상당한 논쟁거리이다. 특히 흥미로운 부분은 주어진 문제의 솔루션을 검증하는 것은 쉬운 반면, 실제 솔루션을 만들어내는 작업은 매우 어렵다는 것이다. 프로그래밍 분야에서 널리 논의되고 있는 미해결 문제 중 하나는 다음과 같다. “주어진 문제의 솔루션 검증이 클래스 P에 속한다는 것이 해당 문제의 다항 시간 솔루션을 보장하는가?” 즉 다시 말해 P = NP인가? 일반적으로는 이 질문에 대답은 아니요라고 알려져 있다. 하지만 아직 증명된 것은 아니다. 만약 이것에 대한 증명이 이루어진다면 결과가 무엇이든지 알고리즘 분야에서 혁신적인 진보가 될 것이다.

NP에 속하는 많은 문제는 NP-완전(NP-complete)로 알려져 있으며, 이들 문제는 특별한 특성을 공유한다. 만약 NP 문제 중 하나를 다항 시간처럼 효율적으로 해결하는 솔루션이 발견된다면, 해당 솔루션을 수정하여 다른 모든 NP 문제를 효율적으로 해결할 수 있다. 즉, 앞에서 첫 번째 예로 들었던 부울 수식 충족 가능성 문제(SAT, Boolean satisfiability problem)에 대한 다항 시간 솔루션이 발견될 경우, 로직을 조금 변경하여 두 번째 그래프 컬러링 문제도 해결할 수 있으며, 그 반대도 가능하다. 

복잡도가 높은 모든 문제가 이러한 특징을 갖는 것은 아니다. 체스 게임에서 가장 좋은 이동 방법을 찾는 문제를 생각해본다. 아마도 다음과 같은 순환 로직을 생각할 수 있을 것이다.

현재 플레이어가 가진 각각의 피스 a에 대해:
	
	피스 a가 움직일 수 있는 이동 방법 m_a에 대해:
		
		상대방 플레이어가 가진 각각의 피스 b에 대해:

			m_a 이동 후, 피스 b가 움직일 수 있는 이동 방법 m_b에 대해:

				현재 플레이어가 가진 각각의 피스 a에 대해:...

				...

	이러한 이동 후에 player_1 플레이어가 이길 수 있는 방법의 수를 계산한다.

가장 좋은 이동 방법은 player_1 플레이어가 이기는 확률이 최대가 되는 이동 방법이다.

따라서 지금까지 다뤄본 동적 계획법 풀이 방법은 다항 시간 복잡도를 갖는 것으로 취급되지 않는다. 부분집합의 합 문제는 의사 다항 시간
(pseudo-polynomial time)으로 동작한다고 정의하며, 실제로 NP-완전 문제이다.

# 0-1 Knapsack Problem using Dynamic Programming

그리디 알고리즘에서 살펴봤던 배낭 문제를 다시 살펴본다. 이 문제는 바로 앞에서 살펴봤던 부분집합의 합 문제의 큰 형님이라고 볼 수 있다. 

“용량 제한이 있는 배낭에 서로 다른 가격과 무게를 갖는 여러 물건이 주어질 경우, 배낭의 제한 용량을 넘지 않으면서 가방에 넣은 물건들딍 가격 합이 최대가 되는 물건 조합은 무엇인가?”

이 문제 또한 대표적인 NP-완전 문제이며, 다른 NP-완전 문제와 밀접한 관련이 있다. 다음의 예를 살펴본다.

용량 -> 10

물건 개수 -> 5

무게 -> {2 3 1 4 6}

가격 -> {4 2 7 3 9}

이 문제를 풀기 위해 부분집합의 합 알고리즘을 많이 확장해야 할까?



<0-1 배낭 문제 - 부분집합의 합 문제 확장하기>

이 경우 부분집합의 합 문제를 해결할 때 사용했던 상태 변환 로직과 유사한 공통점을 발견할 수 있다. 부분집합의 합 문제의 경우, 집합의 i번째 원소 set[i]에 대해 다음 작업을 수행했다.

1.이전에 구한 부분집합의 합에 set[i]를 더한다.

2.이전에 구한 부분집합의 합을 그대로 유지한다.

이 경우 (i+1)번째 인덱스와 부분집합의 합 x에서의 DP 테이블 값은 다음을 참조하여 TRUE로 설정된다.

1.DP(i,x) - 이전 행, 같은 부분집합의 합 위치 값

2.DP(i,x+set[i]) - 이전 행, 같은 부분집합의 합에 set[i]를 더한 위치 값

즉, i번째 인덱스에서의 부분집합의 합은 이전 부분집합의 합 또는 이전 부분집합의 합에 현재 원소를 더한 값으로 결정된다.

0-1배낭 문제의 경우, i번째 물건의 무게가 w이고 가격이 v라면 다음 중 하나를 수행할 수 있다.

1.기존에 선택된 물건들의 무게에 w를 더한 결과가 최대 용량보다 같거나 작을 경우, 기존에 선택된 물건들의 가격 합에 v를 더한다.

2.기존에 선택된 물건들의 가격 합을 그대로 유지한다.

가격이 v이고 무게가 w인 (i+1)번째 물건을 고려할 때, 선택된 물건들의 무게 합이 W인 경우의 최대 가격 합은 다음 중 하나로 결정된다.

1. i번째 물건에 대해 선택된 물건들의 무게 합이 W인 경우의 최대 가격 합

2.i번째 물건에 대해 선택된 물건들의 무게 합이 W-w인 경우의 최대 가격 합에 v를 더한 값

즉, i번째 물건과 무게 w를 고려할 때의 최대 가격 합은 같은 무게에 대해 i-1번째 물건을 고려할 경우와 같거나, 또는 이전의 최대 가격 합에 현재 물건의 가격을 더한 것과 같다.

부분집합의 합 문제에서 DP테이블을 채우는 의사 코드는 다음과 같이 작성할 수 있다.

i번째 인덱스에서 sum(1 <= sum <= max_sum) 값에 대해:
	
	만약 sum < set[i-1]이면:
		
		DP(i,sum) = DP(i-1,sum)

	그렇지 않으면:

		DP(i,sum) = DP(i-1,sum) 또는 DP(i-1,sum-set[i-1])

이와 같은 로직을 배낭 문제에 적용하면 다음과 같다.

i번째 인덱스에서 total_weight(1 <= total_weight <= max_capacity) 값에 대해:

	만약 total_weight < weight[i]이면:

		DP(i,total_weight) = DP(i-1,total_weight)

	그렇지 않으면:

		DP(i,total_weight) = 다음 중 최댓값:
	
			(1) DP(i-1,total_weight)

			(2) DP(i-1,total_weight-weight[i])+value[i]

여기서 전체적인 알고리즘의 흐름은 실질적으로 같다는 점을 알 수 있다. 집합의 원소 개수와 집합 원소의 합으로 크기가 고정된 2차원 검색 공간을 탐색하면서 새로운 부분집합의 합을 찾을 수 있는지 여부를 결정한다. 다만 차이점은 단순히 특정 부분집합의 합이 존재하는지 여부를 기록하는 것이 아니라, 선택된 항목들의 부분집합이 구성하는 무게를 고려하여 최대 가격을 찾는다는 점이다.

# 2023.09.06

# user-defined string class

c-style function을 사용하여 사용자 정의 string class를 간단하게 구현한 코드이다.

# Unbounded_Knapsack_problem & State space reduction

<무한 개수 배낭 문제>

각 물건을 개수 제한 없이 배낭에 담을 수 있는 무한 개수 배낭 문제(unbounded knapsack problem)을 알아본다.

위 문제에 대해서 전수 조사 방식을 잠시 살펴본다.

용량 = 25

가격 -> {5, 13, 4, 3, 8}

무게-> {9, 12, 3, 7, 19}

{0} -> 무게 = 9, 가격 = 5

{1} -> 무게 = 12, 가격 = 13

{2} -> 무게 = 3, 가격 = 4

 ...

{0,0} -> 무게 = 18, 가격 = 10

{0,1} -> 무게 = 21, 가격 = 18

{0,2} -> 무게 = 12, 가격 = 9

...

{0,0,0} -> 무게 = 27, 가격 = 15

{0,0,1} -> 무게 = 30, 가격 = 26

...

전수 조사 관점에서 볼 때 무한 개수 배낭 문제는 훨씬 더 복잡해보인다. 다음에서 의사 코드 로직을 설명한다.

현재 선택된 물건들의 무게 합이 total_weight이고, 무게가 current_weight일 인 i번째 물건을 고려할 때, 최대 가격 합은 다음 중 하나일 수 있다.

1.(i-1)번째 물건과 total_weight 무게를 고려할 때의 최대 가격 합

2.(i-1)번째에서 선택된 물건들의 무게에 current_weight를 더하여 total_weight가 형성되었다고 가정할 경우:

	a.(i-1)번째에서 선택된 물건들의 무게가 total_weight - current_weight일 때의 최대 가격 합에 현재 물건 가격을 합한 값

	b.현재 선택된 물건들의 무게가 total_weight - current일 때의 최대 가격 합에 현재 물건 가격을 합한 값.

이 새로운 로직을 DP테이블 관점에서 다음과 같이 나타낼 수 있다.

i번째 인덱스에서 total_weight( 1< = total_weight <= max_capacity)에 대해:

	만약 total_weight < set[i-1]이면:

		DP(i,total_weight) = DP(i-1,total_weight)

	만약 total_weight >= set[i-1]이면:

		DP(i,total_weight) = 다음 중 최댓값:
		
			1.DP(i-1,total_weight)

			2.DP(i-1,total_weight-currentweight)+currentvalue
	
			3.DP(i,total_weight-current_weight)+currentvalue

이를 C++코드로 구현하면 다음과 같다.

//max 람다 함수 정의

auto max = [](int a,int b,int c){return std::max(a,std::max(b,c));};

for(int i=1;i<=items;++i)

{

	int current_weight = weight[i-1];

	int current_value = value[i-1];

	for(int total_weight=0;total_weight<=capacity;++total_weight)

	{

		if(total_weight < current_weight)

		{

			DP[i][total_weight]=DP[i-1][total_weight];

		}

		else

		{

			DP[i][total_weight] = max(DP[i-1][total_weight],DP[i-
			1][total_weight-current_weight]+current_value,
			DP[i][total_weight-current_weight]+current_value);

		}

마지막 경우는 현재 아이템을 중복해서 담았을 경우를 생각한 것이다. 
0-1문제는 물건이 중복되어서 들어가는 경우는 없지만 무한 배낭 문제는 하나의 물건을 중복해서 넣을 수 있기 때문이다.

0-1문제에서 생각해보자.

<i = 1 일 때>

cw = 8
cv = 10

...

*total = 8일 때

DP[1][8] = max(DP[0][8],DP[0][0]+cv) 
	 = 10


*total = 9일 때

DP[1][9-18] = max(DP[0][9-18],DP[0][1-10]+cv,DP[1][1-10]+cv)

여기서 DP[1][9-15] 까지는 10으로 설정될 것이다. 그러나 DP[16-18]은 현재 물건을 중복해서 넣을 수 있다. 따라서 다음과 같다.

DP[1][16] = max(DP[0][16],DP[0][8]+cv,DP[1][8]+cv)
	   = max(0,10,20)

따라서 1번째 아이템을 고려했을 경우 16이상의 무게를 채울 수 있을 때 최대 가격이 되는 경우는 현재 아이템을 중복해서 가방에 넣는 것이다.

<i = 2일 때>

이제부터 중복해서 담는 경우들도 비교 대상이 되므로 위 의사 코드를 충족하게 된다. 예를 들어

DP[2][16] = max(DP[1][16],DP[1][12]+cv,DP[2][12]+cv)

첫 번째 아이템을 2개 담는 경우와 첫 번째 아이템까지 고려한 경우에서 현재 아이템을 추가한 경우, 또 현재 아이템이 중복으로 들어간 경우를 비교한다.

이 구현은 분명히 제대로 동작하지만, 가장 효율적인 구현은 아니다. 


<상태 공간 축소>

동적 계획법을 효과적으로 사용하는 데 있어 까다로운 측면 중 하나는 상태 공간 축소(state space reduction)개념이다. 이는 문제의 상태를 표현하기 위해 사용하는 공간의 크기가 최소화되도록 동적 계획법 알고리즘을 재구성하는 작업이다. 이 작업은 종종 주어진 문제의 본질 속의 특정 패턴을 찾거나 대칭을 이용하는 형태로 귀결된다.

상태 공간 축소 개념을 이해하기 위해 파스칼의 삼각형(pascal's triangle)에서 n번째 행,m번째 열위치의 값을 구하는 문제에 대해 생각해본다. 파스칼의 삼각형 일부를 다음에 나타낸다.

					1
				1		1
			1		2		1
		1		3		3		1
	1		4		6		4		1
1		5		10		10		5		1

...

파스칼의 삼각형은 다음 규칙에 의해 구성된다.

m>=n을 만족하는 두 정수 m과 n에 대해:

	기저 조건:

		m=1,m=n -> triangle(n,m) = 1

	순환식:

		triangle(n,m) = triangle(n-1,m-1) + triangle(n-1,m)

즉 모든 행의 첫 번째와 마지막 원소는 1이고, 나머지 원소는 이전 행의 같은 열과 이전 열에 있는 원소의 합으로 계산된다. 

테이블을 사용하여 n행, m열의 원소 값을 계산하는 소스 코드를 다음과 같이 작성할 수 있다.

vector<vector<int>> DP(N+1,vector<int>(N+1,0));

DP[1][1] = 1;

for(int row = 2; row <= N; ++row)
{

	for(int col = 1; col <= row; ++col)

	{

		DP[row][col] = DP[row-1][col-1]+DP[row-1][col];
	
	}

}

DP 테이블을 확인하면 매우 비효율적이라는 사실을 알 수 있다.

일단 1행의 벡터 크기는 N+1이지만 저장된 값은 하나이다. 2행도 확인해보면 두 개의 값만 저장되어 있다. 즉 낭비가 심하다는 것을 알 수 있다. 이 알고리즘은 메모리 사용량과 중복 계산 측면에서 상당히 비효율적이다. 이 테이블은
(N+1)개의 열을 가지고 있지만, 오직 하나의 행만 그만큼의 원소를 가지고 있을 뿐이다. 이러한 공간 복잡도는 각각의 행을 필요한 크기로 생성하는 방식으로 쉽게 줄일 수 있다. 즉, 테이블 구성에 필요한 메모리 크기를 N^2에서 
N*(N+1)/2로 줄일 수 있다. 이를 적용한 소스 코드는 다음과 같다.

vector<vector<int>> DP(N+1);

DP[1] = {0,1};

for(int row = 2; row <= N; ++row)

{

	DP[row].resize(row+1);

	for(int col = 1; col <= row; ++col)

	{

		int a = DP[row-1][col-1];

		int b = DP[row-1][min(col,DP[row-1].size()-1)];

		DP[row][col] = a + b;

	}

}

3행 3열 같은 경우를 계산할 때 2행의 크기는 3이므로 col=3을 인덱스로 사용할 수 없다. 따라서 DP[2].size()-1 값이 맞는 인덱스가 된다. 따라서 min함수를 사용해서 올바른 인덱스를 선택하는 것이다. 크기 축소를 하지 않은 이전 코드에서는 모든 vector의 크기가 N+1이므로 인덱스의 범위를 생각하지 않아도 된다.

DP[2][min(3,DP[2].size()-1 = 2)]

만약 2행 1열을 계산한다고 하면

DP[1][min(1,DP[1].size()-1 = 1)]
 
이 경우에는 min안의 값이 모두 같으므로 min함수가 역할을 하지 않아도 된다. 하지만 아까와 같이 행 끝 부분이 필요할 때는 정확한 인덱스가 필요하기 때문에 min함수를 사용하는 것이다.

파스칼의 삼각형을 좀 더 살펴보면 각 행의 절반이 서로 대칭인 것을 확인할 수 있다. 이러한 특성을 이용하면 n행에 대해 (n/2)열에 해당하는 원소만 계산해도 된다. 즉, 다음 수식이 성립한다.

DP(7,7) = DP(7,1)
DP(7,6) = DP(7,2)

DP(7,5) = DP(7,3) 

이러한 수식을 일반화하면 다음과 같이 정리할 수 있다.

DP(N,M) = DP(N,N-M+1)

이러한 특성을 적용하여 소스 코드를 다음과 같이 바꿔쓸 수 있다.

vector<vector<int>> DP(N+1);

DP[0] = {0, 1};

for(int row = 1; row <= N; ++row)

{

	int width = (row / 2) + (row % 2);

	DP[row].resize(width+2);

	for(int col = 1; col <= width; ++col)

	{
		
		//이전 행의 size와 현재 행의 size는 1차이가 난다.

		//따라서 이전 행에서 세그멘테이션 오류는 나지 않는다.

		//또한 width만큼만 테이블을 업데이트하면 된다.

		//대칭 구조이기 때문이다.
	
		DP[row][col] = DP[row-1][col-1] + DP[row-1][col];

	}

	if(row % 2 == 0)

	{
		
		//짝수 행에서는 중간에 연속적으로 같은 원소가 등장한다.

		DP[row][width+1] = DP[row][width];

	}

}

...

for(int i=0; i<queries; ++i)

{

	int N,M;

	cin>>N>>M;

	//각 행의 중간을 넘어가는 열에 대해서는 대칭을 이용하여 미리 계산	
 
 	//된 열을 출력한다.

	if(M*2>N)

	{

		M=N-M+1;

	}

	cout<<DP[N][M]<<endl;

}

만약 파스칼의 삼각형에서 특정 원소만을 알고 싶다면 DP 테이블 전체를 저장할 필요가 없다. 현재 행의 원소를 알기 위해서는 바로 이전 행 원소만 필요하기 때문이다. 이를 코드로 구현하면 다음과 같다.

map<pair<int,int>,int> results;

vector<pair<int,int>> queries;

int q;

cin>>q;

int maxRow = 0;

for(int i = 0; i < q; ++i)

{
		
	int N,M;

	cin>>N>>M;

	//검색할 원소를 queries에 저장한다.

	queries.push_back({N,M});

	if(M*2 > N)

	M = N-M+1;

	//result는 DP테이블에 해당한다.	

	result[{N,M}] = -1;

	//maxRow는 입력된 원소 중에서 가장 큰 행 값을 저장하는 것이다.
	
	//그래야 아래 코드에서 해당 행까지 테이블을 업데이트할 것이다.
	
	//즉 구하고자 하는 행 이후의 테이블은 사용하지 않으므로 업데이트

	//하지 않는다.

	maxRow = max(maxRow,N);

}

vector<int> prev = {0,1};

for(int row = 1; row <= maxRow; ++row)

{

	//1행에 대해서 curr[1]까지만 실행된다.

	//curr[1] = prev[0] + prev[1] -> 1
 
	//파스칼 삼각형에서는 이전 행 과 다음 행 의 원소 관계식은 다음과 같다.

	int width = (row/2) + (row % 2);

	vector<int> curr(width + 2);

	for(int col = 1; col <= width; ++col)

	{

		curr[col] = prev[col-1] + prev[col];

		//만약 검색하고자하는 원소라면 테이블을 업데이트한다.

		if(result.find({row,col}) != result.end())

		{

			results[{row,col}] = curr[col];

		}

	}

	if(row % 2 == 0)

	{

		curr[width + 1] = curr[width];

	}

	//계산이 끝난 현재행을 다음 반복에서 이전행 prev로 사용하기 위해서 move를 사용해서 전달한다.	

	prev = move(curr);

}

for(auto query : queries)

{

	int N = query.first, M = query.second;

	if(M*2>N)

	M = N-M+1;

	cout<<results[{N,M}]<<endl;

}

이제 다시 무한 개수 배낭 문제로 돌아온다.

용량 -> 12

가격 -> {5 1 6 3 4 }

무게 -> {3 2 4 5 2}

가방 용량과 물건 정보가 위와 같이 주어질 경우, 앞 절에서 설명한 무한 개수 배낭 문제의 DP 테이블은 파스칼 삼각형에서 최적화하지 않은 테이블처럼 빈 공간이 많다.

DP테이블을 만들기 위해 사용한 로직은 앞서 0-1 배낭 문제를 풀기 위해 사용했던 방법을 기반으로 한다. 그러므로 i번째 물건과 무게 weight에서 가능한 최대 가격 합 DP(i,weight)는 다음과 같이 구할 수 있다.

1.DP(i-1,weight) : 현재 물건을 포함하지 않는 경우로, i-1번째 물건과 같은 weight를 고려할 때와 같은 최대 가격 합

2.DP(i-1,weight-w)+value: 현재 물건을 새로 포함하는 경우로, 현재 물건의 가격 value를 i-1번째 물건을 고려할 때의 최대 가격 합에 더한 값

3.DP(i,weight-w)+value: 현재 물건을 중복해서 포함하는 경우로, 현재 물건의 가격 value를 i번째 물건을 고려할 때의 최대 가격 합에 더한 값

처음 두 조건은 0-1배낭 문제에서 나왔던 로직이다. 그러나 무한 개수 배낭 문제라는 점을 고려하고 앞서 알고리즘에 의해 생성된 DP테이블을 확인해보면 처음 두 조건은 본질적으로 이 문제와는 무관하다는 점을 알 수 있다.

0-1배낭 문제에서는 i번째 물건을 포함할지 말지를 결정하기 위해(i-1)개의 물건들만 고려했다. 그러나 무한 개수 배낭 문제에서는 선택된 물건들의 무게 합이 배낭 용량을 초과하지 않는 한 모든 물건을 고려해야 한다.

즉 상태 전환을 나타내는 조건은 오직 무게에만 의존하며, 이 때문에 1차원 테이블로 표현할 수 있다.

여기서 중요한 차이를 반드시 이해해야 한다. 즉, 상태를 시뮬레이션하는 데 필요한 차원과 상태를 표현하는 데 필요한 차원이 반드시 같아야 하는 건 아니다. 지금까지 살펴본 모든 동적 계획법 문제는 상태를 캐시에 저장하기 위해 상태 자체와 같은 형식을 사용했다. 그러나 무한 개수 배낭 문제에서는 각각의 상태를 다음과 같이 기술할 수 있다.

“무게가 w이고 가격이 v인 물건이 있을 때, 용량이 C인 배낭에 들어갈 수 있는 최대 물건 가격은 용량이 C-w인 배낭에 들어갈 수 있는 최대 물건 가격에 v를 더한 것과 같다.”

다음과 같은 입력에 대해 생각해본다.

용량 -> 12

가격 -> {5,1,6,3,4}

무게 -> {3,2,4,5,2}

중복을 허용함으로써 배낭의 최대 용량을 초과하지 않는 한 특정 번호의 물건 추가를 배제할 필요가 없다. 그러므로 무게 합이 0번 인덱스에서 발견될 수 있는지, 또는 1000번 인덱스에서 발견될 수 있는지 여부는 중요하지 않다. 무게 합이 배낭 용량을 초과하지 않는 한 배낭을 그대로 두지 않을 것이기 때문이다. 이는 물건 인덱스를 더 이상 사용할 필요가 없음을 의미하며, 결국 캐시 공간을 1차원으로 처리할 수 있다. 여기서 1차원은 임의 개수 물건들로 구성된 무게 합을 의미한다. 

# Maximizing_Profit 

우리가 대형 백화점 체인점에서 일하고 있다고 가정한다. 다른 상점과 마찬가지로 우리 상점도 도매 유통업체로부터 대량으로 물품을 구매한 후, 더 높은 가격에 판매하여 수익을 낼 수 있다. 우리 상점에서 판매하고 있는 상품들은 여러 유통업체에서 구입할 수 있으며, 다만 각 상품의 품질과 가격이 서로 다르기 때문에 소매 가치에 영향을 준다. 환율과 공공 수요와 같은 요소들을 고려하면 특정 유통업체로부터 실제 소매 가격보다 훨씬 더 낮은 가격으로 상품을 구매할 수 있다. 이제 우리는 할당된 예산에서 얻을 수 있는 최대 이익을 계산하는 시스템을 설계해야 한다.

우리는 상품 카탈로그를 받았으며, 여기에는 다음과 같은 정보가 적혀 있다.

*상품의 도매 가격

*소매 가격 책정 후 해당 상품을 판매하여 얻을 수 있는 수익 금액

*유통 업체가 판매하는 제품의 단위 수량

유통 업체가 지정된 수량으로만 제품을 판매한다. 이제 우리는 카탈로그에 나열된 제품의 일부 상품을 구입하여 만들어낼 수 있는 최대 금액을 결정해야 한다. 카탈로그에 나열된 각 항목은 한 번만 구매할 수 있다. 그리고 우리는 상점의 창고는 공간이 제한되어 있기 때문에 구매한 제품의 전체 개수가 창고 용량을 초과하지 않도록 해야 한다.

*입력

첫 줄은 세 개의 정수 N, budget, capacity가 적혀 있다. N은 유통업체 수, budget은 최대 가용 예산, capacity는 구매할 수 있는 상품의 최대 수량을 의미한다.

그 다음 N개의 줄에는 다음 항목을 나타내는 세 정수 값이 빈칸으로 구분되어 나타난다.

-quantity: 유통 업체가 제공하는 단위 수량

-cost: 상품 가격

-value: 제품을 판매한 후 얻을 수 있는 이익

*출력

카탈로그에서 일부 항목을 선택하여 얻을 수 있는 최대 이익을 출력한다.

*문제 해결 가이드라인

-필요한 구현 사항은 0-1 배낭 문제와 유사하다.

-capacity와 budget 두 개의 제약 사항이 있으므로, DP테이블은 3차원이어야 한다.

다른 동적 계획법 문제와 마찬가지로 기저 조건과 상태를 정의해야 한다. 선택된 상품들은 다음 조건을 만족해야 한다.

-선택된 상품의 가격 합은 정해진 예산(budget)을 넘지 않아야 한다.

-선택된 상품의 수량은 창고 용량을 넘지 않아야 한다.

-선택된 상품의 이익 합이 최대가 되어야 한다.

이러한 조건이 주어졌을 때, 각각의 상태는 다음과 같은 매개변수를 이용하여 정의할 수 있다.

-현재 고려하고 있는 상품

-이전에 구입한 상품 개수

-구입한 상품의 전체 가격

-상품을 소매로 판매했을 때 얻을 수 있는 전체 이익

탐색을 종료할 수 있는 기준은 다음과 같다.

-모든 상품을 고려한 경우

-전체 금액이 예산을 초과한 경우

-전체 수량이 용량을 초과한 경우

0-1배낭 문제와 마찬가지로 이 문제도 0에서 (N-1)까지의 항목을 선형으로 고려해야 한다. i번째 인덱스 항목에 대해, 상태 변환은 현재 상품을 선택하거나 또는 그대로 놔두는 방법중 하나를 선택할 수 있다. 상태 변환 로직을 의사 코드로 작성하면 다음과 같다.

F(i,count,cost,total):

*i->현재 아이템 인덱스

*cost->현재까지 구매한 상품 금액

*count->현재까지 구매한 상품 수량

*total->현재 선택한 상품에서 얻을 수 있는 전체 이익

기저 조건:
	
	만약 i == N이면: return total

	만약 cost > budget이면: return 0

	만약 count > capacity이면: return 0

순환식:

	F(i,count,cost,total) = 다음 중 최댓값:

		F(i+1,count+quantity[i],cost+price[i],total+value[i]) - 현재 상품 포함하기

		F(i+1,count,cost,total) - 그대로 놔두기


앞에 나온 코드처럼 순환식은 i,count,cost,total값에 의해 결정된다. 이러한 하향식 로직을 상향식으로 변경하면 다음과 같다.

기저 조건:

	DP(0,0,0) = 0 [아무 상품도 선택되지 않은 상태]

For i = 1 to N:

	Product->quantity,price,value

	For cost = 0 to capacity:

		만약price가 cost보다 크거나 또는 quantity가 count보다크면:

			DP(i,cost,count)=DP(i-1,cost,count)

		그렇지 않으면:

			DP(i,cost,count) = 다음 중 최댓값:

				DP(i-1,cost,count)

				DP(i-1,cost-price,count-quantity)+value

즉, 각각의 상태는 현재 인덱스, 상품 구매 비용, 상품 개수에 의해 결정된다. 유효한 cost와 count값에 대해 i번째 상품에서의 이익은 같은 cost와 count값에 대한 i-1번째 상품에서의 이익(DP[i-1][cost][count])와 같거나 또는 i번째 상품을 추가할 경우에 나타날 수 있는 이익(DP[i-1][cost-price][count-quantity]+value)와 같다.

# 2023.09.07

# Double-Ended_Queue(Deque)

Deque 자료구조는 배열을 순환식으로 구성하여 양방향 접근이 가능하게 한다. 이 때 순환식 구조를 구현하기 위해 front와 rear의 업데이트를 덱의 크기인 SIZE에 대해서 %연산을 이용한다. 또한 가득 찬 경우에는 마지막 칸을
비워두기 때문에 원형을 유지할 수 있다.

# Circle_Queue (using Deque)

Deque 자료구조를 사용하여 어댑터 컨테이너인 Queue를 구현하였다. Deque에서 선입선출 구조를 지원하기 위해 단방향 삽입,삭제 인터페이스만 지원하였다.

# Stack (using Deque)

Deque 자료구조를 사용하여 어댑터 컨테이너인 Stack을 구현하였다. Stack에서 후입선출 구조를 지원하기 위해 단방향 삽입,삭제 인터페이스만 지원하였다.

# Shortest_Path using Dynamic Programming

벨만-포드 알고리즘을 더 잘 이해하는 방법 중 하나는 이를 하향식 솔루션으로 변환하는 것이다. 이를 위해 먼저 기저 조건에 대해 생각해본다. 벨만-포드 알고리즘은 보통 for문을 이용하여 그래프 전체 에지에 대해(V-1)번의 반복을 수행한다. 이전에 구현한 방식에서는 0부터 (V-1)까지 반복을 수행했으므로 하향식 해법으로 바꾸면 (V-1)부터 0까지 감소하면서 반복을 수행한다. 순환 구조 관점에서 각각의 상태는 다음과 같이 기술할 수 있다.

ShortestPath(node,depth)

node -> 현재 정점

depth -> 현재 반복수

첫 번째 기저 조건은 다음과 같이 정의할 수 있다.

만약 depth = 0이면:

	ShortestPath(node,depth) -> UNKNOWN

즉, depth가 0으로 감소하면 경로가 존재하지 않는다고 결론을 내리고, 탐색을 종료한다.

두 번째 기저 조건은 시작 정점에서 목표 정점까지의 경로를 찾은 경우이다. 이때 탐색의 깊이는 중요하지 않다. 목표 정점에서 시작하는 최단 거리는 당연히 0이다.

만약 node = target이면:

	ShortestPath(node,depth) -> 0

이제 중간 상태 정의에 대해 생각해본다. 벨만-포드 알고리즘에서 사용되는 순환식은 다음과 같다.

i를 1부터 V-1까지 증가시키면서:

	그래프 모든 에지에 대해:

		edge -> u, v, weight

			만약 distance(u)가 UNKNWON이 아니고, distance(u)+weight<distance(v)이면:

				distance(v) = distance(u) + weight

이를 재귀 호출 관점에서 다시 작성하면 다음과 같다.

현재 정점과 연결된 모든 에지에 대해:

	edge -> neighbor,weight

	만약 ShortestPath(neighbor,depth-1)+weight < ShortestPath(node,depth)이면:
		ShortestPath(node,depth) =shortestPath(neighbor,depth-1)+weight

모든 상태는 2차원 공간에서 유일한 형태로 표현될 수 있고 사이클로 인해 같은 상태를 두 번 이상 만나게 될 가능성이 있다. 그러므로 메모이제이션 방법을 위해 상태를 node와 depth의 쌍으로 저장하는 것은 유효하고, 또한 유용하다고 결론 지을 수 있다.

Depth = 7:
	
	SP(0,7): 0

	SP(1,7): 6

	SP(2,7):UNKNOWN

	SP(3,7): 12

	SP(4,7): UNKNOWN

	SP(5,7): UNKNOWN

	SP(6,7): 13

	SP(7,7):UNKNOWN

...

# 2023.09.08

# Floyd-Warshall Algorithm(Shortest-path)

<모든 쌍 최단 경로>

memoization을 사용한 최단 거리 알고리즘은 벨만-포드 알고리즘을 V번 호출하는 것과 같다. 또한 재귀호출로 인해서 메모리 사용량 측면에서 단점이 있다.

다행히도 O(V^3)의 시간복잡도와 O(V^2)의 메모리 사용량으로 동작하는 상향식 알고리즘이 존재한다. 이 방법은 매우 직관적이다.


<플로이드 - 워셜 알고리즘>

이제 벨만-포드 알고리즘이 최단 경로 문제에서 최적 부분 구조를 어떻게 활용하는지 이해할 수 있을 것이다.

중요한 것은 그래프의 두 정점 사이의 최단 경로가 출발 정점에서 시작하는 다른 최단 경로와 최종 목표 정점으로 연결된 에지의 조합으로 구성된다는 점이다.

플로이드 워셜 알고리즘(Floyd-Warshall algorithm)은 이러한 개념에 좀 더 광범위한 일반화를 적용함으로써 큰 효과를 얻는다.

“정점 A와 정점 B사이의 최단 거리가 AB이고 정점 B와 정점 C사이의 최단 거리가 BC이면, 정점 A와 정점 C사이의 최단 거리는 AB+BC이다.”

이 논리는 확실히 그 자체로 획기적인 것은 아니다. 그러나 이 논리와 V-1번의 반복을 통해 최단 거리를 구하는 벨만-포드 알고리즘을 결합하여 사용할 수 있다. 즉 먼저 정점 A에서 나머지 모든 정점까지의 최단 경로를 구하고, 이 결과를 이용하여 점진적으로 정점 B,C,D등에서 시작하는 잠재적인 최단 경로를 구할 수 있다. 

플로이드-워셜 알고리즘은 정점들에 대해 V^3만큼 반복하여 결과를 얻을 수 있다. 여기서 첫 번째 차원은 A정점과 C정점 사이에 있는 정점 B를 나타낸다. 이 알고리즘은 현재까지 구한 A에서 C까지의 거리가 A에서 B까지의 거리와 B에서 C까지의 거리를 합한 값보다 큰지를 검사한다. 만약 그렇다면, 해당 합계가 A에서 C까지의 최적의 최단 거리에 더 적합하기 때문에 이 값을 캐시 테이블에 저장한다. 플로이드-워셜 알고리즘은 그래프의 모든 정점을 중간 정점으로 사용하면서 지속적으로 결과 정확도를 향상시킨다. 모든 정점을 시작 정점과 목표 정점으로 사용하고, 동시에 모든 정점을 중간 정점으로 사용하면서 테이블에는 모든 정점 쌍 사이의 최단 거리가 저장된다.

다른 그래프 알고리즘과 마찬가지로 플로이드-워셜 알고리즘도 모든 상황에서 최선의 선택이라고 보장할 수는 없으며, 또한 다른 대안 알고리즘과 복집도를 고려해봐야 한다. 일반적으로 많은 수의 에지로 구성되어 있는 밀집 그래프(dense graph)에서는 플로이드-워셜 알고리즘을 사용하는 것이 좋다. 예를 들어 100개의 정점과 500개의 에지가 있는 그래프가 있다고 가정한다. 최악의 경우 O(V*E)의 복잡도를 갖는 벨만 포드 알고리즘을 각각의 정점을 시작 정점으로 취급해서 실행하면 100*100*500=5000000번의 연산이 필요하다. 반면에 플로이드-워셜 알고리즘은 100*100*100 = 1000000번의 연산이 필요하다. 다익스트라 알고리즘은 보통 벨만-포드 알고리즘보다 더 효율적이며, 대안으로 사용할 수도 있다. 그럼에도 플로이드-워셜 방법이 가지고 있는 뚜렷한 장점은 다른 그래프 특성에 관계없이 전체 복잡도가 항상 O(V^3)이라는 것이다. 그러므로 플로이드-워셜 알고리즘이 얼마나 효율적으로 동작할 것인지를 가늠하기 위해서는 오직 그래프의 정점 개수만 알면 된다.

마지막으로 고려할 점은 벨만-포드 알고리즘과 마찬가지로 플로이드-워셜 알고리즘도 음수 에지 가중치가 있는 그래프에서도 동작하지만, 음수 에지 사이클에 대해서는 별도의 처리를 수행해야 한다.

# Residential_Roads using Floyd-Warshall

<실습 문제 23: 도로 건설>

우리는 대규모 고급 주택 단지 건설을 계획 중인 부동산 개발 프로젝트 책임자이다. 우리는 개발될 부동산에 대한 다양한 정보를 제공받았고, 이를 활용하여 최대한 저렴하게 도로 시스템을 설계해야 한다. 많은 주택 단지가 호수, 숲 및 산이 많은 지역에 건설될 예정이다. 이러한 지역에는 지반이 너무 단단해서 단지 건설이 훨씬 더 복잡해질 수 있다. 건설 비용은 지반 강도에 영향을 받는다고 알려져 있다. 일단 도로가 건설되는 위치의 지반 강도와 관련하여 비용이 선형으로 증가한다고 고려해야 한다.

우리가 제공받는 정보는 다음과 같다.

*부동산 지도

*주택을 건설할 좌표

*각 좌표에서 지반 강도

또한 도로 건설 방법을 결정하기 위한 다음의 지침도 제공되었다. 

*도로가 건설될 지점은 “.”문자로 표시된다.

*도로는 수평,수직,대각선 경로에 있는 두 집 사이에만 건설될 수 있다.

*단지 내의 모든 집은 다른 나머지 집에 모두 접근할 수 있어야 한다.

*도로는 강, 산, 숲 등을 가로질러 건설할 수 없다.

*두 집 사이에 도로를 건설하는 데 필요한 비용은 두 집을 잇는 경로상의 지반 강도 합과 같다.

*도로는 지정된 단지 입구까지 가장 낮은 비용으로 이동할 수 있도록 건설해야 한다.

*단지 입구는 항상 입력에서 가장 마지막 집이다.

집과 도로의 위치가 결정되면 다음 규칙에 따라 새 버전의 지도를 만들어 출력해야 한다.

*주택은 입력 순서에 따라 영문 대문자로 표시한다. 즉, 0 == A, 1 == B, 2 == C 등으로 표기한다.

*도로는 방향에 따라 |,-,/,\ 중 하나의 문자료 표현되어야 한다. 만약 방향이 다른 두 도로가 교차한다면 + 문자로 표시해야 한다.

*지도에서 다른 모든 것들은 처음 입력에서 제공된 것 그대로 표시되어야 한다.

입력

*첫 번째 줄에는 지도의 높이와 너비를 나타내는 두 정수 H와 W가 빈칸으로 구분되어 적혀 있다.

*두 번째 줄에는 지어야 할 집의 수를 나타내는 정수 N이 적혀 있다.

*그다음 H개 줄에는 지도의 각 행을 나타내는, 길이 W의 문자열이 나타난다. 도로를 건설할 수 있는 위치는 “.”문자로 표시된다.

*그다음 H개 줄에는 지도의 지반 강도를 나타내는 정수가 W개씩 나타난다.

*그다음 N개 줄에는 주택의 좌표를 나타내는 정수 x와 y가 적혀 있다. 마지막 인덱스 (N-1)은 단지의 입구를 나타낸다.

출력

*각 집의 위치는 A,B,C.. 순서의 대분자로 레이블을 지정해야 한다. 여기서 A,B,C...문자는 0- 기반 인덱스와 대응된다.(즉 0==A,1==B,2==C 등)

*두 집을 연결하는 도로는 다음 규칙에 맞게 출력한다.

*도로가 가로 방향이면 ‘-’문자

*도로가 세로 방향이면 ‘|’문자

*도로가 대각 방향이면 ‘/’또는 ‘\’문자

*서로 다른 방향의 도로가 한 지점에서 교차하면 ‘+’문자

문제 해결 가이드라인

*최종 결과를 얻으려면 몇 가지 단계가 필요하다. 곧바로 구현하기에 앞서 필요한 단계를 개략적으로 구상하는 것이 좋다.

*프로그램의 각 부분에서 테스트 결과를 출력하거나 디버깅 방법을 고안하는 것이 큰 도움이 될 수 있다. 프로그램 초기에 실수가 있으면 후속 단계가 실패로 이어질 수 있다.

*어떤 작업이 필요한지 이해하기 어렵다면 더 간단한 입력과 출력을 사용하여 구현해라.

*이전 장에서 논의했던 알고리즘 중에서 필요한 것부터 구현을 시작해라. 이 문제 해결을 위한 각 단계는 여러 방법에 의해 구현할 수 있다. 창의력을 발휘해라.

이번 문제는 신중하게 접근하지 않으면 많은 어려움을 겪을 수 있다. 가장 어려운 점은 여러 단계가 필요하다는 점이고, 부주의한 실수에 의해 전체 프로그램이 실패할 수도 있다. 따라서 각 단계를 차근차근 풀어나가는 과정이 필요하다. 필요한 기본 단계는 다음과 같다.

1.입력 처리하기

2.그래프 구성하기

3.그래프 정점 사이의 최단 거리 찾기

4.경로 재구성

5.지도 다시 그리기

#
0단계: 선행 작업

입력과 관련된 코드를 작성하기에 앞서 데이터를 어떻게 표현할 것인지를 미리 결정해야 한다. 입력으로 주어지는 값은 다음과 같다.

*지도의 높이와 너비를 나타내는 두 개의 정수 H와 W

*단지 내 주택 수를 나타내는 정수 N

*단지 내 지도를 나타내는 H개의 문자열, 각 문자열의 길이는 W이다. 이 데이터를 H개의 문자열 벡터에 저장할 수 있다.

*지반의 강도를 나타내는 정수 행렬, 각각의 정수는 한 줄에 W개씩,H줄로 구성된다. 이 값들은 정수 행렬에 저장할 수 있다.

*주택의 좌표를 나타내는 N행, 각 행은 두 개의 정수 x와 y로 구성된다. 이 데이터를 저장하기 위해 Point라는 간단한 구조체를 만들어 사용할 수 있다.

#
2단계: 그래프 구성하기

문제 설명은 다음과 같다.

*도로는 수평,수직,대각선 경로에 있는 두 집 사이에만 건설할 수 있다.

*도로는 강, 산, 숲등을 가로질러 건설할 수 없다.

*두 집 사이에 도로를 건설하는 데 필요한 비용은 두 집을 잇는 경로상의 지반 강도 합과 같다.

첫 번째 조건을 확인하려면 두 집의 좌료를 비교하여 다음 조건이 참인지를 검사하면 된다.

*A.x = B.x (수평 위치)

*A.y = B.y (수직 위치)

*|A.x-B.x| = |A.y-B.y| (대각 위치)


#
3단계: 그래프 정점 사이의 최단 거리 찾기

이 문제에서는 모든 집이 단지 입구까지 가장 낮은 비용으로 이동할 수 있도록 도로가 건설되어야 한다. 이를 위해 플로이드-워셜 알고리즘을 사용할 수 있다.

#
4단계:

LCS 또는 0-1배낭 문제에서 사용되었던 재구성 방식과 next행렬에 저장된 값을 이용하여 각 경로상의 좌표를 재구성할 수 있다. 이를 위해 새로운 함수 GetPath()를 정의한다. 이 함수는 두 개의 정수 start와 end,그리고 next행렬 참조를 인자로 받고, 경로상의 정점 인덱스를 저장한 정수형 벡터를 반환한다.

#
5단계: 지도 그리기

지도를 그리기 위한 함수들을 정의하여 마무리한다.

# 2023.09.11

# Bloom-Filter

블룸 필터는 해시 테이블에 비해 공간 효율이 매우 높은 방법이지만, 결정적 솔루션 대신 부정확한 결과를 얻을 수 있다. 블룸 필터는 거짓-부정(false nagative)이 없다는 것은 보장하지만, 거짓-긍정(false positive)은 나올 수 있다. 즉, 특정 원소가 존재한다는 긍정적인 답변을 받을 경우, 이 원소는 실제로 있을 수도 없을 수도 있다. 그러나 특정 원소가 존재하지 않는다는 부정적인 답변을 받았을 때는 이 원소는 확실히 없다.

뻐꾸기 해싱과 마찬가지로 블룸 필터도 여러 개의 해시 함수를 사용한다. 보통 두 개의 해시 함수는 충분한 정확도를 기대하기 어렵기 때문에, 세 개 이상의 해시 함수를 사용해야 한다. 블룸 필터는 실제 값을 저장하지는 않으며, 대신 특정 값이 있는지 없는지를 나타내는 부울 타입 배열을 사용한다. 

원소를 삽입할 경우, 모든 해시 함수 값을 계산하고 부울 타입 배열에서 이 해시 값에 대응되는 위치의 비트 값을 1로 설정한다. 룩업의 경우, 모든 해시 값을 계산하고 이에 대응되는 위치의 비트 값이 1로 설정되어 있는지를 검사한다. 만약 검사한 모든 비트가 1이면 true를 반환한다. 1이 아닌 비트가 하나라도 있다면 false를 반환하고, 이는 해당 원소가 없음을 의미한다. 

그럼 블룸 필터가 왜 결정적이지 않은 것일까? 그 이유는 특정 비트가 다수의 원소에 의해 1로 설정될 수 있기 때문이다. 즉 특정 값x와 연관된 모든 비트가 이전에 삽입된 다른 원소 값들에 의해 모두 1로 설정되어 있을 가능성이 있다는 뜻이다. 이러한 경우 x에 대한 룩업 함수는 true를 반환한다. 이처럼 특정 원소가 있다고 잘못 판단하는 것을 거짓-긍정이라 한다. 원소 개수가 많아질수록 거짓-긍정이 발생할 확률이 높아진다. 그러나 x와 관련된 비트 중 하나라도 1로 설정되어 있지 않다면, x가 확실하게 없다고 말할 수 있다. 그러므로 거짓-부정은 발생할 수 없다.

부울 배열의 모든 원소가 true 또는 1로 설정될 경우, 이 배열은 포화상태가 된다. 이 상태에서 룩업 함수는 항상 true를 반환하고, 삽입 함수는 블룸 필터 상태에 아무런 영향을 주지 못한다.

출력 결과를 보면 거짓-긍정이 발견되지만, 거짓-부정은 나타나지 않은 것을 확인할 수 있다. main()함수와 bloom_filter 클래스 생성자 코드를 보면 이 프로그램에서 필요한 정보를 저장하기 위해 겨우 7비트만을 사용했다. 필터 크기를 좀 더 크게 설정하고 해시 함수를 보완하면 훨씬 더 나은 성능을 얻을 수 있다. 예를 들어 배열 크기를 소수인 1023으로 늘려도 실제로는 130바이트보다 작은 메모리를 사용하는 것이며, 이는 다른 방법보다는 훨씬 작은 메모리만 사용하는 것이다. 해시 테이블 크기를 1023으로 늘린다면, 해시 함수도 hash(x)=x%1023같은 형태로 사용할 수 있고, 이 경우 더 나은 숫자들의 분포와 결과를 얻을 수 있다. 

블룸 필터는 컨테이너에 실제 데이터를 저장하지 않기 때문에, 다양한 타입의 데이터에 대해서도 사용할 수 있다. 해시 함수를 충분히 잘 만들었다면 하나의 블룸 필터에 정수, 문자열, 실수등의 데이터를 섞어서 삽입할 수도 있다.

블룸 필터를 사용하기에 적합한 실제 상황을 꽤 많이 찾을 수 있다. 즉, 데이터양이 너무 많아서 해시 테이블조차도 사용하기가 버겁고, 거짓-긍정이 있어도 괜찮은 경우가 있다. 예를 들어 Gmail이나 Outlook같은 이메일 서비스 사이트에서 새로운 이베일 주소를 만들려고 할 때, 사용자가 입력한 이메일을 이미 다른 사람이 사용하고 있는지를 검사한다. 데이터베이스에 수십억 개의 이메일이 있을 경우, 이러한 기본적인 검사도 매우 빈번하게 수행해야 하기 때문에 성능에 영향을 줄 수 있다. 다행히 사용하고 있지 않은 이메일 주소를 사용 중이라고 한다고 해도 큰 문제는 없다. 사용자는 다른 이메일 주소를 새로 입력할 것이다. 이러한 경우에 블룸 필터를 사용하는 것이 좋은 선택일 수 있다. 이에 대한 좀 더 자세한 내용은 실습 문제에서 확인하겠다. 

페이스북 광고와 같은 새로운 추천 광고 선택 알고리즘도 블룸 필터를 사용하기에 적합한 예이다. 페이스북은 사용자가 매번 접속할 때마다 새로운 광고를 보여준다. 이 경우 사용자가 이미 보았던 모든 광고의 ID를 블룸 필터에 저장한다. 그리고 사용자가 다음 번 접속했을 때 특정 광고의 ID를 블룸 필터에서 검색한다. 만약 사용자가 보지 않았던 광고를 블룸 필터가 이미 보았다고 판단하더라도 단순히 해당 광고를 보여주지 않으면 그만이다. 사용자는 자신이 어떤 광고를 보지 않았는지 알 수 없기 때문이다. 따라서 큰 문제가 되지 않는다. 이러한 방식으로 매번 아주 빠르게 새로운 광고를 보여줄 수 있다.

# e-mail_duplicate_check using Bloom_Filter

이번 실습 문제에서는 Gmail이나 Outlook 같은 이메일 서비스 사이트에 가입할 때 볼 수 있는 이메일 주소 중복 검사 프로그램을 만들어 보겠다. 여기서는 블룸 필터를 이용하여 사용자가 입력한 이메일 주소가 이미 다른 사람이 사용하고 있는지 여부를 검사하겠다. 

실습 문제를 해결하기 위해 다음 단계를 따라가라.

1.해시 함수 개수와 블룸 크기를 지정할 수 있는 Bloomfilter 클래스를 생성한다.

2.OpenSSL 라이브러리의 MD5 알고리즘을 사용하여 주어진 이메일 주소로부터 해시 값을 생성한다. MD5는 128비트(16바이트) 해싱 알고리즘이다. MD5의 각 바이트를 해시 값으로 사용함으로써 해시 함수를 대체할 수 있다. 

3.블룸 필터에 이메일 주소를 추가하려면 2단계에서 계산한 해시 값의 모든 비트를 true로 설정해야 한다.

4,특정 이메일 주소를 검색하기 위해 2단계에서 계산한 해시 값의 모든 비트가 true로 설정되어 있어야 한다.

# Priority_Queue

<우선순위 큐>

우선순위 큐는 임의의 순서로 입력된 우선순위된 원소들을 저장하고 우선순위에 따라 출력하는 추상 데이터 타입이다. 즉 언제든지 저장된 원소들 중 가장 우선순위가 높은 원소가 삭제된다. 이 ADT(abstract data type) 추상 데이터 타입은 위치라는 개념이 없고 우선순위에 따라 원소들을 저장한다.

우리는 키를 원소들에게 속성으로서 주어진 객체라고 정의하며, 그 원소를 식별하거나 순위를 정하거나 또는 측정하는 데 사용된다. 보통 키는 사용자나 응용프로그램에 의해 어떤 원소에게 주어진다. 따라서, 키는 그 원소가 자연 상태에서는 소유하지 않았던 특성을 나타낸다. 키는 경우에 따라 단일 숫자로 정량화할 수 없는 좀 더 복잡한 특성을 지닌다. 예를 들어 대기 승객의 우선 순위는 보통 사용 고객 여부, 지불한 요금, 그리고 도착 시간 등의 여러 요건을 복합적으로 고려하여 결정한다. 어떤 응용프로그램에서는 객체의 키가 그 객체의 일부이다.(예를 들어 책의 가격이나 자동차의 무게와 같은 값들은 멤버 변수에 저장된다.)

*전체 순서(total orders)로 키 비교

우선 순위 큐는 항상 적용할 수 있는 비교 규칙이 필요하다. <=으로 표시되는 비교 규칙이 항상 적용되기 위해서는 전체 순서(total order)관계를 만족해야 한다. 전체 순서 관계는 모든 쌍의 두 키에 대하여 다음과 같은 특성을 만족해야 한다.

*반사성(Reflexive property): k<=k

*비대칭성(Antisymmetric property): 만약 k1<=k2이고 k2<=k1일 경우, k1=k2

*이행성(Transitive property): 만약 k1<=k2이고 k2<=k3일 경우, k1<=k3

위와 같은 세 가지 특성을 갖는 모든 비교 규칙은 모순되지 않는다. 사실, 이러한 규칙은 한 집합의 키에 대하여 선형 순위 관계를 정의한다. 따라서 유한한 원소들에 대하여 전체 순서가 정의되어 있으면, 최소 키(k min)의 개념이 정의된다. 최소 키는 집합의 모든 키 k에 대하여 k min <= k를 만족한다.

우선순위 큐는 원소들의 컨테이너로서 각 원소가 입력될 때 그와 연관된 키를 가지고 있다. “우선순위 큐”라는 이름은 원소를 제거할 때 키로 “우선순위”를 결정하는 것에서 유래되었다. 우선순위 큐 P의 두 기본적인 함수는 다음과 같다.

insert(e): 원소 e(내재적으로 연관된 키 값을 갖는)를 P에 삽입

min():가장 작은 연관된 키 값을 갖는 P의 원소를 반환. 즉, 키가 P의 모든 다른 원소의 키보다 작거나 같은 원소를 반환

removeMin():P에서 원소 min()을 삭제

하나 이상의 원소들이 같은 값을 가질 수 있기 때문에, removeMin()함수는 단지 가장 키가 작은 원소를 삭제하는 것이 아니라. min함수에 의해 반환되는 원소를 삭제하는 것으로 정의되었음을 유의하라.

#
*비교자

우선순위 큐의 구현에 있어 중요한 점은 키를 비교하기 위한 관계를 정의하는 것이다. 이 시점에서 키를 비교하기 위하여 우리가 선택할 수 있는 방법은 여러 가지가 있으며, 각각 장점과 단점이 있다.

한 가지 가장 직접적인 방법으로는 사용하려는 키의 종류와 그들을 비교하는 방법에 따라 다른 우선순위 큐를 만드는 것이다. 그러나 이러한 접근 방법의 문제점은 일반적인 해결이 되지 않을 뿐 아니라 유사한 많은 코드가 생성된다는 점이다. 거의 동일한 프로그램의 여러 복사본을 유지 보수하는 것은 힘들고 에러가 발생하기 쉽다. 보다 일반적인 접근 방법은 우선순위 큐를 템플릿화된 클래스로 가정하는 것이다. 여기서 각 원소 타입은 추상 템플릿 인수 E로 정의된다. 우리는 우선순위 큐의 원소로 사용할 수 있는 각 클래스가 타입 E를 갖는 두 개의 객체를 비교할 수 있는 수단을 제공한다고 가정한다. 방법에는 함수 객체를 사용하는 것이 있다.(function object - functor)

원소의 타입과 비교 방법을 독립적으로 만드는 목표를 달성하는 방법은 두 가지가 있다. 가장 일반적인 접근은 구성 방법(composition method)으로서 원소 e와 키 k로 이루어진 쌍(e,k)로 정의된 우선순위 큐의 각 엔트리에 기반한다. 원소 부분은 데이터를 저장하고, 키 부분에 정의된 정보로 우선순위 순서를 결정한다. 각 키 객체는 자신의 비교 함수를 정의한다. 키 클래스를 변경함으로써 우리는 큐의 정렬 방법을 바꿀 수 있다. 이 방법은 키 부분이 원소 부분의 데이터에 종속되지 않기 때문에 매우 일반적이다. 여기서 사용하는 방법은 구성 방법보다 약간 간단한 비교자를 사용하는 방법이다.

isLess()함수 객체가 존재한다고 가정하면, 다음 코드로 동등 비교를 수행할 수 있다. (!isLess(a,b) && !isLess(b,a)) 지금 구성할 우선순위 큐는 원소 E와 비교자 C에 의해 템플릿화된 일반 클래스이다.

비교자 접근 방법은 구성 방법보다 약간 덜 일반적이다. 그 이유는 비교자가 원소 자신들의 내용에 대한 판단을 기반으로 하기 때문이다. 구성 방법에서는, 키가 원소 객체의 일부분이 아닌 정보를 포함할 수 있다. 비교자 접근 방법은 더 간단하다는 장점을 갖는다. 왜냐하면 우리는 원소-키 쌍을 생성할 필요 없이 원소를 우선순위 큐에 직접 삽입할 수 있기 때문이다.

#
*우선순위 큐 ADT

우선순위 큐는 다음 함수를 지원한다.

size(): P에 있는 원소의 개수를 반환

empty(): P가 비어 있으면 참을 그렇지 않으면 거짓을 반환

insert(e): 새 원소 e를 삽입

min():P에서 가장 작은 키를 갖는 원소 e의 레퍼런스 반환(삭제하지는 않음), 우선순위 큐가 비어 있으면 에러

우선순위 큐의 구현을 논의하기 전에, 비정규적인 C++ 인터페이스를 정의한다. 이것은 완벽한 class는 아니고 단지 public 함수들의 선언이다.

template<typename E,typename C>

class PriorityQueue

{
public:

	int size() const;

	bool isEmpty() const;

	void insert(const E& e);

	const E& min() const throw(QueueEmpty);

	void RemoveMin() throw(QueueEmpty);

};

함수 min은 큐에 있는 원소의 상수 레퍼런스를 반환함을 유의하라. 따라서 이 값을 읽거나 복사는 가능하지만 수정은 안된다.

#
*우선순위 큐를 이용한 정렬

우선순위 큐의 다른 중요한 응용분야는 정렬이다. 전체 순서 관계에 따라 비교될 수 있는 n개의 원소들의 집합 L이 주어졌을 때, 이들을 오름차순으로 정렬하려 한다(또는 동률이 있다면 적어도 비내림차순으로). L을 우선순위 큐 Q를 이용하여 정렬하는 알고리즘은 Priority Queue Sort라고 불리는데 매우 간단하며, 다음 두 단계로 이루어진다.

1. 첫 단계에서, 처음에 비어 있는 우선순위 큐 P에 L의 원소들을 n번의 연속된 insertItem()연산에 의하여 한 원소에 대해 하나의 연산으로 삽입한다.

2. 두 번째 단계에서 n번의 연속된 min과 removeMin연산을 이용하여 P에서 각 원소를 비내림차순으로 하나씩 꺼내어 L에 다시 넣는다.

이 알고리즘의 의사 코드는 다음과 같다. 여기서 L은 STL 리스트로 가정하였으나, 프로그램은 다른 컨테이너에도 적응될 수 있다.

Algorithm PriorityQueue(L,P):

	입력: n개의 원소를 저장하는 리스트 L 그리고 전체 순서 관계를 이용해 키를 비교하는 우선순위 큐 P

	출력: 정렬된 리스트 L

while !L.empty() do

	e<-L.front()

	L.pop_front()

	P.insert(e)

while !P.empty() do

	e<-P.min()

	P.removeMin()

	L.push_back(e)


*STL priority_queue 클래스

priority_queue는 <queue>를 포함해야 하며 세 개의 매개변수로 템플릿화되었다. 원소의 기본 타입, 우선순위 큐가 저장된 바탕의 STL 컨테이너, 그리고 비교자 객체이다. 첫 번째 매개변수만이 필수적으로 필요하다. 비교자는 less-than연산자로 디폴트되어있다. 우선순위 큐의 주요 함수들이 아래 주어졋다. 

size()

empty()

push(e)

top()

pop()

함수 이름들이 다른 것 외에, 우리의 우선순위 큐와 STL의 우선순위 큐 사이의 가장 중요한 차이는 함수 top와 pop이 우선순위 순서에 의해 가장 작은 것이 아니라 가장 큰 원소에 접근한다는 점이다.

*리스트를 이용한 우선순위 큐의 구현

#
<비정렬 시퀀스를 이용한 구현>

우선순위 큐 P의 이중 연결 리스트 L에 의한 구현 방법을 고려한다. P의 insert(e)를 구현하는 방법은 새로운 원소를 L.push_back(e) 함수를 실행하여 리스트 L의 끝에 추가하는 것이다. 이러한 insert구현은 O(1)의 실행시간을 갖는다. 이 삽입은 키 값을 고려하지 않기 때문에 리스트 L은 정렬되지 않는다. 결과적으로 함수 min이나 removeMin을 P에서 실행하기 위해서는 리스트의 전체 원소들을 조사하여 최소 키 값을 갖는 원소를 찾아야 한다 따라서 함수 min과 removeMin은 각각 O(n)의 실행시간을 갖는다. 여기서 n은 함수가 실행될 시점에 P에 저장되어 있는 원소의 개수이다. 또한 각각의 함수는 최선의 경우에도 n에 비례하는 실행시간을 갖는다. 왜냐하면 그들은 각각 가장 작은 원소를 찾기 위해 전체 리스트를 검사하기 때문이다. 비정렬 리스트를 이용한 우선순위 큐에서 삽입은 상수 시간에 실행되고 접근과 삭제는 선형 시간이 소요된다.

#
<정렬된 시퀀스를 이용한 구현>

우선순위 큐 P를 구현하는 다른 방법 역시 리스트 L을 이용하는데, 이번에는 항목들이 키를 기준으로 정렬된 상태로 저장하는 경우를 설명한다. 구체적으로, 우리는 우선순위 큐 P를 원소들의 키값들이 비내림차순으로 정렬된 리스트 L로 표현한다. 따라서 L의 첫 번째 원소가 갖아 작은 키를 갖는다. 함수 min은 L의 begin함수를 이용하여 리스트의 첫 번째 원소에 접근하여 구현할 수 있다. 유사한 방법으로 P의 함수 removeMin도 L.pop_front()와 같이 구현할 수 있다. L이 Doubly_linke_list로 구현되었다고 가정하면, P의 연산 min과 removeMin은 O(1)시간이 되어 매우 효율적이다.

그러나 이러한 이점을 얻는 대가로 이번에는 P의 insert함수가 새로운 원소와 키를 삽입할 위치를 찾기 위하여 전체 리스트 L을 탐색하여야 한다. 따라서 P의 insert함수의 실행에 O(n) 시간이 필요하게 된다. 여기서 n은 이 함수가 실행되는 시점에 P에 저장된 원소의 개수이다. 요약하면, 정렬된 시퀀스를 이용하여 우선순위 큐를 구현할 경우, 삽입은 선형 시간에 실행되지만, 최소값의 탐색과 삭제는 O(1)이 소요된다.

다음은 insert의 구현이다.

template<typename E,typename C>

void ListPriorityQueue(const E& e)

{

	typename std::list<E>::iterator p;

	p=L.begin();

	while(p != L.end() && !IsLess(e,*p)

		++p;
	
	L.insert(e,p);

}

p를 리스트를 위한 반복자로 정의한다. 우리의 방법은 e의 키 값보다 큰 키를 갖는 첫 번째 원소를 찾을 때까지 리스트를 차례로 탐색한 다음 p의 바로 앞에 e를 삽입한다. *p로 p가 레퍼런스하는 원소에 접근하고, ++p는 리스트의 다음 원소로 이동한다. 우리는 리스트의 끝까지 왔거나 isLess(e,*p)를 만족하는 e보다 큰 원소를 처음 만났을 때 검색을 중지한다. 그러한 엔트리에 도착하면, STL 리스트의 함수 insert를 호출하여 e를 그 앞에 삽입한다.

e가 큐에 있는 어떤 원소보다 큰 키 값을 가질 때, 위 함수의 동작을 고려해본다. 그러한 경우에 p가 L.end()와 같은 조건에서 while반복절을 빠져나온다. 따라서 이 원소의 앞에 삽입함으로써, 결과적으로 리스트의 뒤에 추가하게 되어 원하는 결과를 얻는다.

리스트를 사용하는 코드는 repository에 있는 이중 링크드 리스트 코드를 사용하여 어댑터 컨테이너로 만들면 될 것이다.

#
<선택 정렬과 삽입 정렬>

우선순위 큐 P를 비정렬 시퀀스로 구현한다면, 첫 번째 단계는 O(n) 시간이 소요된다. 이것은 각 원소를 삽입하는 데 상수 시간이 소요되기 때문이다. 두 번째 단계에서, 두 키를 상수 시간에 비교한다고 가정하면, 각 min과 removeMin함수의 실행 시간은 현재 P에 포함된 원소의 개수이 비례한다. 따라서 이러한 구현 방법에서 병목 계산은 단계 2에서 비정렬 시퀀스로부터 최소값을 연속적으로 “선택”하는 것이다. 이러한 이유에서 이 알고리즘을 선택 정렬이라 한다. 위에서 언급된 바와 같이, 병목은 두 번째 단계에서 우선순위 큐 P로부터 가장 작은 키를 반복적으로 삭제하는 것이다. P의 크기는 n에서 출발하여 removeMin마다 하나씩 감소하여 결국 0이 된다. 따라서, 첫 번째 removeMin연산은 O(n)시간이 소요되고, 두 번째에는 O(n-1) 세 번째에는 O(n-2)와 같이 되어 마지막 n번째에는 O(1)시간이 소요된다. 결국, 두 번째 단계의 실행에 필요한 전체 시간은 O(n+(n-1)+...+2+1) 따라서 두 번째 단계는 O(n^2)이 소요되며, 이것이 전체 선택 정렬 알고리즘의 실행 시간이 된다.
위 알고리즘은 비정렬 리스트에서 원소들을 하나씩 꺼내어 우선순위 큐에 넣어 정렬된 원소들을 다시 하나씩 꺼내어 리스트에 넣어 정렬된 리스트로 만든다.

#
<삽입 정렬>

만약 정렬된 시퀀스로 우선순위 큐 P를 구현한다면, P에서 각 min과 removeMin연산은 O(1)시간이 소요되므로 두 번째 단계에서 실행시간을 O(n)으로 개선할 수 있다. 하지만, 이번에는 첫 번째 단계가 병목이 된다.

알고리즘에서 "병목(bottleneck)"은 전체 실행 시간 또는 성능을 제한하는 가장 느린 부분이나 제약 조건을 가리킨다. 즉, 알고리즘이나 프로그램의 실행 속도를 결정하는 주요 요소 중 하나이다.

병목은 일반적으로 시스템 내에서 가장 비효율적인 연산, 자원 사용 불균형, 혹은 처리량이 제한된 구성 요소 등으로 인해 발생할 수 있다. 이러한 병목 현상은 전체 알고리즘의 성능을 저하시킬 수 있으며, 최적화 작업의 대상이 된다.

예를 들어, 다음과 같은 상황에서 병목이 발생할 수 있다:

알고리즘이 큰 데이터 집합에 대해 반복 작업을 수행하는데, 그 중 한 연산이 다른 연산들보다 훨씬 오래 걸릴 때.
멀티스레드 환경에서 스레드 간 동기화 문제로 인해 전체 실행 시간이 지연되는 경우.
네트워크 통신에서 데이터 전송 속도가 네트워크 대역폭에 의해 제한되는 경우.
병목 현상을 해결하기 위해서는 해당 부분을 최적화하거나 개선하여 성능을 향상시켜야 한다. 이를 위해서는 프로파일링 도구를 사용하여 성능 분석을 수행하거나 코드의 구조와 알고리즘 설계를 재검토하여 병목 현상을 파악하고 개선 방법을 찾아야 한다.

각 insert연산의 실행시간은 최악의 경우 우선순위 큐에 저장되어 있는 원소의 개수에 비례하게 된다. 우선순위 큐의 원소 수는 0에서 시작하여 n까지 증가하게 된다. 마찬가지로 O(n^2)이 소요된다.

만약 위 정렬의 실행시간을 어떻게든 균형있게 할 수 있다면, 전체 정렬 시간을 획기적으로 단축할 수 있을 것이다. 우선순위 큐를 효율적으로 구현하기 위해서 힙이라는 자료구조를 이용한다. 이 자료구조는 삽입과 삭제를 로그 시간에 실행하는데, 이것은 위에서 설명한 실행시간보다 획기적으로 개선된 것이다. 힙이 이러한 개선을 할 수 있는 근본적인 방법은 원소와 키를 리스트에 저장하지 않고 대신 이진 트리에 저장하는 것이다.

#
<힙 자료구조>

힙은 키들을 내부 노드들에 저장하는 이진 트리 T이며 다음과 같은 두 가지 추가적인 특성을 갖는다. 키들의 T에 저장되는 방법으로 정의되는 관계적인 특성과 T의 노드 자체에 정의되는 구조적인 특성이다. 비교자와 같은 키들의 전체 순서(total order)관계가 주어졌다고 가정한다. 키들이 저장되는 방법으로 정의되는 T의 관계적인 정의는 다음과 같다.

힙-순서 특성(heap - order property): 힙 T에서 루트를 제외한 모든 노드 v에 대하여, v에 저장된 키는 v의 부모에 저장된 키보다 크거나 같다.

이러한 힙-순서 특성으로 인해 T의 루트에서 한 외부 노드로 연결되는 경로에서 키들은 감소하지 않는 순서가 된다. 또한 최소값을 갖는 키는 항상 T의 루트에 저장된다. 이것이 가장 중요한 키이고 흔히 “힙의 꼭대기에”라고 말한다. 여기서 이 자료구조의 이름 "힙“이 유래되었다. 왜 힙의 꼭대기에 가장 큰 값이 아닌 가장 작은 값을 정의하였는가 하고 의아해할 수 있다. 그것은 임의의 결정이다. STL 우선순위 큐는 정확히 반대로 정의되었다. 비교자가 두 키 사이에 less-than 관계를 구현했다는 것을 상기하자. 만약 우리가 비교자를 표준적인 전체 순서 관계와 반대로 정의하면 힙의 루트에 최대값이 저장될 것이다. 

효율성을 위하여 우리는 힙 T의 높이를 가능한 한 작게 만들어야 한다. 이러한 이유에서 다음과 같은 힙 T의 구조적 특성이 필요하다. 힙은 완전이어야 한다. 이러한 구조적 특성을 정의하기 전에 몇 가지 정의가 필요하다. 이진 트리 T의 레벨 i는 깊이 i를 갖는 모든 T의 노드의 집합이다. T의 같은 레벨에 노드 v와 w가 주어졌을 때 만약 중위 순회에서 v를 w보다 먼저 만난다면 v가 w의 왼쪽에 있다고 한다. 즉, v는 T의 한 노드 u의 왼쪽 서브트리에 속하고 w는 u의 오른쪽 서브트리에 속하는 u가 존재한다.

*완전 이진 트리 특성:만약 레벨 0,1,2...,h-1들이 가질 수 있는 최대 수의 노드를 포함하고(즉, 레벨 i는 2^i노드를 포함, 이때 0<=i<=h-1) 레벨 h-1에서 모든 내부 노드는 외부 노드들의 왼쪽에 위치한다면, 높이 h인 이진 트리 T는 완전하다.

*힙의 높이: T의 높이를 h라 하자. T의 마지막 노드를 정의하는 다른 방법은 그것이 레벨 h에 있으며 같은 레벨의 다른 노드들이 모두 그것의 왼쪽에 있다는 것이다. T가 완전할 때 다음과 같은 주요한 특성을 가진다.

n개의 키를 저장하는 힙 T의 높이는 다음과 같다.

h=[log n]

완전 이진 트리의 add의 동작은 다음과 같이 두 가지가 있다.

*만약 T의 바닥 레벨이 꽉 차지 않았다면, add는 T의 바닥 레벨의 가장 오른쪽에 있는 노드(즉, 마지막 노드)의 바로 다음에 새 노드를 삽입한다. 따라서 T의 높이는 변하지 않는다.

*만약 T의 바닥 레벨이 꽉 찼다면 add는 T의 바닥 레벨의 가장 왼쪽에 있는 노드의 왼쪽 자식으로 새 노드를 삽입한다. 따라서, T의 높이는 1 증가한다.

#
<완전 이진 트리의 벡터 표현>

벡터-기반한 이진트리의 표현이 완전 이진트리 T의 표현에 특히 적절하다. 이 방법은 T의 노드를 벡터 A에 저장하는데 인덱스는 다음과 같은 레벨 번호 f(v)와 같다.

*만약 v가 T의 루트이면, f(v) = 1

*만약 v가 노드 u의 왼쪽 자식이면, f(v) = 2f(u)

*만약 v가 노드 u의 오른쪽 자식이면, f(v) = 2f(u) + 1

이 방법에서 T의 모든 노드는 인덱스 범위 [1,n]에 연속적으로 저장되고 마지막 노드는 항상 인덱스 n(T의 노드 수)에 비례한다. 

완전 이진 트리의 벡터 기반한 표현의 단순함으로 인해 함수 add와 remove의 구현에 도움이 된다. 배열의 확장이 필요하지 않다고 가정하면, 함수 add와 remove는 벡터의 마지막 원소를 추가하거나 삭제하기 때문에 O(1)시간에 실행된다. 또한 T와 연관된 벡터는 n+1개의 원소를 갖는다(인덱스 0은 사용하지 않는다). 만약 벡터의 구현에 크기를 줄이거나 늘릴 수 있는 확장 가능한 배열을 사용한다면(예를 들어, STL 벡터 클래스),n개의 노드를 갖는 완전 이진 트리의 벡터-기반한 표현에 필요한 공간은 O(n)이고 연산 add와 remove는 O(1)의 할부된(amortized)시간이 소요된다.

#
*완전 이진 트리 C++ 구현

이 인터페이스는 중첩된 클래스 position을 정의했는데, 이것은 트리의 노드를 나타낸다. 우리는 루트와 마지막 위치에 접근하는 함수와 트리 전체를 순회하는 함수를 제공한다. 수정하는 함수 add와 remove가 제공되고, 두 개의 주어진 노드 간 내용을 서로 바꾸는 함수 swap을 역시 제공한다.

<힙을 이용한 우선순위 큐의 구현>

우선순위 큐 q를 위한 힙 자료구조는 다음을 포함한다.

*heap: 완전 이진 트리 T로서 원소들이 힙-순서 특성에 따라 내부 노드에 저장되어 있다. 이진 트리 T가 설명한 바와 같이 벡터로 구현되어 있다고 가정한다. T의 각 내부 노드 v에 각 원소의 키 k(v)가 저장되어 있다.

*comp: 키 간의 전체 순서 관계를 정의하는 비교자.

#
-삽입

힙 T를 이용하여 우선순위 큐의 insert함수의 구현 방법을 알아본다. 새로운 원소 e를 T에 삽입하기 위하여 우선 함수 add로 T에 새로운 내부 노드를 추가하여 새 노드가 T의 마지막 노드가 되게 한 후 e를 이 노드에 저장한다.

이러한 작업 뒤에 트리 T는 완전하나 힙-순서 특성을 위반하고 있을 수 있다. 따라서 노드 z가 T의 루트가 아닌 한(즉, 삽입 전 우선순위 트리가 비어 있을 경우) 키 k(z)를 z의 부모 u의 키 k(u)와 비교한다. 만약 k(u)>k(z)이면, 힙-순서 특성을 복구하여야 한다. 이것은 z와 u에 저장된 원소들을 서로 교환하면 된다. 힙-순서 특성이 또 다시 위반될 수 있기 때문에 이러한 교환을 더 이상 힙-순서 특성의 위반이 없을 때까지 T의 상위 레벨로 계속한다.

이러한 교환에 의한 상향 움직임을 일반적으로 업-힙 버블링(up-heap bubblinng) 교환에 의하여 힙-순서 특성의 위반이 해결되기도 하고 때에 따라 상위 레벨로 문제가 전이되기도 한다. 최악의 경우, 업-힙 버블링에 의하여 새로운 키-원소 쌍이 T의 루트까지 계속 움직이게 된다. 따라서 최악의 경우에 insert함수에 의해 원소가 교환되는 횟수는 T의 높이와 같고, O(log n)이 된다.

#
-삭제

우선순위 큐 ADT의 removeMin 함수로 돌아가본다.  가장 작은 키를 가진 원소가 T의 루트 r에 저장되어 있다는 것을 알고 있다(비록 가장 작은 키가 하나 이상 일지라도). 그러나, 만일 r이 T의 내부 노드가 아니라면, T의 마지막 노드 w를 간단히 삭제할 수 없다. 왜냐하면, 이 연산은 이진 트리의 구조를 파괴할 수 있기 때문이다. 대신, 우리는 T의 마지막 노드 w에 접근하여 그 엔트리를 루트 r에 복사한 다음, 완전 이진 트리의 연산 remove를 이용하여 마지막 노드를 삭제한다.

삭제 후의 다운-힙 버블링(Bubbling)

그러나 아직 종료된 것이 아닐 수 있다. 그것은 비록 T가 지금은 완전하나, T는 힙 순서의 특성을 위반하고 있을 수 있기 때문이다. 만약 T가 하나의 자식(루트)을 가진다면, 힙-순서 특성이 자연적으로 만족된 것이고 알고리즘은 종료한다. 그렇지 않으면, 두 경우를 구별해야 하는데 여기서 r은 T의 루트를 나타낸다.

*만약 r이 오른쪽 자식이 없으면, s를 r의 왼쪽 자식으로 한다.

*그렇지 않으면(r이 두 자식을 갖는다), 가장 작은 키를 가진 자식을 s라 한다.

만약 k(r)<=k(s), 힙-순서 특성을 만족하면 알고리즘은 종료한다. 대신 k(r)>k(s)이면, r과 s에 저장된 엔트리를 교환함으로써 힙-순서 특성을 복구할 필요가 있다. r과 그 자식 노드를 힙-순서 특성에 따라 복원을 수행하는 교환은 다시 s의 힙-순서 특성을 위반할 수 있다. 따라서 이러한 교환을 더 이상 힙-순서 특성의 위반이 없을 때까지 T의 하위 레벨로 계속한다. 

이러한 교환에 의한 아래방향으로의 움직임을 다운-힙 버블링이라 한다. 교환에 의하여 힙-순서 특성의 위반이 해결되기도 하고 힙의 하위레벨로 문제가 전이되기도 한다. 최악의 경우, 키-원소 쌍들이 T의 바닥까지 아래로 움직이게 된다. 최악의 경우 removeMin 함수에 의해 교환되는 횟수는 T의 높이와 같고, 그것은 O(log n)이다.

#
-분석

두 키가 O(1)시간에 비교되고 힙 T가 벡터 또는 링크드 구조로 구현되었다는 가정하에, 우선순위 큐의 힙 구현에 대한 우선순위 큐 ADT 함수들의 실행 시간을 아래에 나타낸다.

size,empty O(1)

min O(1)

insert O(log n)

removeMin O(log n)

요약하면, 각 우선순위 큐 ADT의 함수들은 O(1)또는 O(log n)시간에 실행된다. 이때 n은 각 함수가 실행될 때 저장된 원소들의 수이다. 각 함수의 실행 시간 분석은 다음 사실에 바탕을 둔다.

*힙 T는 n개의 노드를 가지고 각 노드는 엔트리에 대한 레퍼런스를 가진다.

*연산 add와 remove는 O(1)의 할부법의 시간(벡터 표현) 또는 O(log n) 최악의 경우 시간을 갖는다.

*최악의 경우 업-힙 또는 다운-힙 버블링은 T의 높이와 같은 수의 교환을 실행한다.

*T는 완전하므로 T의 높이는 O(log n)이다. 

따라서 만약 힙 T가 이진 트리를 위한 링크드 구조로 구현되었다면, 필요한 공간은 O(n)이다. 대신 T를 벡터에 기반하여 구현하였다면, 공간은 T를 벡터로 표현하기 위해 사용한 배열의 크기 N에 비례한다. 결론적으로, 힙이 구현된 방법에 무관하게 힙은 우선순위 큐 ADT를 구현하는 매우 효율적인 자료구조이다. 시퀀스에 기반한 우선순위 큐와는 다르게, 힙 구현은 삽입과 삭제 모두 빠르게 시행한다. 이러한 효율적인 힙 구현으로 인하여 시퀀스에 기반한 삽입-정렬이나 선택-정렬보다 매우 빠르게 우선순위-큐 정렬을 실행할 수 있다.

#
<C++ 구현>

클래스의 데이터 멤버는 완전 트리 T와 비교자 객체 isLess이다. Position이라 불리는 노드 위치의 타입 정의도 제공한다.
# Dynamic_array

<연속된 자료구조>

연속된 자료구조는 모든 원소를 단일 메모리 청크(chunk)에 저장한다. 배열같은 연속된 자료구조에서 각 원소는 서로 인접해 있기 때문에 하나의 원소에 접근할 때 그 옆에 있는 원소 몇 개도 함께 캐시로 가져온다. 그러므로 다시 주변 원소에 접근할 때에 해당 원소를 캐시에서 가져오게 되며, 이 작업은 매우 빠르게 동작한다. 이러한 속성을 캐시 지역성(cache locality)라고 한다. 

#
<연결된 자료구조>

연결된 자료구조는 여러 개의 메모리 청크에 데이터를 저장하며, 이 경우 서로 다른 메모리 위치에 데이터가 저장된다. 

#
<차이점>

*연속된 자료구조

-모든 데이터가 메모리에 연속적으로 저장된다.

-임의 원소에 즉각적으로 접근할 수 있다.

-데이터가 연속적으로 저장되어 있고, 캐시 지역성 효과로 인해 모든 데이터를 순회하는 것이 매우 빠르다.

-데이터 저장을 위해 정확하게 데이터 크기만큼의 메모리를 사용한다.

*연결된 자료구조

-데이터는 노드에 저장되고, 노드는 메모리 곳곳에 흩어져 있을 수 있다.

-임의 원소에 접근하는 것은 선형 시간 복잡도를 가지며 느린 편이다.

-캐시 지역성 효과가 없으므로 모든 데이터를 순회하는 것이 느린 편이다.

-각 노드에서 포인터 저장을 위해 여분의 메모리를 사용한다.

*시간 복잡도

배열

-임의 접근 O(1)

-맨 뒤에 원소 삽입 O(1)

-중간에 원소 삽입 O(n)

-캐시 지역성 있음

연결 리스트

-O(n)

-O(1)

-O(1)

-캐시 지역성 없음

*세그멘테이션 결함

-허용되지 않은 메모리 영역에 접근하거나 허용되지 않는 방법으로 메모리에 접근했을 때 생기는 오류

#
<C-스타일 배열의 제약 사항>

C-style 배열은 배열의 역할을 충분히 수행하지만 그다지 많이 사용되지는 않는다. C-style 배열은 몇 가지 제약 사항을 가지고 있어서 더 나은 형태의 배열이 필요하기도 한다. 다음은 C-style 배열의 단점을 나열한 것이다.

*메모리 할당과 해제를 수동으로 처리해야 한다. 메모리를 해제하지 못하면 메모리 누수가 발생할 수 있고, 이 경우 해당 메모리 영역을 사용할 수 없다.

*[]연산자에서 배열 크기보다 큰 원소를 참조하는 것을 검사하지 못한다. 잘못 사용하면 세그멘테이션 결함이 발생할 수 있다. 또한 메모리 손상으로 이어질 수 있다.

*배열을 중첩해서 사용할 경우, 문법이 너무 복잡해서 코드를 이해하기 어렵다.

*깊은 복사가 기본으로 동작하지 않는다. 이러한 동작은 수동으로 구현해야 한다.

#
<std::array>

*std::array

-메모리를 자동으로 할당하고 해제한다.

-빠른 동작을 위해 전달된 인덱스 값이 배열의 크기보다 작은지를 검사하지는 않는다. std::Array는 at(index)형식의 함수도 함께 제공하며 index값이 유효하면 예외를 발생시킨다. at이 []연산자보다는 느리지만 예외를 적절히 처리할 수 있는 장점이 있다.

-c스타일 배열을 함수에 전달할 때처럼 포인터 연산을 사용한다던가 참조 또는 역참조 연산자를 사용하지 않아도 된다.

void print(std::array<int,5> arr)

{

for(auto ele:arr)

	std::cout<<ele<<",";

}
std::array<int,5> arr={1,2,3,4,5};

print(arr);

*템플릿 형으로 선언

template <size_t N>

void print(const array<int, N> &arr)

{

	for (auto ele : arr)

	{

		cout << ele << ",";

	}

}

함수의 매개변수에 Array를 전달할 경우 매개변수에 데이터가 깊은 복사가 일어나기 때문에 이러한 동작을 피하고 싶다면, const나 참조 연산자를 사용하면 된다.

범위 기반 반복문을 사용하여 std::array의 모든 원소에 접근할 수 있는 이유는 반복자를 사용하기 때문. 명심해야 할 것은 end()연산자를 사용하면 invalid한 반복자를 반환한다. 즉 마지막 원소 다음 위치를 반환. 반복자를 사용함으로써 소스 코드의 재사용성 ,유지보수,가독성 측면에서 유리함을 얻을 수 있다.

for(auto it=arr.begin();it != arr.end(); i++)

{

auto element=(*it);

std::cout<<element<<' ';

const iterator는 반복자의 const버전이고, reverse iterator는 역반복자이다. const로 선언된 배열에 대해 begin() 또는 end()같은 함수를 사용하면 const_iterator를 반환한다. reverse_iterator를 사용하면 배열을 역방향으로 이동할 수 있다. 이 반복자를 ++같은 증가 연산자와 함께 사용할 경우, 일반 반복자와 반대 방향으로 이동하게 된다.

*std::array의 함수

-front()

배열의 첫 번째 원소에 대한 참조를 반환한다.

-back()

배열의 마지막 원소에 대한 참조를 반환한다.

-data()

배열 객체 내부에서 실제 데이터 메모리 버퍼를 가리키는 포인터를 반환한다. 반환된 포인터를 이용하여 다양한 포인터 연산을 수행할 수 있다. 이 기능은 포인터를 함수의 인자로 받는 예전 스타일의 함수를 사용할 때 유용하다.

사용 예

std::array<int,5> arr={1,2,3,4,5);

std::cout<<arr.front() <<std::endl;

std::cout<<arr.back()<<std::endl;

std::cout<<*(arr.data()+1)<<std::endl;

std::array는 깊은 비교를 위한 관계 연산자와 깊은 복사를 위한 복사 할당 연산자도 지원한다. std::array에 저장되는 데이터 타입 크기 비교를 지원할 경우, 이들 관계 연산자를 이용하여 두 std::array배열을 비교하는 용도로 사용할 수 있다. 단, 비교 대상인 두 array의 크기가 같아야 한다.

C-style 배열에 대해서도 관계 연산자를 사용할 수 있지만, 이 경우에는 배열 원소 값을 비교하는 것이 아니라 포인터 주소 값을 비교한다. 즉, 깊은 비교 대신 얕은 비교를 수행한다.

# Common_Type build_array function

<빠르고 범용적인 데이터 저장 컨테이너 만들기>

다양한 타입의 데이터 여러 개를 인자로 받아 공통 타입으로 변환하는 함수를 만들어 본다. 이 함수가 반환하는 컨테이너는 모든 인자를 공통 타입으로 변환하여 저장하며, 전체 원소를 빠르게 순회할 수 있어야 한다.

먼저 컨테이너를 생성하는 build_array() 함수를 선언한다. 이 함수는 빠른 원소 순회를 보장하는 array를 반환한다. 임의 개수의 매개변수를 허용하기 위해 가변 템플릿을 사용한다.

template<typename ...args>

array::<?,?> build_array(args&&...args)

반환된 컨테이너는 빠르게 순회할 수 있어야 한다는 조건이 있으므로 배열 또는 벡터를 사용할 수 있다.

template<typename ...Args>

auto build_array(Args&&...args)->array<typename common_type<Args...>::type, ? >

{

using commonType = typename common_type<Args...>::type

}

array를 사용하려면 원소의 타입과 원소 개수를 지정해야 한다. array에 저장할 원소의 타입을 결정하기 위해 common_type템플릿을 사용할 수 있다. 이 작업은 함수 인자에 의존적이기 때문에 함수 반환형을 후행 리턴 타입으로 지정한다.

#include <iostream>

#include <array>

#include <type_traits>

using namespace std;

template<typename ...Args>

auto build_array(Args...args)->array<typename common_type<Args...>::type, sizeof...(args) >

//->이후에오는코드는후행리턴타입이다.

//common_type<Args...>는가변템플릿인자로받아들인여러타입을하나의타입으로묶는다.

//forward는보편참조를반환한다.

{

using commonType = typename common_type<Args...>::type

return { forward<commonType>((Args)args)... };

}

int main()
{

auto data = build_array(1, 0u, 'a', 3.2f, false);

for (auto i : data)

cout << i << endl;

cout << endl;

}

함수에 전달된 인자들이 모두 float으로 캐스팅될 수 있기 때문에, 최종 출력은 float으로 출력됩니다. 그러나 다음과 같이 입력한다면 에러가 발생한다.

auto data2=build_array(1,"packt",2.0);

소스 코드를 이와 같ㅇ리 작성할 경우, 모든 데이터 타입을 하나의 공통 타입으로 변환할 수 없어서 에러가 발생합니다. 이는 문자열과 숫자를 모두 표현할 수 있는 공통의 자료형이 존재하지 않기 때문이다. 이 코드의 build_array()같은 빌더 함수는 입력 데이터 타입이 모호할 때에도 사용할 수 있다.

#
<vector>

array의 단점

1.array의 크기는 컴파일 시간에 결정되는 상수이어야 한다. 따라서 런타임에는 변경할 수 없다.

2.크기가 고정되어 있어서 원소를 추가, 삭제할 수 없다.

3.array의 메모리 할당 방법을 변경할 수 없다. 항상 스택 메모리를 사용한다.

대부분의 실제 응용 프로그램에서 데이터는 동적이며 고정 크기가 아니다. 대부분의 경우에 데이터의 크기를 미리 알고 있기 쉽지 않다. array를 사용하는 것이 항상 좋은 것은 아니며, 가변 크기의 데이터를 처리할 수 있는 컨테이너가 필요하기도 하다.

*std::vector - 가변 크기 배열

std::vector는 초기화 과정에 데이터의 크기를 제공하지 않아도 된다.

다음은 벡터를 초기화 하는 방법이다.

크기가 0인 벡터 선언 vector<int> vec;

지정한 초깃값으로 이루어진 크기가 5인 벡터 선언 vector<int> vec={1,2,3,4,5};

크기가 10인 벡터 선언 vector<int> vec(10);

크기가 10이고, 모든 원소가 5로 초기화된 벡터 선언 vector<int> vec(10,5);


첫 번째 초기화 코드처럼 벡터는 원소 크기를 지정하지 않고 선언할 수 있다. 만약 벡터의 크기를 명시적으로 지정하지 않거나 또는 초깃값을 지정하여 크기를 유추할 수 있게 코드를 작성하지 않을 경우, 컴파일러 구현 방법에 따른 용량을 갖는 벡터가 생성된다. 벡터의 크기는 벡터에 실제로 저장된 원소 개수를 나타내는 용어이며, 용량과는 다른 의미이다. 그러므로 첫 번째 초기화의 경우, 크기는0이지만 용량은 0 또는 작은 양수일 수 있다.

벡터에 원소를 추가하려면 push_back()또는 insert()함수를 사용한다. push_back()함수는 벡터의 맨 마지막에 원소를 추가한다. insert()함수는 삽입할 위치를 나타내는 반복자를 첫 번째 인자로 받음으로써 원하는 위치에 원소를 추가할 수 있다. push_back()은 벡터에서 자주 사용되는 연산이며, 매우 빠르게 동작한다. push_back 함수의 의사코드는 다음과 같다.

push_back(val) :

if size < capacity //새원소를추가할공간이있는경우

- 마지막원소다음에val 저장

- 벡터크기를1만큼증가

- return

if vector is already full //할당할메모리공간이가득차있는경우

-2*size 크기의메모리를새로할당

-새로할당한메모리로기존원소전부를복사/이동

-데이터포인터를새로할당한메모리주소로지정

-마지막원소다음에val을저장하고, 벡터크기를1만큼증가


원소를 삽입할 때 공간이 있다면, O(1)의 시간이 걸린다. 그러나 공간이 없다면, 모든 원소를 복사/이동해야 하며, 이때는 O(n)의 시간이 걸린다. 대부분의 구현에서는 용량이 부족할 때마다 벡터 용량을 두배로 늘린다. O(n) 시간 동작은 n개의 원소를 추가한 후에만 발생하며, 이러한 경우는 많지 않으므로 push_back 연산의 평균 시간 복잡도는 O(1)에 가깝다. 즉 push_back은 매우 빠르게 동작한다. insert()함수의 경우, 지정한 반복자 위치 다음의 모든 원소를 이동시키는 연산이 필요하다. 필요한 경우 새로 메모리를 할당하는 작업도 수행된다. 

insert()는 O(n)의 시간이 걸린다. 벡터는 push_front()함수를 지원하지 않는다.

일단 다섯 개의 정수를 갖는 벡터를 정의한다.

vector<int> vec={1,2,3,4,5};

벡터의 맨 앞에 새로운 원소를 추가하려면 insert() 함수를 다음과 같이 사용한다.

vec.insert(vec.begin(),0);

push_back()과 insert() 함수를 사용하는 예제 코드를 좀 더 보자,

vector<int> vec; //비어 있는 벡터 생성

vec.push_back(1); //맨 뒤에 1 추가:{1}

vec.push_back(2); //맨 뒤에 2 추가:{1,2}

vec.insert(vec.begin(),0); //맨 앞에 0 추가:{0,1,2};

vec.insert(find(vec.begin(),vec.end(),1),4); //1 앞에 4 추가:{0,4,1,2}

push_back()또는 insert() 함수의 단점 중 하나는 이들 함수가 추가할 원소를 먼저 임시로 생성한 후, 벡터 버퍼 내부 위치로 복사 또는 이동을 수행한다는 점이다. 이러한 단점은 새로운 원소가 추가될 위치에서 해당 원소를 생성하는 방식으로 최적화할 수 있다. 이러한 기능이 emplace_back() 또는 emplace() 함수에 구현되어 있다. 그러므로 push_back() 또는 insert()같은 일반적인 삽입 함수 대신 emplace_back()또는 emplace 함수를 사용하는 것이 성능 향상에 도움이 된다. 이 경우 새 원소 위치에서 곧바로 객체가 생성되기 때문에 이들 함수 인자에 생성된 객체를 전달하는 것이 아니라 생성자에 필요한 매개변수를 전달해야 한다. 그러면 emplace 함수들이 전달된 매개변수를 적절하게 활용하여 객체를 생성하고 삽입한다.

vector는 원소 제거를 위해 pop_back()과 erase()함수를 사용한다. pop_back()함수는 벡터에서 맨 마지막 원소를 제거하며, 그 결과 벡터 크기는 1만큼 줄어든다. erase()함수는 두 가지 형태로 오버로딩되어 있다. 한 가지 형태는 반복자 하나를 인자로 받아 해당 위치 원소를 제거하고, 다른 형태는 범위의 시작과 끝을 나타내는 반복자를 받아 시작부터 끝 바로 앞 원소까지 제거한다. 즉 시작 위치 원소는 제거되지만 끝 위치 원소는 제거되지 않는다. C++표준에서는 이들 함수 동작 시 벡터의 용량이 감소할 필요가 없지만, 컴파일러 구현에 따라 달라질 수 있다. pop_back()함수는 남아 있는 위치를 조정할 필요가 없으므로, 매우 빠르게 동작하고, 시간 복잡도는 O(1)이다. 그러나 erase()함수는 특정 위치 원소를 삭제한 후, 뒤쪽의 원소들을 모두 앞으로 이동해야 하기 때문에 O(n)의 시간이 소요된다. 벡터에서 원소를 제거하는 다양한 방법에 대해 알아본다. 10개의 데이터{0,1,2,3,4,5,6,7,8,9}를 가지고 있는 벡터 vec이 있다고 가정한다.

std::vector<int> vec={0,1,2,3,4,5,6,7,8,9};

//맨 마지막 원소를 하나 제거한다: {0,1,2,3,4,5,6,7,8}

vec.pop_back();

//맨 처음 원소를 제거한다. :{1,2,3,4,5,6,7,8}

vec.erase(vec.begin());

//1번째 원소부터 4번째 앞 원소까지 제거한다 :{1,5,6,7,8}

vec.erase(vec.begin()+1,vec.begin()+4);

다음은 몇 가지 유용한 vector의 멤버 함수를 소개한다.

clear():모든 원소를 제거하여 완전히 비어 있는 벡터로 만든다.

reverse(capacity):벡터에서 사용할 용량을 지정한다. 매개변수로 지정한 값이 현재 용량보다 크면 메모리를 매개변수 크기만큼 재할당한다. 매개변수 값이 현재 용량보다 같거나 작으면 아무런 동작을 하지 않는다. 이 함수는 벡터의 크기를 변경하지는 않는다.

shrink_to_fit():여분의 메모리 공간을 해제하는 용도로 사용된다. 이 함수를 호출하면 벡터의 용량이 벡터 크기와 같게 설정된다. 벡터 크기가 더 이상 변경되지 않을 때 사용하면 유용하다.

*std::vector 할당자

std::vector는 템플릿 매개변수에서 데이터 타입 다음에 할당자를 전달할 수 있다. 이 기능을 이용하면 std::array의 단점을 해결할 수 있다. 사용자 정의 할당자를 사용하려면 정해진 인터페이스를 따라야 한다. 벡터는 메모리 접근과 관련된 대부분의 동작에서 할당자 함수를 사용하므로 할당자는 allocate(), deallocate(), construct(), destory() 등의 함수를 제공해야 한다. 할당자는 메모리 할당과 해제, 그리고 여타 동작에서 데이터를 손상시키지 않도록 주의해야 한다. 일반적인 힙 메모리 대신 자체적인 메모리 풀 또는 이와 유사한 자원을 사용하거나 자동 메모리 관리가 필요한 응용 프로그램을 만들어야 하는 경우에 사용자 정의 할당자를 사용하면 유용하다. 결국 vector는 array에 대한 정말 좋은 대안이고, 크기, 증분 등의 관점에서 더욱 많은 유연성을 제공한다. 배열과 벡터에서 공통으로 제공하는 기능은 서로 같은 점근적 시간 복잡도를 갖는다. 다만 추가적인 기능에 대해서는 합리적인 수준의 추가 연산 비용이 필요하다. 추가적으로 벡터의 성능은 배열에 비해 그리 나쁘지 않다. 그러므로 vector는 성능과 유연성으로 인해 실전에서 널리 사용되는 STL 컨테이너중 하나이다.

# std::forward_list & std::remove_if

*배열, 벡터 같은 연속된 자료 구조에서는 데이터 중간에 자료를 추가하거나 삭제하는 작업이 매우 비효율적이다. 그래서 연결 리스트와 같은 형태의 자료 구조가 등장합니다. 많은 응용 프로그램에서 자료 구조 중간에 삽입 또는 삭제 작업을 필요로 합니다. 예를 들어 탭을 지원하는 브라우저는 언제든 새로운 탭을 임의의 위치에 옮길 수 있어야 하며, 음악 플레이어는 재생 목록 중간에 새로운 노래를 추가할 수 있어야 한다. 이러한 빠른 동작을 위해 연결 리스트를 사용할 수 있다. 기본적으로 연결 리스트를 구성하려면 포인터를 하나 가지고 있어야 하고, new와 delete 연산자를 이용하여 메모리를 할당하고 해제할 수 있어야 한다. C++클래스는 C 스타일 배열에 대한 래퍼 클래스 array를 제공하듯이 기본적인 연결 리스트에 대한 래퍼 클래스인 forward_list 클래스를 제공한다. forward_list는 기본적인 연결 리스트의 성능을 유지하면서 추가적인 기능을 제공한다. 성능 유지를 위해 forward_list는 전체 리스트의 크기를 반환하거나 또는 첫 번째 원소를 제외한 나머지 원소에 직접 접근하는 기능을 제공하지 않는다. 즉 맨 처음 원소에 접근하는 front()함수를 제공하지만, back()같은 함수는 제공하지 않는다. 원소의 삽입, 삭제, 순서 뒤집기, 분할을 위한 기능은 제공한다. 이러한 기능은 기본적인 연결 리스트의 메모리 사용량이나 성능에 영향을 주지 않는다. vector와 마찬가지로 forward_list도 두 번째 템플릿 매개변수에 사용자 지정 할당자를 지정할 수 있다. 따라서 맞춤형 메모리 관리가 필요한 고급 응용 프로그램에서도 forward_list를 사용할 수 있다.

*forward_list에서 원소를 삽입할 때에는 push_front()와 insert_after() 함수를 사용한다.

이 두 함수는 vector에서 원소를 삽입할 때와는 조금 다른 동작을 수행한다. push_front()함수는 연결 리스트 맨 앞에 새로운 원소를 삽입한다. forward_list는 마지막 원소에 직접 접근할 수 없으므로 push_back() 함수를 제공하지 않는다. 특정 위치에 원소를 삽입하려면 insert()가 아니라 insert_after() 함수를 사용해야 한다. 이는 연결 리스트에서 새로운 원소를 삽입한 후 해당 위치 앞에 있는 원소의 next포인터를 수정해야 하기 때문이다. forward_list에서 반대 방향으로 이동하는 것이 허용되지 않으므로 특정 원소 뒤에 새로운 원소를 삽입한 후 해당 원소의 next포인터를 수정하는 것이 타당합니다. 연결 리스트에서 원소 삽입은 노드의 포인터 조작으로 구현되므로, 삽입 후 다른 원소를 이동할 필요가 없다. 그러므로 forward_list의 삽입 함수는 모두 배열 기반 구조에서의 삽입 함수에 비해 매우 빠르게 작동한다. forward_list의 삽입 함수는 리스트의 원소 크기에 영향을 받지 않으며, 시간 복잡도는 O(1)이다. 다음 예제에서 이들 함수의 사용 방법에 대해 알아보자.

*다음은 다양한 코드 예제이다.

forward_list<int> fwd_list={1,2,3};

fwd_list.push_front(0); //맨 앞에 0추가

auto it=fwd_list.begin();

fwd_list.insert_after(it,5); //맨 처음 원소 뒤에 5 추가:{0,5,1,2,3}

fwd_list.insert_after(it,6); //같은 위치에 6 추가:{0,6,5,1,2,3}

forward_list는 vector의 emplace() 함수와 유사한 emplace_front()와 emplace_after()함수도 제공한다. 이 두 함수는 삽입 함수와 같은 기능을 수행하지만 추가적인 복사 또는 이동을 하지 않기 때문에 더 효율적이다. forward_list에서 원소를 삭제할 때에는 pop_front()와 erase_after()함수를 사용한다. pop_front()는 리스트의 맨 처음 원소를 제거한다. 이 작업은 원소 이동이 필요하지 않으므로 매우 빠르게 동작하며 시간 복잡도는 O(1)이다. erase_after()는 두 가지 형태로 제공된다. 하나는 특정 원소를 가리키는 반복자를 인자로 받아서 바로 다음 위치의 원소를 삭제한다. 일련의 원소를 제거할 때에도 erase_after()함수를 사용할 수 있으며, 이 경우에는 삭제할 범위의 시작 원소 앞을 가리키는 반복자와 삭제할 범위의 끝 원소를 가리키는 반복자를 인자로 받는다. erase_after()함수를 사용하여 일련의 원소를 삭제하는 시간 복잡도는 삭제할 원소 개수의 선형 함수 형태로 나타난다. 이는 연결 리스트에서 각각의 노드는 전체 메모리의 임의 위치에 산재되어 있으며, 각각의 노드에 사용된 메모리를 개별적으로 해제해야 하기 때문이다. 리스트의 원소르 삭제하는 코드 예제는 다음과 같다.

forward_list<int> fwd_list={1,2,3,4,5};

fwd_list.pop_front() //맨 앞 원소를 삭제:{2,3,4,5}

auto it=fwd_list.begin();

fwd_list.erase_after(it); //맨 앞의 다음 원소를 삭제:{2,4,5}

fwd_list.erase_after(it,fwd_list.end()); /맨 앞 원소 다음부터 맨 마지막 원소까지 삭제:{2}

*std::forward_list 기타 멤버 함수

반복자로 원소 위치를 지정하여 삭제하는 erase() 함수 외에도 forward_list 원소값을 검사하여 삭제하는 remove()와 remove_if() 함수도 제공한다. remove()함수는 삭제할 원소 값 하나를 매개변수로 받는다. 이 함수는 저장된 데이터 타입에 정의된 등호 연산자를 사용하여 전달된 값과 일치하는 모든 원소를 찾아 삭제한다. 저장된 데이터 타입에서 등호 연산이 제공되지 않으면 remove()함수를 사용할 수 없으며, 이 경우 컴파일러는 에러를 발생시킨다. remove()함수는 오직 등호 연산에 근거하여 원소를 삭제하며, 다른 조건에 근거하여 삭제 여부를 결정할 수 없다. 좀 더 유연한 조건부 삭제를 수행하려면 remove_if()함수를 사용할 수 있다. remove_if()는 데이터 원소 값 하나를 인자로 받아 bool값을 반환하는 조건자 함수를 인자로 받는다. 그리고 조건자가 true를 반환하는 모든 데이터 원소를 리스트에서 삭제한다. 최신 c++버전을 사용한다면 조건자 자리에 람다 표현식을 사용할 수 있다. remove()와 remove_if()함수 사용법을 익히기 위해 다음 예제를 살펴보겠다.

*연결리스트에서 remove_if()함수를 이용한 조건부 원소 삭제

선거 기간에 일부 시민들의 정보를 이용하여 선거권이 없는 사람을 가려내려고 한다. 편의상 시민 정보는 이름과 나이만을 사용하겠다. 연결 리스트를 사용하여 데이터를 저장하고, remove_if()함수를 사용하여 특정 원소를 제거할 것이다. remove_if()함수는 삭제할 원소 위치를 명시적으로 지정하는 것이 아니라 특정 조건에 해당하는 원소를 선별적으로 삭제할 때 사용한다.

먼저 필요한 헤더 파일을 포함시키고, citizen 구조체를 정의한다.

remove()와 remove_if()함수는 리스트를 전체 순회하면서 조건에 맞는 원소를 모두 삭제하므로 O(n)의 시간 복잡도를 갖는다. forward_list는 원소 데이터를 정렬하는 sort()함수를 제공한다. array,vector등에 저장된 데이터는 범용적인 sort(first_iterator,last_iterator) 함수를 이용하여 원소를 정렬할 수 있다. 그러나 연결 리스트 같은 자료 구조는 특정 원소에 임의 접근이 불가능하므로 sort()함수를 사용할 수 없다. 또한 forward_list에서 사용하는 반복자는  array또는 vector에서 사용하는 반복자와는 다르다. forward_list에서 제공하는 sort()함수는 두 가지 형태를 지원한다. 하나는 <연산자를 기반으로 정렬하고, 다른 하나는 매개변수로 전달된 비교자를 사용한다. 기본 sort()함수는 std::less<value_type>을 비교자로 사용한다. 이 비교자는 첫 번째 인자가 두 번째 인자보다 작으면 true를 반환하며, 사용자 정의 타입 원소를 사용할 경우에는 < 연산자가 재정의 되어 있어야 합니다. 이외에도 다른 기준을 이용하여 원소를 비교하고 정렬하려면 이항 조건자를 지정할 수 있다. 두 가지 형태의 sort()함수 모두 선형 로그 시간 복잡도 O(nlogn)을 갖는다. 다음 두 코드는 sort()함수 사용법을 보여준다.

forward_list<int> list1={23,0,1,-3,34,32};

list1.sort(); //{-3,0,1,23,32,34} 순서로 바뀐다.

list1.sort(greater<int>()); //{34,32,23,1,0,-3}

앞 예제 코드에서 greater<int>는 표준으로 제공되는 비교 함수 객체이며, 결과 리스트에서 확인할 수 있듯이 원소를 내림차순으로 정렬하기 위한 >연산자에 대한 래퍼이다. forward_list에서 제공하는 다른 멤버 함수로는 reverse()와 unique()가 있다. reverse()함수는 저장된 원소의 순서를 역순을 변경한다. 이때 걸리는 시간은 리스트 원소 개수에 비례하며 시간 복잡도는 O(n)이다. unique()함수는 리스트에서 홀로 나타나는 원소는 놔두고, 인접하여 중복되는 원소에 대해서는 첫 번째 원소만 남기고 나머지는 제거한다. 이 함수는 두 원소가 같은지를 판단하는 방식에 따라 두 가지 형태로 제공된다. 하나는 인자가 없는 형태이며, 이때는 원소 타입의 등호 연산자를 사용하여 같은지를 판단한다. 다른 하나는 bool값을 반환하는 이항 조건자를 인자로 받으며, 이 조건자는 리스트 원소 타입의 인자를 두 개 받는다. unique()함수의 시간 복잡도도 선형 함수로 표현되는데 이는 unique()함수가 각각의 원소를 나머지 원소 전체와 비교하는 형태로 동작하는 것이 아님을 암시한다. 실제로 unique()함수는 서로 인접한 원소끼리 같은지를 판단하고, 만약 서로 같으면 앞에 있는 원소는 남기고 뒤의 원소는 제거한다. 그러므로 리스트 전체에서 유일한 원소들만 남게 만들려면 먼저 리스트를 정렬한 후 unique()함수를 사용해야 한다. reverse(),sort(),unique()함수를 사용하는 예제 코드를 보자.

forward_list<int> list1={2,53,1,0,4,10};

list1.reverse(); //실행 결과:{10,4,0,1,53,2}

list1={0,1,0,1,-1,10,5,5,10,0};

list1.unique(); //실행 결과:{0,1,0,1,-1,10,5,10,0}

list1={0,1,0,1,-1,10,5,5,10,0};

list1.sort(); //실행 결과{-1,0,0,0,1,1,5,5,10,10}

list1.unique(); //실행 결과:{-1,0,1,5,10}

다음 예제 코드는 리스트에서 특정 원소가 바로 앞 원소보다 2 이상 크지 않으면 삭제한다.

list1.unique([](int a,int b){return (b-a)<2;}); //실행 결과:{-1,1,5,10}

# Iterator

*반복자

앞에서 배열과 벡터를 설명할 때 반복자에 숫자를 더하여 사용한 것을 기억할 것이다. 반복자는 포인터와 비슷하지만, STL컨테이너에 대해 공통의 인터페이스를 제공한다. 반복자를 이용한 연산은 어떤 컨테이너에서 정의된 반복자인지에 따라 결정된다. 벡터와 배열에서 사용되는 반복자는 기능 면에서 가장 유연하다. 벡터와 배열은 연속된 자료 구조를 사용하기 때문에 특정 위치의 원소에 곧바로 접근할 수 있다. 이러한 반복자를 임의 접근 반복자라고 한다. 그러나 forward_list의 경우 기본적으로 역방향으로 이동하는 기능을 제공하지 않으며, 바로 이전 노드로 이동하려면 맨 처음 노드부터 시작해서 찾아가야 한다. 따라서 forward_list에서는 증가 연산만 가능하며, 이러한 반복자를 순방향 반복자라고 한다.

반복자 타입에 따라 사용할 수 있는 함수 중에 advance(),next(),prev()함수에 대해 알아본다. advance()함수는 반복자와 거리 값을 인자로 받고 반복자를 거리 값만큼 증가시킨다. next()와 prev()함수도 반복자와 거리 값을 인자로 받고, 해당 반복자에서 지정한 거리만큼 떨어진 위치의 반복자를 반환한다. 이들 함수는 해당 반복자가 지원할 경우에만 동작한다. 예를 들어 순방향으로만 이동 가능한 순방향 반복자에 대해 prev()함수를 사용하면 에러가 발생한다. 이들 함수의 동작 시간은 반복자 타입에 따라 결정된다. 예를 들어 임의 접근 반복자에서는 덧셈 또는 뺄셈이 상수 시간으로 동작하므로 next(),prev()등의 함수도 상수 시간으로 동작한다. 나머지 타입의 반복자에서는 주어진 거리만큼 순방향 또는 역방향으로 이동해야 하기 때문에 선형 시간이 소요된다.

# Forward_List

지난 몇 년간의 싱가포르 F1 그랑프리 수상자 명단이 있다고 가정해보겠다. 그리고 벡터 반복자를 사용하여 이 데이터로부터 유용한 정보를 검색하는 방법을 알아본다. 그런 다음 
forward_list를 사용하여 같은 작업을 반복하고, 벡터 반복자와 다른 점을 살펴본다.

vector를 이용하여 최근 경기 우승자 명단을 작성한다. 또한 forward_list를 사용하여 같은 작업을 수행하고 벡터 사용법과의 차이점을 살펴본다.

또한 it1에 다음과 같은 숫자 값을 더하면 에러가 난다.

it1+=2; 
no match for ‘operator’(operand types are std::_Fwd_list_iterator<int>’ and’int’)

array가 C스타일 배열의 래퍼인 것처럼 forward_list는 단일 연결 리스트를 구현해 놓은 래퍼일 뿐이다. forward_list는 성능이나 메모리를 크게 낭비하지 않으면서 간단하고 에러를 유발하지 않는 인터페이스를 제공한다. 벡터에서는 특정 원소에 즉각적으로 접근할 수 있으므로 벡터 반복자의 덧셈과 뺄셈 연산은 O(1)이다. 반면에 forward_list는 연속적인 순회를 통해서만 특정 원소에 접근할 수 있다. 그러므로 forward_list는 반복자의 덧셈 연산 시간 복잡도는 O(n)이고, 여기서 n은 순회할 횟수를 나타낸다. 다음 연습문제에서는 forward_list와 비슷한 방식으로 동작하지만 약간 개선된 형태의 사용자 정의 컨테이너를 만들어 본다. forward_list에서 제공하는 많은 함수를 비슷하게 구현할 것이다. 이러한 연습을 통해 내부적인 구조를 알 수 있을 것이다.

# Singly_Linked_List

forward_list와 유사하면서 더 많은 기능을 제공하는 사용자 정의 컨테이너를 만들어 본다. 먼저 singly_ll 이라는 이름의 기본적인 컨테이너 클래스를 구현하고 여러 기능을 추가한다.
먼저 필요한 헤더를 포함하고, singly_ll 구현에 필요한 단일 노드 클래스 singly_ll_node를 정의한다. 또한 singly_ll 클래스를 구현한다. 이 클래스는 singly_ll_node를 사용하는 연결 리스트 클래스이다. 또한 singly_ll 클래스의 기본 반복자를 구현한다. 이 반복자는 생성자와 접근자를 가지고 선행 증가와 후행 증가를 위한 ++연산자 함수도 구현한다.


이번 연습문제에서 initializer_list를 이용하여 연결 리스트를 초기화하는 방법을 사용했다. 
push(),pop_front(),back()같은 함수를 사용할 수도 있으며, 이 예제에서는 sll2 리스트에 
push_front() 함수로 새로운 원소를 추가했다. sll2가 깊은 복사에 의해 생성되었기 때문에 sll2에 새 원소를 추가해도 sll 리스트에는 여전히 네 개의 원소가 있음을 확인할 수 있다.

# std:list 

*std::list

앞에서 설명했듯이 forward_list는 아주 기본적인 형태로 구현된 연결 리스트이다. 

forward_list는 다른 유용한 기능 중에서도 리스트 끝에 원소 추가, 역방향 이동, 리스트 크기 반환 등의 기능은 제공하지 않는다. 이는 메모리를 적게 쓰고, 빠른 성능을 유지하기 위함이다.

 이외에도 forward_list의 반복자는 매우 적은 기능만 지원한다. 컨테이너의 크기를 얻어오거나 또는 자료 구조 맨 뒤에 새로운 데이터를 추가하는 등의 기능은 매우 유용하고 빈번하게 사용되지만 forward_list에서는 지원되지 않는다. forward_list는 빠른 원소 삽입이 필요한 모든 경우에 어울리는 컨테이너는 아니다. 이러한 forward_list의 단점을 보완하기 위해 C++는 std:list를 제공한다. std::list는 양쪽 방향으로 연결된 리스트, 즉 이중 연결 리스트이다. 덕분에 forward_list에 비해 더 많은 기능을 제공한다. 

다만 forward_list에 비해 더 많은 메모리를 사용한다. 이중 연결 리스트에서 사용하는 노드의 기본 형태는 다음과 같다.

struct doubly_linked_list_node

{

	int data;

	doubly_linked_list_node* next;

	doubly_linked_list_node* prev;

};

앞 코드에서 볼 수 있듯이 이중 연결 리스트 노드는 이전 노드를 가리키는 포인터가 추가로 있다. 이 포인터를 이용하여 역방향으로 이동할 수 있으며, 맨 마지막 원소와 리스트 크기를 따로 저장하여 빠른 push_backI() 또는 size()함수를 지원할 수 있다. forward_list와 마찬가지로 템플릿 매개변수로 사용자 정의 할당자를 지정할 수도 있다.

*std::list 멤버함수

list에서 제공하는 대부분의 함수는 forward_list의 함수와 같거나 유사하며, 약간의 차이가 있다. 예를 들어 forward_list에서 _after로 끝나는 함수는 list에서 _after로 끝나지 않는 형태로 바뀐다. 즉 insert_after()와 emplace_after() 함수는 insert()와 emplace()로 대응된다. 

std::list에서는 원소 이동을 역방향으로도 할 수 있으므로 원소 삽입을 위해 특정 원소의 이전 원소 반복자를 제공하지 않아도 되며, 대신 정확하게 새로운 원소가 삽입될 위치를 가리키는 반복자를 함수 인자로 전달한다. 이외에도 std::list는 빠른 push_back(),emplace_back(),pop_back()함수를 제공한다. 

# 양방향 반복자

<양방향 반복자>

*양방향 반복자

앞서 반복자에 대해 설명할 때, 배열 기반의 임의 접근 반복자와 forward_list 기반의 순방향 반복자의 유연성 차이에 대해 알아봤다. list의 반복자는 이 두 반복자 중간 정도의 유연성을 가지고 있다. list의 반복자는 역방향으로 이동할 수 있으므로 forward_list보다 제약이 적다. 즉, list는 역방향으로의 연산이 필요한 경우에는 역방향 반복자를 사용할 수 있다. 

그러나 list 반복자는 임의 접근 반복자보다는 유연하지 않다. list반복자를 이용하여 어느 방향으로든 원하는 만큼 이동할 수 있지만, 임의 접근 반복자의 경우처럼 특정 위치로 한 번에 이동하는 것은 불가능하다. 그러므로 list 반복자를 이용하여 특정 위치로 이동하는 작업은 선형 시간 복잡도를 가진다. list 반복자는 어느 방향으로든 이동할 수 있으므로 양방향 반복자라고 부른다.


*반복자 무효화

지금까지 어떤 컨테이너든 원소 접근, 순회, 삽입, 삭제 등의 작업을 반복자를 사용하여 모두 같은 방식으로 처리한다는 점을 확인했다, 반복자는 메모리 주소를 가리키는 포인터를 이용하여 구현되었기 때문에 경우에 따라 컨테이너가 변경될 경우 제대로 동작하지 않을 수 있다. 

그러므로 컨테이너가 변경되어 특정 노드 또는 원소의 메모리 주소가 바뀌면 사용하던 반복자가 무효화될 수 있고, 이 경우 예측할 수 없는 동작이 발생할 수 있다. 벡터에서 맨 뒤에 원소를 추가하는 vector::push_back()함수를 예로 들어본다. 이 함수는 경우에 따라 새로 메모리 공간을 할당하고 기존의 모든 원소를 새 메모리 공간으로 복사하는 동작이 발생한다. 

이 경우 기존에 사용하던 모든 반복자와 포인터, 참조는 모두 무효화된다. 마찬가지로 vector가 insert()함수를 수행할 때 메모리 재할당이 필요한 경우라면, 이 경우에도 기존의 반복자, 포인터, 참조는 모두 사용하면 안된다. vector::insert()함수에서 메모리 재할당 없이 원소를 삽입하는 경우라면, 원소 삽입 위치 이후에 있는 원소를 모두 이동해야 하므로 이 위치를 가리키는 반복자는 모두 무효화된다.

 벡터와 달리 연결 리스트에서는 삽입 또는 삭제 동작에서 원소를 이동할 필요가 없으므로 반복자가 무효화되지 않는다. 즉 list또는 forward_list에서 삽입 동작은 반복자의 유효성에 영향을 미치지 않는다. 다만 특정 원소를 삭제하는 경우, 삭제되는 삭제되는 원소를 가리키던 반복자는 당연히 무효화되지만 나머지 원소를 가리키는 반복자는 그대로 사용할 수 있다. 다음은 다양한 연산이 반복자에 어떤 영향을 주는지 확인하기 위한 예제 코드이다. 

vector<int> vec={1,2,3,4,5};

auto v_it4=vec.begin()+4; //v_it4는 vec[4] 원소를 가리킨다.

vec.insert(vec.begin()+2,0); //v_it4 반복자는 무효화된다.


앞 코드에서 마지막 문장이 수행되면 v_it4 반복자는 무효화되며, v_it4를 이용하여 원소에 접근하려고 하면 예상하지 못한 에러가 발생할 수 있다.

list<int> lst={1,2,3,4,5};

auto 1_it4 = next(lst.begin(),4);

lst.insert(next(lst.begin(),2),0); //l_it4 반복자는 여전히 유효하다.

list는 size(), push_back(), pop_back()등의 더 많은 함수를 제공하며, 이들 연산은 O(1)시간 복잡도로 동작한다. 그러므로 std::list가 forward_list보다 저 자주 사용된다. forward_list는 역방향으로 이동하며 접근하지 않아도 되는 경우에 메모리 또는 성능을 최적화하고 싶을 때에만 제한적으로 사용된다. 즉 대부분의 경우에는 list를 사용한다.

# CardGame

<카드게임>

실습 문제 2 카드 게임 시뮬레이션 
이번 코드에서는 주어진 상황을 분석하고 최적의 성능을 내기 위해 가장 적합한 자료 구조를 찾는 연습을 해본다. 카드 게임을 시뮬레이션하려고 한다. 한 게임에 네 명의 플레이어가 있고 각각 임의의 카드 13장을 가지고 게임을 시작한다. 그리고 각 플레이어의 카드에서 임의의 카드 한 장을 선택한다. 그렇게 하면 비교할 카드가 네 장 생기게 되고, 이 중 서로 중복되는 카드 쌍은 제거한다. 세 장의 카드가 같을 경우에는 이 중 임의로 두 장만 제거한다.

 네 장의 카드가 모두 같으면 네 장을 모두 제거한다. 남겨진 카드는 카드를 낸 플레이어가 다시 가져간다. 일치하는 카드 쌍이 없으면 플레이어의 카드 세트를 섞을 수 있다. 이제 이 과정을 어느 한 사람의 카드가 다 없어질 때까지 반복한다. 제일 먼저 자신의 카드를 모두 없앤 사람이 게임의 승자이다. 최종적으로 승자를 화면에 출력하고 게임이 끝난다.

이 문제를 해결하기 위해 다음 단계를 수행한다.

1. 먼저 각 플레이어가 가지고 있는 카드를 저장하기에 적합한 컨테이너를 결정해야 한다. 네 명의 플레이어가 각기 여러 장의 카드를 가지고 있으므로 네 개의 컨테이너 객체를 생성해야 한다.

2. 카드를 초기화하고 섞는 함수를 작성한다.

3. 네 명의 플레이어에서 각각 무작위로 카드를 선택하는 함수를 작성한다.

4. 서로 일치하는 카드가 있는지 검사하는 매칭 함수를 작성한다. 이 함수는 각 플레이어로부터 카드를 한 장씩 선택하고, 선택된 네 장의 카드를 서로 비교한다. 그리고 일치하는 카드를 제거한다. 카드를 제거하는 작업이 빠르게 동작할 수 있도록 카드를 선택해야 한다. 처음에 카드를 저장할 컨테이너를 선정할 때 이러한 점도 고려해야 한다.

5. 승자가 있는지를 검사하는 함수를 작성한다.

6. 이제 게임의 핵심 로직을 구현한다. 이 단계에서는 이전에 작성한 함수들을 이용하여 승자가 나타날 때까지 매칭 작업을 반복적으로 수행한다.

# std::deque

<std::deque>

지금까지 배열 기반과 연결 리스트 기반 컨테이너를 살펴봤다. std::deque 은 두 가지 방식이 섞여 있는 형태이며, 각각의 장점을 적당히 가지고 있다. 앞서 살펴봤듯이 벡터는 가변 길이 배열이고, push_front()또는 pop_front() 같은 함수는 비용이 많이 드는 작업이다. 덱을 사용하면 이런 단점을 극복할 수 있다. 덱은 양방향 큐의 약자 이다. 

*덱의 구조

C++표준은 어떤 기능의 동작만을 정의할 뿐이며, 어떻게 구현해야 하는지는 정의하지 않는다. 

앞에서 살펴본 컨테이너들은 매우 단순해서 그 구현을 충분히 예측할 수 있다. 그러나 덱은 약간 더 복잡하다. 먼저 덱의 필요조건을 살펴본 후 실제 구현 방법에 대해서 알아본다.

C++표준은 덱의 동작에 있어서 다음 조건을 만족해야 한다고 규정한다.

*push_front(), pop_front(), push_back(), pop_back() 동작이 O(1) 시간 복잡도로 동작하여야 한다.

*모든 원소에 대해 임의 접근 동작이 O(1) 시간 복잡도로 동작해야 한다.

*덱 중간에서 원소 삽입 또는 삭제는 O(n) 시간 복잡도로 동작해야 하며, 실제로는 최대 n/2단계로 동작한다. 여기서 n은 덱의 크기이다.

이 요구사항을 살펴보면, 덱은 양방향으로 매우 빠르게 확장할 수 있어야 하며, 모든 원소에 임의 접근을 제공해야 한다. 그러므로 자료 구조가 벡터와 비슷하지만, 앞쪽과 뒤쪽으로 모두 확장할 수 있다는 점이 다르다. 원소 삽입과 삭제 시 n/2 단계를 허용한다는 점에서 이 연산이 모든 원소를 이동시키는 동작을 수행한다는 점을 예상할 수 있으며, 이러한 원소 이동은 벡터에서 삽입 또는 삭제를 할 때에도 발생하는 연산이다. 

다만 덱은 어느 방향으로든 빠르게 확장할 수 있으므로 원소 삽입 시 나머지 원소를 항상 오른쪽으로 이동해야만 하는 것은 아니다. 원소 삽입 위치에서 가장 가까운 끝 쪽으로 나머지 원소를 이동해도 된다. 특정 위치에서 가장 가까운 끝은 컨테이너 내부의 삽입 위치에서 n/2이상 떨어져 있을 수 없기 때문에 최대n/2 단계의 시간 복잡도를 가진다. 이번에는 원소의 임의 접근과 맨 앞에 원소 추가에 대해 생각해본다. 덱은 단일 메모리 청크를 사용하지 않는다.

 대신 크기가 같은 여러 개의 메모리 청크를 사용하여 데이터를 저장한다. 이 경우, 청크의 인덱스 및 크기(또는 하나의 청크에 저장된 원소 개수)를 이용하여 특정 위치의 원소가 어느 청크에 저장되어 있는지를 알 수 있습니다. 모든 메모리 청크 주소를 연속적인 메모리 구조에 저장해놓고 사용하면 O(1)이 시간 복잡도로 원소이 임의 접근이 가능해진다.

 따라서 덱의 구조는 배열 또는 벡터와 유사하다. 덱의 맨 앞에 원소를 추가할 경우, 만약 첫 번쨰 메모리 청크에 여유 공간이 없다면, 새로운 청크를 할당하고, 이 메모리 청크 주소를 맨 첫 번째 메모리 청크 주소로 설정한다. 이 작업을 수행하려면 청크 주소를 저장하는 메모리 공간은 새로 할당해야 하지만, 실제 원소 데이터는 전혀 이동시키지 않아도 된다. 메모리 재할당을 최소홯려면 첫 번재 청크부터 원소를 추가하지 않고 중간 위치의 청크부터 원소를 저장할 수 있다. 이러한 방식을 사용하면, 일정 횟수의 push_front()함수에 대해 메모리 재할당을 피할 수 있다. 


덱은 벡터와 리스트에서 제공되는 함수를 조합한 것 이상의 기능을 제공한다. 덱은push_front(),push_back(), insert(), emplace_front(), emplace_back(), emplace(), pop_front(), pop_back(), erase() 등의 함수를 제공한다. 또한 벡터에서 저장 용량 최적화를 위해 사용하는 shrink_to_fit() 같은 함수도 지원한다. 그러나 capacity() 함수는 구현 방법에 의존적일 수 있으므로 지원되지 않는다. 그리고 벡터와 같은 임의 접근 반복자도 당연히 제공된다. std::deque를사용하여 원소를 삽입하거나 삭제하는 다양한 방법에 대해 알아보겠다.

deque<int> de={1,2,3,4,5};

deq.push_front(0); //맨 앞에 0 추가:{0,1,2,3,4,5}

deq.push_back(6); //맨 뒤에 6 추가:{0,1,2,3,4,5,6}

deq.insert(deq.begin()+2,10);//맨 앞에서 2칸 뒤에 10추가:{0,1,10,2,3,4,5,6}

deq.pop_back(); //맨 뒤 원소 삭제:{0,1,2,3,4,5}

deq.pop_front(); //맨 앞 원소 삭제:{1,10,2,3,4,5}

deq.erase(deq.begin()+1); //{1,2,3,4,5}

deq.erase(deq.begin()+3,deq.end()); //{1,2,3}

덱 구조는 항공기 탑승 대기열과 같은 경우에 사용될 수 있다. 각각의 컨테이너마다 유일하게 다른 점은 성능과 메모리 요구 사항이다. 덱은 데이터 맨 뒤뿐만 아니라 맨 앞에서도 매우 빠르게 원소를 삽입하거나 삭제할 수 있다. 

데이터 중간에서의 삽입 또는 삭제에 대한 시간 복잡도는 벡터와 동일하지만, 실제로는 벡터보다 약간 빠르게 동작한다. vector와 마찬가지로 deque도 사용자 정의 할당자를 지정할 수 있다. 덱을 초기화할 때 템플릿 두 번째 매개변수에 할당자를 지정할 수 있다. 주의할 점은 할당자가 객체의 일부가 아니라 타입의 일부라는 점이다. 이는 서로 다른 할당자를 사용하는 두 개의 벡터 또는 두 개의 덱 객체를 서로 비교할 수 없음을 의미한다. 

마찬가지로 서로 다른 할당자를 사용하는 객체에 대해 할당 또는 복사를 사용할 수 없다. 지금까지 살펴본 바와 같이 deque은 앞 절에서 나왔던 컨테이너에 비해 다소 복잡한 구조를 가지고 있다. 그렇지만 deque는 매우 빠른 push_front()와 push_back() 동작과 효과적인 임의 접근을 제공하는 유일한 컨테이너다. 덱은 이제부터 설명할 몇몇 자료 구조의 구현을 위한 용도로도 사용된다. 

# Printer(Queue)

<Printer>

사무실 프린터에서 인쇄 대기 목록을 시뮬레이션해본다. 보통의 회사 사무실에는 한 대의 프린터를 공유하여 사용한다. 보통 여러 대의 컴퓨터가 하나의 프린터에 연결되어 있다. 프린터는 한 번에 하나의 인쇄 요청을 할 수 있으며, 하나의 인쇄 작업을 완료하기까지는 얼마간의 시간이 필요하다. 그러는 동안 다른 사용자가 인쇄 요청을 보낼 수 있다. 이 경우 프린터의 지연된 인쇄 요청 내역을 어딘가에 저장해 두어야 하며, 현재 인쇄 작업이 완료된 후 저장된 인쇄 요청을 처리해야 한다.

1. job이라는 이름의 클래스를 생성한다. 이 클래스는 작업 ID, 인쇄 요청을 한 사용자 이름,인쇄 페이지 수 등으로 구성된다.

2.Printer 클래스를 생성한다. 이 클래스는 새 인쇄 작업을 추가하고, 현재까지 추가된 모든 인쇄 작업을 처리하는 기능을 제공한다.

3.Printer 클래스를 구현하려면, 모든 지연되고 있는 인쇄 요청을 저장해야 한다. 인쇄 요청은 먼저 요청된 순서대로 처리하는 방식을 따른다. 즉, 가장 ᄈᆞ른 인쇄 요청부터 처리하여 인쇄된다. 

4.마지막으로 여러 사람이 프린터에 작업을 추가하는 시나리오를 구현하고, 프린터는 차례대로 인쇄 작업을 수행한다.

# Tree Traversal Algorithm

*전위 순회(preorder traversal): 이 방법은 현재 노드를 먼저 방문하고, 그 다음은현재 노드의 왼쪽 하위노드, 마지막으로는 오른쪽 하위 노드를 재귀적인 방식으로 탐색한다.

static void preOrder(node* Start)

{

	if(!Start)

 		return;

   	std::cout<<Start->position<<",";

    	preOrder(Start->first);

     	preOrder(Start->second);

}

*중위 순회(inorder traversal): 왼쪽노드, 현재 노드, 오른쪽 노드를 방문하는 방법

static void inOrder(node* start)

{

	if(!start)

  		return;

    	inOrder(start->first);

     	std::cout<<start->position<<",";

      	inOrder(start->second);

}

*후위 순회(post-order traversal): 두 자식 노드를 먼저 방문 후, 현재 노드 방문

static void postOrder(node* start)

{

	if(!start)

 		return;

   	postOrder(start->first);

     	postOrder(start->second);

        std::cout<<start->position<<",";

 }

 *레벨 순회(level order traversal): 트리의 맨 위 레벨부터 아래 레벨까지 왼쪽 노드에서 오른쪽 노드를 방문하는 순서이다. 저장소 예제 코드로 확인한다.

 # Balanced_Tree & N-ary Tree

 <균형 트리>
트리의 원소가 왼쪽이나 오른쪽으로 편향되어 있는 경우에는 원소를 찾는 연산이 원소의 개수와 거의 같다. 따라서 연산량이 많다. 하지만 트리가 균형잡힌 상태라면 연산량이 크게 줄어든다. 균형잡혔다는 말은 트리의 원소가 왼쪽이나 오른쪽으로 편향되어 있지 않고 양 쪽에 고루 퍼져 있다는 뜻이다. 트리의 원소 탐색 연산 복잡도는 트리의 높이와 비례하기 때문에, 트리의 높이가 최적화되어야 한다. 이러한 작업을 트리의 균형 잡기라고 한다. 트리의 균형을 잡기 위해서는 원소 삽입 또는 삭제 후에 트리 구성을 조정해야 한다. 이렇게 조정되어 편향성이 줄어든 이진 검색 트리를 높이-균형 BST라고 한다.

트리의 균형을 잡는 방법은 여러 가지가 있으며, 이를 통해 AVL트리, 레드-블랙 트리 같은 다양한 트리를 만들 수 있다. AVL 트리의 기본 아이디어는 BST속성을 유지하면서 트리 높이의 균형을 잡기 위해 약간의 회전을 수행하는 것이다.

<N-항 트리>
이번에 살펴볼 N-항 트리는 각 노드가 N개의 자식을 가질 수 있다. N은 임의의 양수이므로 N개의 자식 노드는 벡터를 이용하여 저장할 수 있다. 그러므로 N-항 트리는 다음과 같이 구현할 수 있다.

struct nTree

{	

	int Data;
 
	vector<nTree*> children;
 
}

위 코드에서 각각의 노드는 임의의 개수의 자식을 거느릴 수 있다. 그러므로 전체 트리도 임의의 형태를 가지게 된다. 평범한 이진 트리를 많이 사용하지 않는 것처럼 평볌한 N-항 트리도 그다지 유용하지 않다. 그러므로 응용 프로그램의 요구 사항에 맞는 형태의 트리를 만들어 사용해야 한다. 컴퓨터 분야에서 N-항 트리의 예이다.

*컴퓨터 파일 시스템 구조:리눅스에서는 루트부터, 윈도에서는 드라이브 이름부터 시작해서 다수의 파일과 폴더를 가질 수 있다. 파일 시스템 구조와 관련해서는 바로 다음에 나오는 실습문제 4: 파일 시스템 자료 구조 만들기에서 자세히 살펴본다.

*컴파일러: 대부분의 컴파일러는 표준 문법에 근거하여 소스 코드로부터 추상 구문 트리를 구성한다.(AST) 그리고 AST를 다시 분석하여 하위 레벨 코드를 생성한다.

# 2023.09.12

# Binary_Search_Tree

<이진 탐색 트리>

이진 검색 트리는 널리 사용되는 형태의 이진 트리이다. BST는 다음과 같은 속성이 있다. 

*부모 노드의 값 >= 왼쪽 자식 노드의 값

*부모 노드의 값 <= 오른쪽 자식 노드의 값
이러한 관계식에는 다음과 같은 특징이 있다. 부모 노드보다 작거나 같은 모든 원소는 항상 왼쪽에 있고, 부모 노드보다 크거나 같은 원소는 항상 오른쪽에 존재한다. 따라서 원소 검색을 위해 노드부터 차례대로 값을 비교하는 경우, 각 단계마다 검색 범위가 절반으로 줄어든다.

-BST에 새 원소 삽입

새로운 원소를 추가하려면 먼저 원소가 삽입될 위치의 부모 노드를 찾아야 한다. BST를 내려가면서 적절한 위치를 찾는다.

-BST에서 원소 삭제

*자식 노드가 없는 경우: 해당 노드 삭제

*자식 노드가 하나만 있는 경우: 노드 삭제 후, 부모 노드의 포인터가 해당 자식 노드를 가리키도록 조정

*자식 노드가 두 개 있는 경우: 노드 삭제 후, 현재 노드를 후속 노드로 대체

후속 노드란 현재 노드 다음으로 큰 숫자를 말한다. 즉 현재 원소보다 큰 원소들 중에서 가장 작은 원소를 의미한다.

이렇게 후속 노드로 대체하는 이유는 오른쪽 서브 트리의 모든 원소보다 현재 원소가 작아야 한다. 따라서 오른쪽 서브 트리의 가장 작은 원소로 대체하면 이진 검색 트리의 성질을 유지할 수 있다.

# URL_Mapping

STL unordered_map 컨테이너를 사용하여 긴 길이의 URL을 짧은 길이의 URL로 매핑하는 코드이다.

# Vaccination using Binary_Search

예방 접종을 받을 학생과 받은 학생을 구분하는 코드이다. 문제 해결 가이드는 다음과 같다.

1.학생을 표현하는 클래스 Student를 정의한다.

2.표준 라이브러리의 std::sort()함수를 이용하여 학생들의 벡터를 정렬할 수 있도록 student클래스의 크기 비교 연산자를 오버로딩한다.

3.학생이 리스트에 있는지 확인하기 위해 이진 검색을 수행한다.

4.만약 특정 학생이 리스트에 없다면 true를 반환한다. 이 경우 해당 학생은 예방 접종을 맞아야 한다.

5.만약 특정 학생이 리스트에 있는데 아직 예방 접종을 받지 않았다면 true를 반환한다.

6.그 외의 경우에는 false를 반환한다.

# Partial_QuickSort

퀵 정렬을 변형한 알고리즘이다. k가 주어지면 k번째 원소까지만 정렬을 진행한다. 

시퀀스의 일부만 정렬이 필요할 때 사용할 수 있다. 예를 들어 10000개의 데이터 중에서 상위 10퍼센트의 정렬된 값이 필요하다면 나머지 90퍼센트는 정렬할 필요가 없다.

모든 원소를 정렬한다면 시간 낭비일 것이다. 따라서 부분 퀵 정렬을 사용하여 상위 10퍼센트정도만 정렬하여 원하는 값을 얻을 수 있을 것이다.

# 2023.09.27

# Selection_Sort & Insertion_Sort

<Selection_Sort>

```cpp
function selectionSort(array A)
    for i from 1 to length[A]-1 do 
        minIndex = i   
        for j from i+1 to length[A] do  
            if A[j] < A[minIndex] then   
                minIndex = j  
            end if   
        end for   
        
        if minIndex != i then   
            swap(A[i],A[minIndex])  
        end if  
    end for  
end function
```

최선의 경우: O(n^2)

최악의 경우: O(n^2)

<Insertion_Sort>

```cpp
function insertionSort(array A)
    for i from 2 to length[A] do
        key = A[i]
        j = i - 1
        while j > 0 and A[j] > key do
            A[j + 1] = A[j]
            j = j - 1
        end while
        A[j + 1] = key 
    end for 
end function 
```

최선의 경우: O(n)

최악의 경우: O(n^2)

시간 복잡도를 보면 삽입 정렬이 최선의 경우에는 더 효율적인 것을 확인할 수 있다.

# Heap_Sort (PriorityQueue_Sort)

<힙 - 정렬>

힙으로 우선순위 큐를 구현할 경우 모든 우선순위 큐 ADT의 함수들을 로그시간 또는 그보다 효율적으로 구현할 수 있는 장점이 있다. 

우선순위 큐 P를 이용하여 리스트 L을 정렬하는 PriorityQueueSort 정렬 방법을 다시 고려한다. 

첫 번째 단계에서, i번째의 (1<= i <=n) 연산은 각각 O(1+log i)시간이 소요된다. 왜냐하면 연산이 수행된 후 힙은 i개의 원소를 갖기 때문이다. 유사하게 두 번째 단계에서 j번째의 (1<= j <=n) removeMin 연산은 각각
O(1 + log(n-j+1)) 시간이 소요된다. 왜냐하면 연산이 수행된 후 힙은 n-j+1 개의 원소를 갖기 때문이다. 결국, 각 단계의 실행 시간은 O(n log n)이 되고 우선순위를 구현하기 위해 힙을 사용할 경우, 전체 우선순위 큐 정렬 알고리즘의 실행 시간도 O(n log n)이 된다. 이러한 정렬 알고리즘을 힙-정렬 알고리즘이라고 한다.

*명제
힙-정렬 알고리즘은 n개의 원소를 갖는 리스트 L을 O(n log n) 시간에 정렬한다. 이때, L의 두 원소는 O(1) 시간에 비교 가능하다.

힙-정렬의 O(n log n) 실행 시간은 모든 정렬 알고리즘 중에 가장 우수하다.

<힙-정렬의 인-플레이스(In place) 구현>

만약 정렬된 리스트 L이 배열로 구현되어 있다면, 힙-정렬의 속도를 향상시킬 수 있으며 또한 리스트 L자체를 이용하여 힙을 저장하여 별도의 힙 자료구조를 사용할 필요가 없다. 이를 위해 다음과 같이 알고리즘을 수정한다.

1. 역 비교자를 사용하여 가장 큰 원소가 힙의 루트에 오도록 한다. 알고리즘을 실행하는 동안, L의 왼쪽 부분(순위 i-1까지)에 힙의 원소들을 저장하고, L의 오른쪽 부분(순위 i부터 n-1까지)에 시퀀스의 원소들을 저장한다. 따라서 L의 처음 i개 원소들(순위 0...,i-1)이 힙의 벡터 표현이 된다.(노드 번호가 1대신 0부터 시작). 즉, 순위 k에 저장된 원소는 순위 2k+1과 2k+2에 저장된 그 자식들보다 크거나 같다.

2.알고리즘의 첫 단계에서 비어 있는 힙에서 출발하여 힙과 시퀀스의 경계를 한 번에 하나씩 왼쪽에서 오른쪽으로 이동한다. 단계 i( i = 1,...,n)에서 순위 i-1에 있는 원소를 힙에 추가한다.

3.알고리즘의 두 번째 단계에서 비어 있는 시퀀스에서 출발하여 힙과 시퀀스의 경계를 한 번에 하나씩 오른쪽에서 왼쪽으로 이동한다. 단계 i(i = 1,...,n)에서 우리는 힙에서 최대값을 제거하여 순위 n-i에 저장한다.

*405페이지 그림 참고 필수.

리스트 자체 외에는 일정한 양의 공간만 추가로 필요하기 때문에, 위와 같은 힙- 정렬의 변형을 인-플레이스라고 한다. 즉, 원소들을 시퀀스의 밖으로 옮기거나 다시 들여오는 대신, 시퀀스 내부에서 움직인다. 일반적으로 정렬되는 객체 자신이 필요한 메모리 외에 일정한 양의 공간만 추가할 경우, 이러한 정렬 알고리즘을 인-플레이스라고 한다.

<적응 가능한 우선순위 큐>

적응 가능한 우선순위 큐의 경우 배열(힙)은 위치 인스턴스에 대한 참조 시퀀스이며, 각 인스턴스는 배열 내 항목의 키, 값 및 현재 인덱스를 저장합니다. 사용자에게는 삽입된 각 요소에 대한 Position 인스턴스에 대한 참조가 제공됩니다.

적응 가능한 우선순위 큐에서 키 값을 이용하여 접근하는 것은 불가능하다. 복수의 같은 키들이 있을 수 있기 때문이다. 대신에 우선순위 큐 연산 insert(e)가 확장되어 원소 e를 삽입한 후 새롭게 생성된 엔트리의 레퍼런스 즉 위치를 반환한다고 가정한다. 이 위치가 엔트리에 영구히 부착되어, 만약 엔트리의 순서가 우선순위 큐의 내부 자료구조에서 변경되더라도(예를 들어 버블링 연산) 그 위치는 이 엔트리에 고정되어 있다. 따라서 위치는 우리에게 각 연산이 적용되는 엔트리를 유일하게 식별할 수 있는 방법을 제공한다.

적응 가능한 우선순위 큐의 특징은 top 값 뿐 아니라 특정 엔트리의 키 값을 교체하거나 삭제할 수 있는 것이다.

일단 함수 replace를 구현하는 가장 간단한 방법을 택했다. 우리는 수정될 엔트리를 삭제하고 새 원소 e를 우선순위 큐에 삽입하였다. 일반적으로, 키 정보가 바뀔 수 있으므로 정렬된리스트에서 새로운 장소로 이동할 필요가 있다. 키의 변화가 드물다는 가정하에, 좀 더 영리한 방법은 수정된 엔트리의 적절한 장소를 결정하기 위해 앞 뒤로 이동하여 검색하는 것일 것이다. 우리의 방법이 매우 효울적이진 않지만 간단하다는 장점이 있다. 

*로케이션 인식 엔트리

AdaptPriorityQueue의 구현에서, 우리는 리스트-기반 우선순위 큐 구현의 장점을 활용하였다. 특히, 새 엔트리가 정렬된 리스트에 한 번 삽입되면, 이 엔트리에 연관된 원소는 결코 변하지 않는다. 이것은 insert나 replace 함수에 의해 반환된 위치는 항상 같은 원소를 가리킴을 의미한다.

그러나 이러한 방법은 힙-기반 우선순위 큐에서는 적용할 수 없다. 그 이유는 힙-기반 구현에서는 엔트리들이 힙 내부에서 이동하기 때문이다.(예를 들어, 업-힙 또는 다운-힙 버블링을 통해).원소 e가 삽입되면, e를 포함하는 엔트리 p의 레퍼런스를 반환한다. 그러나 만약 e가 우선순위 큐에 취해진 후속 연산에 의해 이동하였다면, p는 변하지 않는다. 결과적으로 p는 우선순위 큐의 다른 원소를 가리킬 수 있다. remove(p)또는 replace(p,e')은 e 대신 다른 원소에 적용될 수 있다. 이러한 문제에 대한 해결책은 위치와 원소를 분리하는 것이다. 

우리의 AdaptPriorityQueue의 구현에서, 각 위치 p는 실제 하부 자료구조의 한 노드를 가리킨다.(STL 반복자가 실제 구현된 방법이다) 만약 엔트리를 이동하면, 연관된 포인터도 동시에 바뀌어야 한다. 움직이는 엔트리를 처리하기 위해, 우선순위 큐에 새 원소 e가 삽입될 때마다 자료구조에서 새 엔트리를 생성함과 동시에 로케이터라 불리는 객체를 위해 메모리를 할당한다. 로케이터의 임무는 자료구조에 원소 e의 현재 위치 p를 저장하는 것이다. 우선순위 큐의 각 엔트리는 자신과 연관된 로케이터 e를 알아야 한다. 따라서, 우선순위 큐에 원소 자신만 저장하는 것이 아니라, 원소 e와 로케이터를 가리키는 포인터의 쌍 (e,&l)을 저장한다. 이것을 로케이션-인식 엔트리라고 한다. 우선순위 큐에 새 원소를 삽입한 후, 우리는 이 쌍을 가리키는 연관된 로케이터 객체를 반환한다.

이것이 어떻게 위치와 엔트리를 분리하는 문제를 해결하는가? 첫째, 우선순위 큐의 사용자가 전에 삽입된 원소의 위치 p를 원할 때마다 이 위치를 저장하는 로케이터를 접근하면 충분하다. 그러나, 엔트리가 자료구조 내에서 다른 위치p'으로 이동하였다고 가정하자. 이것을 처리하기 위해, 우리는 우선 로케이터 e에 접근하기 위해 로케이션-인식 엔트리(e,&l)에 접근한다. 다음 e를 수정하여 새 위치 p'을 가리키게 한다. 사용자는 이 로케이터를 접근함으로ㅆ 새 위치를 찾을 수 있을 것이다. 

이러한 추가적인 기능을 위해 우리가 치러야 할 것은 매우 작다. 각 엔트리마다 우리는 두 개의 추가적인 포인터를 저장할 필요가 있다(로케이터와 로케이터의 주소). 자료구조에서 객체를 이동할 때마다, 상수 개의 포인터를 수정하면 된다. 따라서 실행 시간은 단지 일정한 비율로만 증가한다.

# AVL Tree

<AVL 트리>

모든 기본적인 맵 연산에 대해서 로그 시간에 도달할 수 있도록 하는 트리를 설명한다.

간단한 수정은 트리의 로그 높이를 유지하도록 이진 탐색트리를 정의하는 규칙을 추가하는 것이다. 이 절에서 논의하는 규칙은 내부 노드의 높이로써 이진 탐색트리 T의 구조를 특징짓는 높이-균형 특성(height-balance property)이다.(트리의 노드 v의 높이는 v에서 외부 노드까지의 갖아 긴 경로의 길이다)

*높이-균형 특성: T의 모든 내부 노드 v에 대해, v의 자식 노드들의 높이 차는 최대 1이다.

이 특성을 만족하는 이진 탐색트리 T를 AVL트리라고 한다. 높이 - 균형 특성의 직접적인 결과는 AVL 트리의 서브트리가 바로 AVL트리라는 것이다. 다음 명제에서 보이듯이 높이-균형 특성은 또한 높이를 낮게 유지하는 중요한 결과를 가진다.

*명제: n개의 엔트리를 저장하는 AVL트리의 높이는 O(log n)이다. 


*삽입

AVL트리 T에서의 삽입은 이진 탐색트리에 대한 insert연산으로 시작한다. 이 연산은 T에 항상 외부 노드인 노드 w에 새로운 항목을 삽입하고 연산 insertAtExternal을 사용하여 w를 내부 노드로 만든다는 것을 상기하라.

즉 이는 w에 두 개의 외부 자식 노드를 추가한다. 하지만 이 동작은 어떤 노드에 대해 높이가 1만큼 증가하기 때문에 높이-균형 특성을 어길 수 있다. 특히 노드 w와 그 조상들 중 일부는 높이를 1만큼 증가시킬 수도 있다. 

그러므로 이 높이-균형 특성을 회복하기 위해 T를 어떻게 재구성하는지를 설명해보자.

주어진 이진 탐색 트리 T의 어떤 노드 v에 대해서 만일 v의 자식들의 높이 차의 절댓값이 많아야 1이면 T의 노드 v는 균형이라고 하고, 다른 경우는 불균형이라고 말한다. 그러므로 높이-균형 특성을 특징으로 하는 AVL트리는 모든 내부노드가 균형이라는 말과 같다.

T가 높이-균형 특성을 만족한다고 가정하면 새로운 항목을 삽입하기 전에는 AVL트리이다. 언급한 것처럼 T에서 연산 insertAtExternal이 실행된 후 w를 포함하는 T의 어떤 노드들의 높이는 증가한다. 그러한 모든 노드는 w로부터 루트까지 T의 경로상에 있고 이것은 불균형이 발생할 가능성이 있는 T의 노드들이다. 물론, 이런 현상이 발생하면 T는 더 이상 AVL트리가 아니다. 그러므로 불균형을 수정하기 위한 방법이 요구된다.

간단한 탐색-수정(search -and- repair) 전략으로 이진 탐색트리 T의 노드의 균형을 복구한다. 특히 T의 w로부터 루트를 향해 올라가다가 불균형이 되는 첫 노드를 z라고 하자. 또한 더 높은 높이를 가지는 z의 자식 노드를 y라고 하자. 마지막으로 더 높은 높이를 가지는 자식 노드를 x라고 하자(만약 높이가 같으면 w의 조상인 x를 선택한다). 노드 x는 w와 같을 수도 있고 w가 z의 손자 노드임에 주의해야 한다. 자식 y를 루트로 하는 서브트리의 삽입으로 인하여 z가 불균형이 되기 때문에 y의 높이는 형제 노드보다 2만큼 크게 된다.

이제 트라이노드 재구성(trinode restructuring)함수라고 불리는 restructure
함수를 통해서 z를 루트로 하는 서브 트리를 다시 균형화한다. 트라이노드 재구성은 임시적으로 노드 x,y,z를 a,b,c로 재명명하고, T의 중위 순회에서 a는 b에 선행하고, b는 c에 선행한다. x,y,z를 a,b,c로 사상하는 네 가지 가능한 방법이 책 504p에 있다. 이것은 재표시(relabeling)에 의해 하나의 경우로 융합된다. 트라이노드 재구성을 통해 z를 b 노드로 교체하고, a와 c를 이 노드의 자식으로 만들고 T의 모든 노드의 중위 관계를 유지하면서 x,y,z의 이전의 네 자식들(x,y가 아닌)을 a와 c의 자식으로 만든다.

*코드

Algorithm restructure(x):

입력: 부모 y와 조부모 z를 가지는 이진 탐색트리의 T의 노드 x
출력: 노드 x,y,z를 포함하는 트라이노드 재구성(단일회전이나 이중회전에 대응)후의 트리 T

1:(a,b,c)를 노드 x,y,z의 왼쪽에서 오른쪽으로의 (중위) 순서로 두고, T0,T1,
T2,T3를 x,y 또는 z를 루트로 하지 않는 x,y 그리고 z의 네 서브트리를 왼쪽에서 오른쪽으로의 (중위)순서로 둔다.

2:z를 루트로 하는 서브트리를 b를 루트로 하는 서브트리로 교체한다.

3.a를 b의 왼쪽 자식으로 두고, T0와 T1을 각각 a의 왼쪽, 오른쪽 서브트리로 둔다.

4.c를 b의 오른쪽 자식으로 두고, T2와 T3을 각각 c의 왼쪽,오른쪽 서브트리로 둔다.

트라이노드 재구성 연산으로 인한 트리 T의 변경은 T를 바꾸는 방법을 시각화할 수 있는 기하학 방법이기 때문에 회전(rotation)이라고 불린다. 만약 b=y라면, 트라이노드 재구성 함수는 z위에 y가 회전됨으로써 시각화할 수 있기 때문에 단일 회전이라고 불린다. 만약 b=x라면 트라이노드 재구성 함수는 먼저 y위에 x가, 그 후 z위에 회전됨으로써 시각화될 수 있기 때문에 이중 회전이라고 불린다. 몇몇 컴퓨터 연구가들은 각각 대칭적인 두 타입을 가지는 분리된 함수로서 이 두 종류의 회전을 다룬다. 그러나 이 네 가지 회전 타입은 단일 트라이노드 재구성 연산으로 융합된다. T의 모든 노드의 중위 순회 순서를 유지하는 동안 트라이노드 재구성 방법은 T의 O(1)노드들의 부모-자식 관계를 수정한다.

순서-유지 특성에 더하여 트라이노드 재구성 함수는 균형을 회복하기 위해서 T의 노드 높이를 변경한다. x의 조부모인 z가 불균형이 되므로 restructure함수를 실행한다. 더욱이, 이 불균형은 z의 다른 자식의 높이에 비해 상대적으로 매우 큰 높이를 가지고 있는 x의 자식들 중 하나에 의해 발생한다.

회전의 결과로 x의 큰 자식을 위로 올리고, z의 작은 자식을 내리게 된다. 그러므로 restructure의 실행 후 b로 불리는 노드를 루트로 하는 서브트리의 모든 노드는 균형이 된다. 그러므로 지역적으로 노드 x,y,z에서의 높이-균형 특성을 회복한다. 추가로, b를 루트로 하는 서브트리에 새로운 항목의 삽입을 실행한 후에 하나의 유닛만큼 커졌던 x를 루트로 하는 이전의 트리를 바꾸기 때문에 이전에 불균형했던 z의 모든 조상은 균형을 이루게 된다. 그러므로 이 하나의 재구성은 전체적으로 높이-균형을 회복한다. 

*삭제

insert 맵 연산의 경우처럼, 보통 이진 탐색트리에서 이 연산을 실행하는 알고리즘을 사용하여 AVL트리 T에서 erase 맵 연산의 구현을 시작한다. AVL트리에서 이 접근법의 사용으로 추가되는 어려움은 높이-균형 특성을 어길 수도 있다는 것이다. 특히 연산 removeAboveExternal을 사용하여 내부 노드를 삭제한 후와 그 위치로 그 자식의 하나를 올린 후에는 이전에 삭제된 노드의 부모 w로부터 T의 루트까지의 하나의 그러한 불균형 노드가 있을 수 있다. 삽입과 마찬가지로 트리 T의 균형을 회복하기 위해서 트라이노드 재구성을 사용한다. 특히 w에서 T의 루트를 향해 올라가다 만나게 되는 첫 노드를 z라고 하자. 또한 보다 높은 높이를 가지는 z의 자식을 y라고 두고(노드 y는 w의 조상이 아닌 z의 자식임에 유의하자). 다음과 같이 정의된 y의 자식을 x라 하자: y의 자식들 중 하나가 다른 것보다 크다면 x를 y의 자식이라고 한다; 그렇지 않으면(y의 두 자식이 같은 높이이면)x가 y와 같은 쪽에서 y의 자식이라고 한다(즉, y가 왼쪽 자식이면 x는 y의 왼쪽 자식이고, 아니면 x는 y의 오른쪽 자식이다). 어쨋든 z를 루트 노드로 하는 이전의 서브트리에서 높이-균형 특성을 지역적으로 회복하는 restructure를 실행한 후 임시로 b라고 불리는 노드를 루트로 한다.

불행하게도 이 트라이노드 재구성은 b를 루트로 하는 서브트리의 높이를 1만큼 감소시킬 수도 있는데, 이것은 b의 조상을 불균형으로 만들 수 있다. 그러므로 단일 트라이노드 재구성은 삭제 후 전체적으로 높이-균형 특성을 반드시 회복하지는 못한다. 그래서 z를 균형화한 후 계속 T를 따라가며 불균형 노드를 찾는다. 만약 다른 노드가 발견되면 균형을 회복하기 위해 재구성 연산을 실행하고 불균형 노드를 더 찾기 위해 루트로 가는 모든 길을 계속 T를 따라 찾아간다. 그럼에도 불구하고 명제 10.2에 의해 항목의 수를 n이라 하면 T의 높이가 O(log n)이기 때문에 O(log n)트라이노드 재구성은 높이-균형 특성을 회복하기에 충분한다.

*AVL 트리의 성능

명제 10.2에 의해 O(log n)이기 때문에 위 연산들 각 각은 O(log n)시간이 걸린다. 


*AVL 트리의 C++ 구현

이제 n개의 엔트리의 순서화된 딕셔너리를 구현하기 위한 n개의 내부 노드를 가지는 AVL트리 T의 사용 분석과 자세한 구현에 착수한다. T에 대한 삽입과 삭제 알고리즘은 트라이노드 재구성을 실행하고 두 형제 노드의 높이 차이를 판단할 수 있어야 한다. 이제 재구성에 관해서 이진 탐색트리에 대한 구현이 트라이노드 재구성 연산을 수행하는 메소드 restructure()를 포함하고 있음을 확인할 필요가 있다. 이 함수의 구현을 제공하지 않지만 7.3.4절에 주어진 링크드 이진 트리 클래스에 쉽게 추가할 수 있다. 만약 T가 링크드 구조로 구현되면, restructure 연산이 O(1)시간에 실행될 수 있다는 것을 보이기는 쉽다. 
SearchTree클래스가 이 함수를 포함하고 있다고 가정한다.

높이 정보와 관련하여 각 내부 노드 v의 높이를 각 노드에 저장하도록 선택했다. 대안으로 v의 왼쪽 자식의 높이에서 v의 오른쪽 자식의 높이를 뺀 것으로 정의된 v의 균형 요소(balance factor)를 v에 저장할 수 있다. 그러므로 v의 균형 요소는 일시적으로 -2와 +2와 같게 될 수도 있는 삽입이나 삭제를 하는 동안을 제외하고는 항상 -1,0,1 중 하나가 된다. 삽입이나 삭제가 수행되는 동안, O(log n)노드들의 높이와 균형 요소들은 영향을 받으며 O(log n)시간 내에 유지될 수 있다.

높이 정보를 저장하기 위해 AVLEntry라고 하는 서브클래스를 프로그램 코드 10.3에 주어진 표준 항목 클래스로부터 유도한다. 이것은 기본 항목 타입으로 기본 구조를 갖고 있으며 이것으로부터 키와 값 멤버를 상속받는다. 이것은 멤버 변수 ht를 정의하며, 이는 연관 노드를 루트로 하는 서브트리의 높이를 저장한다. 이것은 이 값을 액세스하고 설정하기 위한 멤버 함수를 제공한다. 이들 함수는 보호되며 따라서 사용자는 이들을 액세스할 수 없으나 AVLTree는 할 수 있다.

강화된 AVLEntry를 사용한다. 이 클래스는 키,값,그리고 트리 위치와 같은 엔트리를 참조하기 위한 타입 정의(typedef) 멤버를 정의한다. 이 클래스는 모든 표준 딕셔너리 퍼블릭 멤버 함수를 선언한다. 마지막에, 이것은 AVL 트리 균형 특성을 유지하기 위해 사용된 유틸리티 함수들의 멤버도 정의한다.

다음으로, 우리는 생성자와 높이 유틸리티 함수를 제시한다. 생성자는 단순히 이진 탐색트리를 위한 생성자를 호출하며, 이는 항목이 없는 트리를 생성한다. 함수 height는 AVLEntry로부터 높이 정보를 추출하여 노드의 높이를 반환한다.

다음으로 트리 균형을 유지하는 데 필요한 몇 가지 유틸리티 함수를 제시한다. 함수 setHeight는 노드에 대한 높이 정보를 이것의 두 자식의 높이의 최대값보다 하나 많은 것으로 설정한다. 함수 isBalanced는 자식들 간의 높이 차이가 많아야 1인지를 조사함으로써 노드가 AVL 균형 조건을 만족하는지를 결정한다. 마지막으로, 함수 tallGrandChild는 노드의 가장 큰 자식을 결정한다. 재구성 연산을 적용할 노드를 결정하기 위해 삭제 연산이 이 과정을 필요로 함을 상기하라.

다음으로 삽입 혹은 삭제 후에 AVL트리의 균형을 다시 유지하기 위한 주요한 함수들을 제시한다. 이 과정은 연산에 의해 영향을 받는 노드 v에서 시작한다. 다음에 루트 레벨로 트리를 따라 올라간다. 방문하는 각 노드 z에서 이 과정은 z의 높이 정보(갱신 연산으로 인해 변경되었을 수도 있음)를 갱신하고 z가 균형을 유지하는지를 조사한다. 균형을 유지하지 않는다면, 이 과정은 z의 가장 큰 손자를 찾고 이 노드에 재구성 연산을 적용한다. 높이가 그 결과로 변경되었을 수 있기 때문에, z의 자식과 자신에 대한 높이 정보를 갱신한다.

마지막으로 키를 삽입하고 제거하기 위한 함수를 제시한다. 각각은 기본 클래스 SearchTree로부터 연관된 유틸리티 함수(inserter혹은 eraser)를 호출한다. 다음에 각각은 트리의 균형을 다시 유지하기 위해 rebalance를 호출한다.

# Splay_Tree

<스플레이 트리>

스플레이 트리는 자체 조정 이진 검색 트리 데이터 구조입니다. 즉, 트리 구조는 액세스되거나 삽입된 요소에 따라 동적으로 조정됩니다. 즉, 자주 액세스하거나 삽입되는 요소가 루트 노드에 가까워지도록 트리가 자동으로 재구성됩니다.

O(log n) 상각 시간 복잡도에서 검색, 삽입 및 삭제 작업을 수행할 수 있는 간단하고 효율적인 구현을 가지고 있습니다. 여기서 n은 트리의 요소 수입니다.

스플레이 트리의 기본 아이디어는 스플레잉(splaying)이라고 하는 일련의 트리 회전을 수행하여 가장 최근에 액세스했거나 삽입된 요소를 트리의 루트로 가져오는 것입니다. 스플레잉(Splaying)은 가장 최근에 액세스하거나 삽입한 요소를 새로운 루트로 만들고 나머지 노드를 점차 루트에 더 가깝게 이동하여 트리를 재구성하는 프로세스입니다.

스플레이 트리는 자주 액세스되는 요소에 대한 전체 액세스 시간을 줄이는 자체 조정 특성으로 인해 실제로 매우 효율적입니다. 따라서 캐싱 시스템, 데이터 압축 및 네트워크 라우팅 알고리즘과 같이 빠르고 동적 데이터 구조가 필요한 애플리케이션에 적합한 선택입니다.

그러나 스플레이 트리의 가장 큰 단점은 균형 잡힌 트리 구조를 보장하지 않아 최악의 경우 성능 저하가 발생할 수 있다는 것입니다. 또한, 스플레이 트리는 실시간 시스템이나 안전이 중요한 시스템과 같이 최악의 성능을 보장해야 하는 애플리케이션에는 적합하지 않습니다.

전반적으로 스플레이 트리는 자주 액세스하거나 삽입되는 요소에 빠르고 효율적으로 액세스할 수 있는 강력하고 다양한 데이터 구조입니다. 이는 다양한 애플리케이션에서 널리 사용되며 성능과 단순성 사이의 탁월한 절충안을 제공합니다.

스플레이 트리의 주요 특징은 요소에 액세스할 때마다 해당 요소가 트리의 루트로 이동하여 후속 액세스를 위해 보다 균형 잡힌 구조를 만든다는 것입니다.
스플레이 트리는 모양은 변경하지만 요소의 순서는 유지하는 트리의 로컬 변형인 회전을 사용하는 것이 특징입니다.
회전은 액세스된 요소를 트리의 루트로 가져오고, 여러 액세스 후 균형이 맞지 않는 경우 트리의 균형을 재조정하는 데 사용됩니다.


*삽입: 트리에 새 요소를 삽입하려면 일반적인 이진 검색 트리 삽입을 수행하여 시작합니다. 그런 다음 회전을 적용하여 새로 삽입된 요소를 트리의 루트로 가져옵니다.

*삭제 : 트리에서 요소를 삭제하려면 먼저 이진 검색 트리 검색을 사용하여 해당 요소를 찾습니다. 그런 다음 요소에 자식이 없으면 간단히 제거하면 됩니다. 자식이 하나 있으면 해당 자식을 트리의 해당 위치로 승격시킵니다. 두 개의 자식이 있는 경우 요소의 후속 요소(오른쪽 하위 트리에서 가장 작은 요소)를 찾고 해당 키를 삭제할 요소와 교환한 다음 대신 후속 요소를 삭제합니다.

*검색 : 트리에서 요소를 검색하려면 이진 검색 트리 검색을 수행하여 시작합니다. 요소가 발견되면 회전을 적용하여 트리의 루트로 가져옵니다. 찾지 못한 경우 검색에서 마지막으로 방문한 노드에 회전을 적용하여 새 루트가 됩니다.

*회전 : 전개 트리에 사용되는 회전은 Zig 또는 Zig-Zig 회전입니다. Zig 회전은 노드를 루트로 가져오는 데 사용되는 반면, Zig-Zig 회전은 동일한 하위 트리의 요소에 여러 번 액세스한 후 트리 균형을 유지하는 데 사용됩니다.

Zig Rotation : 노드에 오른쪽 자식이 있으면 오른쪽 회전을 수행하여 루트로 가져옵니다. 왼쪽 자식이 있으면 왼쪽 회전을 수행합니다.
Zig-Zig 회전: 노드에 자식의 오른쪽 또는 왼쪽 자식이기도 한 손자가 있는 경우 트리 균형을 맞추기 위해 이중 회전을 수행합니다. 예를 들어 노드에 오른쪽 자식이 있고 오른쪽 자식에 왼쪽 자식이 있는 경우 오른쪽-왼쪽 회전을 수행합니다. 노드에 왼쪽 자식이 있고 왼쪽 자식에 오른쪽 자식이 있는 경우 왼쪽-오른쪽 회전을 수행합니다.

*스플레이 트리의 회전
지그 회전
재그 회전
지그 – 지그 회전
재그 – 재그 회전
지그 – 재그 회전
재그 – 지그 회전

# B Tree

대량의 데이터를 저장하고 검색할 때 기존 이진 검색 트리는 성능이 낮고 메모리 사용량이 높아 실용적이지 않을 수 있습니다. B-트리(B-Tree) 또는 균형 트리(Balanced Tree)라고도 알려진 B-트리는 이러한 한계를 극복하기 위해 특별히 설계된 자체 균형 트리 유형입니다.

기존 이진 검색 트리와 달리 B-트리는 단일 노드에 저장할 수 있는 키의 수가 많기 때문에 "큰 키" 트리라고도 알려져 있습니다. B-트리의 각 노드에는 여러 개의 키가 포함될 수 있으며, 이를 통해 트리는 더 큰 분기 요소를 가지므로 더 낮은 높이를 가질 수 있습니다. 높이가 낮으면 디스크 I/O가 줄어들어 검색 및 삽입 작업이 더 빨라집니다. B-트리는 하드 드라이브, 플래시 메모리, CD-ROM과 같이 느리고 대용량 데이터 액세스가 가능한 스토리지 시스템에 특히 적합합니다.

B-트리는 각 노드에 최소 개수의 키가 있는지 확인하여 균형을 유지하므로 트리는 항상 균형을 유지합니다. 이러한 균형은 트리의 초기 모양에 관계없이 삽입, 삭제, 검색과 같은 작업의 시간 복잡도가 항상 O(log n)임을 보장합니다.

*B-트리의 속성: 

1.모든 잎은 같은 수준에 있습니다.

2.B-트리는 최소 차수 ' t '라는 용어로 정의됩니다. ' t ' 값은 디스크 블록 크기에 따라 달라집니다.

3.루트를 제외한 모든 노드에는 최대 t-1개의 키가 포함되어야 합니다. 루트에는 최소 1개의 키가 포함될 수 있습니다.

4.모든 노드(루트 포함)에는 최대 ( 2*t – 1 )개의 키가 포함될 수 있습니다.

5.노드의 자식 수는 해당 노드의 키 수에 1을 더한 것과 같습니다 .

6.노드의 모든 키는 오름차순으로 정렬됩니다. 두 키 k1 과 k2 사이의 하위 항목에는 k1 과 k2 범위의 모든 키가 포함됩니다 .

7.B-트리는 이진 검색 트리와 달리 루트에서 성장하고 축소됩니다. 이진 검색 트리는 아래로 성장하고 아래로 축소됩니다.

8.다른 균형 이진 검색 트리와 마찬가지로 검색, 삽입, 삭제의 시간 복잡도는 O(log n)입니다.

9.B-Tree에 노드를 삽입하는 것은 Leaf Node에서만 발생합니다.

# B+ Tree

*B+ 트리의 특징
균형: B+ 트리는 자체 균형을 유지합니다. 즉, 데이터가 트리에 추가되거나 제거될 때 자동으로 조정되어 균형 잡힌 구조를 유지합니다. 이렇게 하면 트리 크기에 관계없이 검색 시간이 상대적으로 일정하게 유지됩니다.

다중 레벨: B+ 트리는 상단에 루트 노드가 있고 그 아래에 하나 이상의 내부 노드 레벨이 있는 다중 레벨 데이터 구조입니다. 최하위 수준의 리프 노드에는 실제 데이터가 포함됩니다.

Ordered: B+ 트리는 트리의 키 순서를 유지하므로 범위 쿼리 및 정렬된 데이터가 필요한 기타 작업을 쉽게 수행할 수 있습니다.

팬아웃(Fan-out): B+ 트리는 팬아웃이 높습니다. 이는 각 노드가 많은 하위 노드를 가질 수 있음을 의미합니다. 이렇게 하면 트리 높이가 줄어들고 검색 및 인덱싱 작업의 효율성이 높아집니다.

캐시 친화적: B+ 트리는 캐시 친화적으로 설계되었습니다. 즉, 최신 컴퓨터 아키텍처의 캐싱 메커니즘을 활용하여 성능을 향상시킬 수 있습니다.

디스크 지향: B+ 트리는 디스크에서 데이터를 저장하고 검색하는 데 효율적이기 때문에 디스크 기반 스토리지 시스템에 자주 사용됩니다.

B+ 트리를 사용하는 이유는 무엇입니까?

B+ Trees는 효율적인 디스크 액세스를 촉진하면서 I/O 작업을 최소화하므로 데이터 액세스가 느린 스토리지 시스템에 가장 적합한 선택입니다.

B+ 트리는 다양한 활동에 대해 예측 가능한 성능을 보장하고 효과적인 범위 기반 쿼리를 촉진하는 균형 잡힌 구조로 인해 빠른 데이터 검색이 필요한 데이터베이스 시스템 및 애플리케이션에 적합한 선택입니다.

# Red Black Tree

<Red Black Tree>

데이터 검색 및 정렬과 관련하여 가장 기본적인 데이터 구조 중 하나는 이진 검색 트리입니다. 그러나 이진 검색 트리의 성능은 모양에 따라 크게 달라지며, 최악의 경우 시간 복잡도가 O(n)인 선형 구조로 변질될 수 있습니다. Red Black Trees가 등장하는 곳입니다. 이는 트리가 항상 균형을 이루도록 특정 규칙 세트를 사용하는 일종의 균형 이진 검색 트리입니다. 이러한 균형은 트리의 초기 모양에 관계없이 삽입, 삭제, 검색과 같은 작업의 시간 복잡도가 항상 O(log n)임을 보장합니다.

레드 블랙 트리는 자체 균형을 유지합니다. 즉, 각 삽입 또는 삭제 작업 후에 트리가 자동으로 조정됩니다. 트리의 각 노드를 빨간색이나 검은색으로 색칠하여 균형을 유지하는 간단하지만 강력한 메커니즘을 사용합니다. 
*레드 블랙 트리의 속성:
Red-Black 트리는 이진 검색 트리의 모든 속성을 만족하며 다음과 같은 추가 속성도 만족합니다.

1. 루트 속성: 루트는 검은색입니다.

2. 외부 속성: 모든 리프(리프는 노드의 NULL 자식임)는 Red-Black 트리에서 검정색입니다.

3. 내부 속성: 빨간색 노드의 자식은 검정색입니다. 따라서 레드 노드의 가능한 부모는 블랙 노드입니다.

4. 깊이 속성: 모든 잎은 동일한 검은색 깊이를 갖습니다.

5. 경로 속성: 루트에서 하위 리프 노드까지의 모든 단순 경로에는 동일한 수의 검정색 노드가 포함됩니다. 

위에서 언급한 모든 속성의 결과는 Red-Black 트리가 대략적으로 균형을 이룬다는 것입니다.

*모든 레드-블랙 트리가 따르는 규칙: 
모든 노드에는 빨간색 또는 검정색의 색상이 있습니다.

트리의 루트는 항상 검은색입니다.

인접한 두 개의 빨간색 노드가 없습니다(빨간색 노드는 빨간색 부모 또는 빨간색 자식을 가질 수 없습니다).

노드(루트 포함)에서 하위 NULL 노드까지의 모든 경로에는 동일한 수의 검정색 노드가 있습니다.

모든 리프(ei NULL 노드)는 검정색이어야 합니다.


*왜 레드-블랙 트리인가?

대부분의 BST 작업(예: 검색, 최대, 최소, 삽입, 삭제 등)은 O(h) 시간이 소요됩니다. 여기서 h는 BST의 높이입니다. 왜곡된 이진 트리의 경우 이러한 작업 비용은 O(n)이 될 수 있습니다. 모든 삽입과 삭제 후에 트리의 높이가 O(log n)으로 유지되도록 하면 이러한 모든 작업에 대해 O(log n)의 상한을 보장할 수 있습니다. Red-Black 트리의 높이는 항상 O(log n)입니다. 여기서 n은 트리의 노드 수입니다. 

*AVL 트리 와의 비교 :

AVL 트리는 Red-Black Tree에 비해 균형이 잘 잡혀 있지만 삽입 및 삭제 시 회전이 더 많이 발생할 수 있습니다. 따라서 애플리케이션에 삽입과 삭제가 자주 발생하는 경우 Red-Black 트리가 선호됩니다. 그리고 삽입과 삭제가 덜 빈번하고 검색이 더 빈번한 작업이라면 AVL 트리가 레드-블랙 트리보다 선호되어야 합니다.

레드-블랙 트리에서 더블 블랙이라는 개념은 노드 삭제 시 발생하는 문제를 처리하기 위해 사용됩니다. 레드-블랙 트리에서 노드를 삭제할 때, 트리의 블랙 높이 규칙이 깨지는 경우가 있습니다.

블랙 높이 규칙이란, 레드-블랙 트리의 모든 노드에 대해, 그 노드에서 임의의 리프 노드(Null 노드)까지의 모든 경로에는 같은 수의 블랙 노드가 있어야 한다는 규칙입니다.

노드를 삭제하면서 이 규칙이 깨지는 경우, 더블 블랙이라는 임시 상태를 부여하여 규칙을 복원하는 동작을 수행합니다. 더블 블랙 노드는 실제 블랙 노드보다 하나 더 많은 블랙색을 가진 것으로 간주되어, 이를 처리하는 과정에서 레드-블랙 트리의 규칙을 유지할 수 있습니다.

더블 블랙 노드는 회전, 색상 변경 등의 연산을 통해 처리되며, 이 과정은 더블 블랙 노드가 더 이상 존재하지 않을 때까지 반복됩니다. 이렇게 함으로써 레드-블랙 트리의 규칙을 유지하면서 노드 삭제를 안전하게 처리할 수 있습니다.

레드-블랙 트리에서 노드를 삭제할 때 더블 블랙이라는 상태가 발생하는 이유는 노드 삭제 과정에서 블랙 높이 규칙을 유지하기 위함입니다.

레드-블랙 트리의 규칙 중 하나는 모든 노드에 대해, 그 노드에서 임의의 리프 노드까지의 모든 경로에 같은 수의 블랙 노드가 있어야 한다는 것입니다. 그런데 블랙 노드를 삭제하면 이 규칙이 깨집니다. 왜냐하면 삭제된 블랙 노드를 지나는 경로는 블랙 노드가 하나 적어지게 되기 때문입니다.

따라서 이를 보정하기 위해 삭제된 노드의 자식 노드를 '더블 블랙'으로 표시하게 됩니다. 더블 블랙 노드는 실제 블랙 노드보다 하나 더 많은 블랙색을 가진 것으로 간주됩니다. 이후 레드-블랙 트리에서는 이 더블 블랙 노드를 처리하는 연산을 수행하여 트리의 균형을 유지하게 됩니다.

이렇게 하면 노드를 삭제하면서도 레드-블랙 트리의 블랙 높이 규칙을 유지할 수 있게 됩니다. 이는 레드-블랙 트리가 노드 추가, 삭제 시에도 탐색, 삽입, 삭제 연산의 시간 복잡도를 유지하기 위한 중요한 메커니즘입니다.

# 백준 15649번 문제 (N과 M)

백트래킹을 이용하여 수열을 구하는 문제이다.

*문제

자연수 N과 M이 주어졌을 때, 아래 조건을 만족하는 길이가 M인 수열을 모두 구하는 프로그램을 작성하시오.

-1부터 N까지 자연수 중에서 중복 없이 M개를 고른 수열

*입력

첫째 줄에 자연수 N과 M이 주어진다. (1 ≤ M ≤ N ≤ 8)

*출력

한 줄에 하나씩 문제의 조건을 만족하는 수열을 출력한다. 중복되는 수열을 여러 번 출력하면 안되며, 각 수열은 공백으로 구분해서 출력해야 한다.

수열은 사전 순으로 증가하는 순서로 출력해야 한다.

조합의 개수를 구하는 문제이다. DFS를 사용하여 구할 수 있다.

# 백준 15650번 N과 M(2)

N과 M문제와 비슷한 문제이나, 오름차순으로 출력해야 한다는 조건이 있다. 간단한 예외 처리로 구현 가능하다.

# 백준 15651번 N과 M(3)

이번에는 중복 선택이 가능한 문제이다.
